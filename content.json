{"pages":[{"title":"关于","text":"关于我和我的站点我叫李云龙，每当谈起我的名字总是能与某部电视剧联想起来。我总觉得怪不好意思的。给别人介绍的时候。都会重复一遍我的名字。 只能摸摸头。说着沾光了沾光了。 也许是我没有电视剧中的人物那么酷。 没有那种野性。也没有太多的闪光点。 不过也不算太糟糕。 我就是我。我没有必要成为别人想象中的样子。 做自己喜欢的事情足矣。 一个程序员我可能是小时候接触的互联网了。 在五六年级的时候，要么就是出去跟人一起打乒乓球，就是带着乒乓球去了网吧。 小时候也不知道互联网是什么。黑客是做什么的。玩过大大小小的游戏。因为舍不得充值，也葬送了我许多帐号。同时也葬送了我的成绩。 小时候成绩一直不好。英语从来也没有重视过。 不过还好，其他科目还算过的去。 不过因为这事情。也让我成为了一个复读生。 复读的时候也纠结过一阵子，当时如果没有复读 可能也不会在这里写博客了吧。 步入大学，精心选了一个个人觉得薪资比较高的专业。可能是因为复读的原因。比较努力对待这个专业。刚开始的时候满脑子都是 编程是什么 这些if有什么用。以前一直没有兴趣爱好。直到学Java我发现这是一个极具魅力的语言，许多东西是最基础，但也是最为重要的，当时为了快速学习搜罗了一大堆的网盘视频。天天都看。搞的有个舍友跟着学。 天天一起钻图书馆，重复看了好多基础书籍。。一直认为基础是最为重要的。 然后过了半个学期就入了一个组织。这个组织说起来也奇怪。也不归属学校。现在想起来。就是一个外包团队。就这样在这个团队中度过了我大学时光。 做的都是非常小的项目。 从代码到项目部署。全部流程都做了一遍。项目基本上都是用SpringBoot来做，在学校学的是Struts+Hibernate+Spring。总是不喜欢这种xml的风格。去spring官网看到了SpringBoot还有网上的各种吹捧。会变成主流。所以一直用着SpringBoot。也踏过了许许多多的坑。慢慢的也就踏上了社会，接过几个小项目。 然后也慢慢的喜欢上了看博客。总说好记性不如烂笔头。所以也就自己搭建了一个博客网站。收集一些文章。还有自己的总结。 找到许多特别有意思的博客。网站右边也有友链。 以前总是看视频，也没有怎么做笔记。忘记的也比较快。找到一个比较完整的书单。想好好的都看一看http://www.iocoder.cn/Architecture/books-recommended/","link":"/about/index.html"},{"title":"docker","text":"docker基本命令 docker logs 检查排错。如果启动不起容器，可以试着检查排错 docker安装jenkins及其相关问题解决 https://www.cnblogs.com/youcong/p/10182091.html systemctl stop firewalld.service 关闭防火墙 docker inspect 容器id 查询容器信息 docker stop 容器id 停止容器id docker rm 容器id 删除容器id systemctl restart docker 重启docker容器 docker exec -it 容器ID /bin/bash 进入容器 docker rm $(sudo docker ps -a -q) 删除所有未运行的容器 docker search elasticsearch 搜索镜像文件 docker run 创建并启动一个容器，在run后面加上-d参数，则会创建一个守护式容器在后台运行。 docker ps -a 查看已经创建的容器 docker ps -s 查看已经启动的容器 docker start con_name 启动容器名为con_name的容器 docker stop con_name 停止容器名为con_name的容器 docker rm con_name 删除容器名为con_name的容器 docker rename old_name new_name 重命名一个容器 docker attach con_name 将终端附着到正在运行的容器名为con_name的容器的终端上面去，前提是创建该容器时指定了相应的sh docker logs –tail=”10” 容器名称 查询容器日志信息","link":"/docker/index.html"}],"posts":[{"title":"Effective Java 读书笔记 - 09. 使用try-with-resources语句替代try-finally语句","text":"9. 使用 try-with-resources 语句替代 try-finally 语句 Java 类库中包含许多必须通过调用 close 方法手动关闭的资源。 比如 InputStream，OutputStream 和 java.sql.Connection。 客户经常忽视关闭资源，其性能结果可想而知。 尽管这些资源中有很多使用 finalizer 机制作为安全网，但 finalizer 机制却不能很好地工作（详见第 8 条）。 从以往来看，try-finally 语句是保证资源正确关闭的最佳方式，即使是在程序抛出异常或返回的情况下： 123456789// try-finally - No longer the best way to close resources!static String firstLineOfFile(String path) throws IOException { BufferedReader br = new BufferedReader(new FileReader(path)); try { return br.readLine(); } finally { br.close(); }} 这可能看起来并不坏，但是当添加第二个资源时，情况会变得更糟： 1234567891011121314151617// try-finally is ugly when used with more than one resource!static void copy(String src, String dst) throws IOException { InputStream in = new FileInputStream(src); try { OutputStream out = new FileOutputStream(dst); try { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); } finally { out.close(); } } finally { in.close(); }} 这可能很难相信，但即使是优秀的程序员，大多数时候也会犯错误。首先，我在 Java Puzzlers[Bloch05] 的第 88 页上弄错了，多年来没有人注意到。事实上，2007 年 Java 类库中使用 close 方法的三分之二都是错误的。 即使是用 try-finally 语句关闭资源的正确代码，如前面两个代码示例所示，也有一个微妙的缺陷。 try-with-resources 块和 finally 块中的代码都可以抛出异常。 例如，在 firstLineOfFile 方法中，由于底层物理设备发生故障，对 readLine 方法的调用可能会引发异常，并且由于相同的原因，调用 close 方法可能会失败。 在这种情况下，第二个异常完全冲掉了第一个异常。 在异常堆栈跟踪中没有第一个异常的记录，这可能使实际系统中的调试非常复杂——通常这是你想要诊断问题的第一个异常。 虽然可以编写代码来抑制第二个异常，但是实际上没有人这样做，因为它太冗长了。 当 Java 7 引入了 try-with-resources 语句时，所有这些问题一下子都得到了解决[JLS,14.20.3]。要使用这个构造，资源必须实现 AutoCloseable 接口，该接口由一个返回为 void 的 close 组成。Java 类库和第三方类库中的许多类和接口现在都实现或继承了 AutoCloseable 接口。如果你编写的类表示必须关闭的资源，那么这个类也应该实现 AutoCloseable 接口。 以下是我们的第一个使用 try-with-resources 的示例： 1234567// try-with-resources - the the best way to close resources!static String firstLineOfFile(String path) throws IOException { try (BufferedReader br = new BufferedReader( new FileReader(path))) { return br.readLine(); }} 以下是我们的第二个使用 try-with-resources 的示例： 12345678910// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException { try (InputStream in = new FileInputStream(src); OutputStream out = new FileOutputStream(dst)) { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); }} 不仅 try-with-resources 版本比原始版本更精简，更好的可读性，而且它们提供了更好的诊断。 考虑 firstLineOfFile 方法。 如果调用 readLine 和（不可见）close 方法都抛出异常，则后一个异常将被抑制（suppressed），而不是前者。 事实上，为了保留你真正想看到的异常，可能会抑制多个异常。 这些抑制的异常没有被抛弃， 而是打印在堆栈跟踪中，并标注为被抑制了。 你也可以使用 getSuppressed 方法以编程方式访问它们，该方法在 Java 7 中已添加到的 Throwable 中。 可以在 try-with-resources 语句中添加 catch 子句，就像在常规的 try-finally 语句中一样。这允许你处理异常，而不会在另一层嵌套中污染代码。作为一个稍微有些做作的例子，这里有一个版本的 firstLineOfFile 方法，它不会抛出异常，但是如果它不能打开或读取文件，则返回默认值： 123456789// try-with-resources with a catch clausestatic String firstLineOfFile(String path, String defaultVal) { try (BufferedReader br = new BufferedReader( new FileReader(path))) { return br.readLine(); } catch (IOException e) { return defaultVal; }} 结论很明确：在处理必须关闭的资源时，使用 try-with-resources 语句替代 try-finally 语句。 生成的代码更简洁，更清晰，并且生成的异常更有用。 try-with-resources 语句在编写必须关闭资源的代码时会更容易，也不会出错，而使用 try-finally 语句实际上是不可能的。","link":"/2019/05/29/Effective-Java-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-09-%E4%BD%BF%E7%94%A8try-with-resources%E8%AF%AD%E5%8F%A5%E6%9B%BF%E4%BB%A3try-finally%E8%AF%AD%E5%8F%A5/"},{"title":"Java 运行时的内存划分","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 Java 运行时的内存划分 程序计数器记录当前线程所执行的字节码行号，用于获取下一条执行的字节码。 当多线程运行时，每个线程切换后需要知道上一次所运行的状态、位置。由此也可以看出程序计数器是每个线程私有的。 虚拟机栈虚拟机栈由一个一个的栈帧组成，栈帧是在每一个方法调用时产生的。 每一个栈帧由局部变量区、操作数栈等组成。每创建一个栈帧压栈，当一个方法执行完毕之后则出栈。 如果出现方法递归调用出现死循环的话就会造成栈帧过多，最终会抛出 StackOverflowError。 若线程执行过程中栈帧大小超出虚拟机栈限制，则会抛出 StackOverflowError。 若虚拟机栈允许动态扩展，但在尝试扩展时内存不足，或者在为一个新线程初始化新的虚拟机栈时申请不到足够的内存，则会抛出OutOfMemoryError。 这块内存区域也是线程私有的。 Java 堆Java 堆是整个虚拟机所管理的最大内存区域，所有的对象创建都是在这个区域进行内存分配。 可利用参数 -Xms -Xmx 进行堆内存控制。 这块区域也是垃圾回收器重点管理的区域，由于大多数垃圾回收器都采用分代回收算法，所有堆内存也分为 新生代、老年代，可以方便垃圾的准确回收。 这块内存属于线程共享区域。 方法区(JDK1.7)方法区主要用于存放已经被虚拟机加载的类信息，如常量，静态变量。这块区域也被称为永久代。 可利用参数 -XX:PermSize -XX:MaxPermSize 控制初始化方法区和最大方法区大小。 元数据区(JDK1.8)在 JDK1.8 中已经移除了方法区（永久代），并使用了一个元数据区域进行代替（Metaspace）。 默认情况下元数据区域会根据使用情况动态调整，避免了在 1.7 中由于加载类过多从而出现 java.lang.OutOfMemoryError: PermGen。 但也不能无限扩展，因此可以使用 -XX:MaxMetaspaceSize来控制最大内存。 运行时常量池运行时常量池是方法区的一部分，其中存放了一些符号引用。当 new 一个对象时，会检查这个区域是否有这个符号的引用。 直接内存直接内存又称为 Direct Memory（堆外内存），它并不是由 JVM 虚拟机所管理的一块内存区域。 有使用过 Netty 的朋友应该对这块并内存不陌生，在 Netty 中所有的 IO（nio） 操作都会通过 Native 函数直接分配堆外内存。 它是通过在堆内存中的 DirectByteBuffer 对象操作的堆外内存，避免了堆内存和堆外内存来回复制交换复制，这样的高效操作也称为零拷贝。 既然是内存，那也得是可以被回收的。但由于堆外内存不直接受 JVM 管理，所以常规 GC 操作并不能回收堆外内存。它是借助于老年代产生的 fullGC 顺便进行回收。同时也可以显式调用 System.gc() 方法进行回收（前提是没有使用 -XX:+DisableExplicitGC 参数来禁止该方法）。 值得注意的是：由于堆外内存也是内存，是由操作系统管理。如果应用有使用堆外内存则需要平衡虚拟机的堆内存和堆外内存的使用占比。避免出现堆外内存溢出。 常用参数 通过上图可以直观的查看各个区域的参数设置。 常见的如下： -Xms64m 最小堆内存 64m. -Xmx128m 最大堆内存 128m. -XX:NewSize=30m 新生代初始化大小为30m. -XX:MaxNewSize=40m 新生代最大大小为40m. -Xss=256k 线程栈大小。 -XX:+PrintHeapAtGC 当发生 GC 时打印内存布局。 -XX:+HeapDumpOnOutOfMemoryError 发送内存溢出时 dump 内存。 新生代和老年代的默认比例为 1:2，也就是说新生代占用 1/3的堆内存，而老年代占用 2/3 的堆内存。 可以通过参数 -XX:NewRatio=2 来设置老年代/新生代的比例。","link":"/2019/05/22/Java-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E5%86%85%E5%AD%98%E5%88%92%E5%88%86/"},{"title":"Java 高级 --- 多线程快速入门","text":"多线程快速入门author: RolandLeetags: []categories: java 基础date: 2019-01-02 21:36:00 这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 多线程快速入门1、线程与进程区别 每个正在系统上运行的程序都是一个进程。每个进程包含一到多个线程。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。 所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。 使用线程可以把占据时间长的程序中的任务放到后台去处理，程序的运行速度可能加快，在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下可以释放一些珍贵的资源如内存占用等等。 如果有大量的线程,会影响性能，因为操作系统需要在它们之间切换，更多的线程需要更多的内存空间，线程的中止需要考虑其对程序运行的影响。通常块模型数据是在多个线程间共享的，需要防止线程死锁情况的发生。 总结:进程是所有线程的集合，每一个线程是进程中的一条执行路径。 2、为什么要使用多线程？ （1）、使用多线程可以减少程序的响应时间。单线程如果遇到等待或阻塞，将会导致程序不响应鼠标键盘等操作，使用多线程可以解决此问题，增强程序的交互性。 （2）、与进程相比，线程的创建和切换开销更小，因为线程共享代码段、数据段等内存空间。 （3）、多核CPU，多核计算机本身就具有执行多线程的能力，如果使用单个线程，将无法重复利用计算资源，造成资源的巨大浪费。 （4）、多线程可以简化程序的结构，使程序便于维护，一个非常复杂的进程可以分为多个线程执行。 3、多线程应用场景？ 答:主要能体现到多线程提高程序效率。 举例: 迅雷多线程下载、数据库连接池、分批发送短信等。 4、多线程创建方式第一种、 继承Thread类 重写run方法123456789101112131415161718192021class CreateThread extends Thread { // run方法中编写 多线程需要执行的代码 publicvoid run() { for (inti = 0; i&lt; 10; i++) { System.out.println(&quot;i:&quot; + i); } }}publicclass ThreadDemo { publicstaticvoid main(String[] args) { System.out.println(&quot;-----多线程创建开始-----&quot;); // 1.创建一个线程 CreateThread createThread = new CreateThread(); // 2.开始执行线程 注意 开启线程不是调用run方法，而是start方法 System.out.println(&quot;-----多线程创建启动-----&quot;); createThread.start(); System.out.println(&quot;-----多线程创建结束-----&quot;); }} 调用start方法后，代码并没有从上往下执行，而是有一条新的执行分支 注意：画图演示多线程不同执行路径。 第二种、实现Runnable接口,重写run方法12345678910111213141516171819202122class CreateRunnable implements Runnable { @Override publicvoid run() { for (inti = 0; i&lt; 10; i++) { System.out.println(&quot;i:&quot; + i); } }}publicclass ThreadDemo2 { publicstaticvoid main(String[] args) { System.out.println(&quot;-----多线程创建开始-----&quot;); // 1.创建一个线程 CreateRunnable createThread = new CreateRunnable(); // 2.开始执行线程 注意 开启线程不是调用run方法，而是start方法 System.out.println(&quot;-----多线程创建启动-----&quot;); Thread thread = new Thread(createThread); thread.start(); System.out.println(&quot;-----多线程创建结束-----&quot;); }} 第三种、使用匿名内部类方式12345678910System.out.println(&quot;-----多线程创建开始-----&quot;); Thread thread = new Thread(new Runnable() { public void run() { for (int i = 0; i&lt; 10; i++) { System.out.println(&quot;i:&quot; + i); } } }); thread.start(); System.out.println(&quot;-----多线程创建结束-----&quot;); 5、使用继承Thread类还是使用实现Runnable接口好？ 使用实现实现Runnable接口好，原因实现了接口还可以继续继承，继承了类不能再继承。 6、启动线程是使用调用start方法还是run方法？ 开始执行线程 注意 开启线程不是调用run方法，而是start方法调用run知识使用实例调用方法。 7、获取线程对象以及名称| 常用线程api方法 || ——– | :—– || start() | 启动线程 || currentThread() | 获取当前线程对象| getID()| 获取当前线程ID Thread-编号 该编号从0开始| getName()| 获取当前线程名称| sleep(long mill) | 休眠线程| Stop（） | 停止线程,| 常用线程构造函数 || Thread（） | 分配一个新的 Thread 对象| Thread（String name）| 分配一个新的 Thread对象，具有指定的 name正如其名。| Thread（Runable r）| 分配一个新的 Thread对象| Thread（Runable r, String name） | 分配一个新的 Thread对象 8、守护线程 Java中有两种线程，一种是用户线程，另一种是守护线程。 用户线程是指用户自定义创建的线程，主线程停止，用户线程不会停止 守护线程当进程不存在或主线程停止，守护线程也会被停止。 使用setDaemon(true)方法设置为守护线程 123456789101112131415161718192021222324252627282930public class DaemonThread { public static void main(String[] args) { Thread thread = new Thread(new Runnable() { @Override public void run() { while (true) { try { Thread.sleep(100); } catch (Exception e) { // TODO: handle exception } System.out.println(&quot;我是子线程...&quot;); } } }); thread.setDaemon(true); thread.start(); for (int i = 0; i &lt; 10; i++) { try { Thread.sleep(100); } catch (Exception e) { } System.out.println(&quot;我是主线程&quot;); } System.out.println(&quot;主线程执行完毕!&quot;); }} 9、多线程运行状态 线程从创建、运行到结束总是处于下面五个状态之一：新建状态、就绪状态、运行状态、阻塞状态及死亡状态 新建状态 当用new操作符创建一个线程时， 例如new Thread(r)，线程还没有开始运行，此时线程处在新建状态。 当一个线程处于新生状态时，程序还没有开始运行线程中的代码 就绪状态 一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的start()方法。当线程对象调用start()方法即启动了线程，start()方法创建线程运行的系统资源，并调度线程运行run()方法。当start()方法返回后，线程就处于就绪状态。 处于就绪状态的线程并不一定立即运行run()方法，线程还必须同其他线程竞争CPU时间，只有获得CPU时间才可以运行线程。因为在单CPU的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态。因此此时可能有多个线程处于就绪状态。对多个处于就绪状态的线程是由Java运行时系统的线程调度程序(thread scheduler)来调度的。 运行状态 当线程获得CPU时间后，它才进入运行状态，真正开始执行run()方法.阻塞状态线程运行过程中，可能由于各种原因进入阻塞状态: 1&gt;线程通过调用sleep方法进入睡眠状态； 2&gt;线程调用一个在I/O上被阻塞的操作，即该操作在输入输出操作完成之前不会返回到它的调用者； 3&gt;线程试图得到一个锁，而该锁正被其他线程持有； 4&gt;线程在等待某个触发条件； 死亡状态 有两个原因会导致线程死亡： - - 1) run方法正常退出而自然死亡， - - 2) 一个未捕获的异常终止了run方法而使线程猝死。 为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用isAlive方法。如果是可运行或被阻塞，这个方法返回true； 如果线程仍旧是new状态且不是可运行的， 或者线程死亡了，则返回false. join()方法作用 当在主线程当中执行到t1.join()方法时，就认为主线程应该把执行权让给t1 创建一个线程，子线程执行完毕后，主线程才能执行。 1234567891011121314151617181920212223242526Thread t1 = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { try { Thread.sleep(10); } catch (Exception e) { } System.out.println(Thread.currentThread().getName() + &quot;i:&quot; + i); } } }); t1.start(); // 当在主线程当中执行到t1.join()方法时，就认为主线程应该把执行权让给t1 t1.join(); for (int i = 0; i &lt; 10; i++) { try { Thread.sleep(10); } catch (Exception e) { } System.out.println(&quot;main&quot; + &quot;i:&quot; + i); } 优先级 现代操作系统基本采用时分的形式调度运行的线程，线程分配得到的时间片的多少决定了线程使用处理器资源的多少，也对应了线程优先级这个概念。在JAVA线程中，通过一个int priority来控制优先级，范围为1-10，其中10最高，默认值为5。下面是源码（基于1.8）中关于priority的一些量和方法。 12345678910111213141516171819202122class PrioritytThread implements Runnable { public void run() { for (int i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().toString() + &quot;---i:&quot; + i); } }}public class ThreadDemo4 { public static void main(String[] args) { PrioritytThread prioritytThread = new PrioritytThread(); Thread t1 = new Thread(prioritytThread); Thread t2 = new Thread(prioritytThread); t1.start(); // 注意设置了优先级， 不代表每次都一定会被执行。 只是CPU调度会有限分配 t1.setPriority(10); t2.start(); }} Yield方法Thread.yield()方法的作用：暂停当前正在执行的线程，并执行其他线程。（可能没有效果）yield()让当前正在运行的线程回到可运行状态，以允许具有相同优先级的其他线程获得运行的机会。因此，使用yield()的目的是让具有相同优先级的线程之间能够适当的轮换执行。但是，实际中无法保证yield()达到让步的目的，因为，让步的线程可能被线程调度程序再次选中。结论：大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。 总结 1.进程与线程的区别？ 答:进程是所有线程的集合，每一个线程是进程中的一条执行路径，线程只是一条执行路径。 2.为什么要用多线程？ 答:提高程序效率 3.多线程创建方式？ 答:继承Thread或Runnable 接口。 4.是继承Thread类好还是实现Runnable接口好？ 答:Runnable接口好，因为实现了接口还可以继续继承。继承Thread类不能再继承。 5.你在哪里用到了多线程？ 答:主要能体现到多线程提高程序效率。 举例:分批发送短信、迅雷多线程下载等。 总结不易，给个关注吧 https://github.com/yunlongn","link":"/2019/01/02/Java-%E9%AB%98%E7%BA%A7-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-1/"},{"title":"Java内存区域与Java内存模型","text":"Java内存区域Java虚拟机在运行程序时把其自动管理的内存划分为以下几个区域。这个区域里的一些数据在JVM启动的时候创建，在JVM退出的时候销毁。而其他的数据依赖于每一个线程，在线程创建时创建，在线程退出时销毁。 1. 方法区（Method Area）：方法区又称Non-Heap（非堆）,主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。简单说方法区用来存储类型的元数据信息，一个.class文件是类被java虚拟机使用之前的表现形式，一旦这个类要被使用，java虚拟机就会对其进行装载、连接（验证、准备、解析）和初始化。而装载（后的结果就是由.class文件转变为方法区中的一段特定的数据结构。这个数据结构会存储如下信息： 类型信息 这个类型的全限定名 这个类型的直接超类的全限定名 这个类型是类类型还是接口类型 这个类型的访问修饰符 任何直接超接口的全限定名的有序列表 字段信息 字段名 字段类型 字段的修饰符 方法信息 方法名 方法返回类型 方法参数的数量和类型（按照顺序） 方法的修饰 其他信息 除了常量以外的所有类（静态）变量 一个指向ClassLoader的指针 一个指向Class对象的指针 常量池（常量数据以及对其他类型的符号引用） JVM为每个已加载的类型都维护一个常量池。常量池就是这个类型用到的常量的一个有序集合，包括实际的常量(string,integer,和floating point常量)和对类型，域和方法的符号引用。池中的数据项象数组项一样，是通过索引访问的。 每个类的这些元数据，无论是在构建这个类的实例还是调用这个类某个对象的方法，都会访问方法区的这些元数据。 构建一个对象时，JVM会在堆中给对象分配空间，这些空间用来存储当前对象实例属性以及其父类的实例属性（而这些属性信息都是从方法区获得），注意，这里并不是仅仅为当前对象的实例属性分配空间，还需要给父类的实例属性分配，到此其实我们就可以回答第一个问题了，即实例化父类的某个子类时，JVM也会同时构建父类的一个对象。从另外一个角度也可以印证这个问题：调用当前类的构造方法时，首先会调用其父类的构造方法直到Object，而构造方法的调用意味着实例的创建，所以子类实例化时，父类肯定也会被实例化。 类变量被类的所有实例共享，即使没有类实例时你也可以访问它。这些变量只与类相关，所以在方法区中，它们成为类数据在逻辑上的一部分。在JVM使用一个类之前，它必须在方法区中为每个non-final类变量分配空间。 方法区主要有以下几个特点： 1、方法区是线程安全的。由于所有的线程都共享方法区，所以，方法区里的数据访问必须被设计成线程安全的。例如，假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待 2、方法区的大小不必是固定的，JVM可根据应用需要动态调整。同时，方法区也不一定是连续的，方法区可以在一个堆(甚至是JVM自己的堆)中自由分配。 3、方法区也可被垃圾收集，当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集 可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。 对于习惯在HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（PermanentGeneration），本质上两者并不等价，仅仅是因为HotSpot 虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 2. JVM堆（Java Heap）：Java 堆也是属于线程共享的内存区域，它在虚拟机启动时创建，是Java 虚拟机所管理的内存中最大的一块，主要用于存放对象实例，几乎所有的对象实例都在这里分配内存，注意Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做GC 堆，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 堆的大小可以通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代； 新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及SurvivorSpace的大小。 老年代：用于存放经过多次新生代GC仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：1、大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。2、大的数组对象，且数组中无引用外部对象。 老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 3. 虚拟机栈(Java Virtual Machine Stacks)：线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。 动画是由一帧一帧图片连续切换结果的结果而产生的，其实虚拟机的运行和动画也类似，每个在虚拟机中运行的程序也是由许多的帧的切换产生的结果，只是这些帧里面存放的是方法的局部变量，操作数栈，动态链接，方法返回地址和一些额外的附加信息组成。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 4. 本地方法栈(Native Method Stacks)：本地方法栈（Native MethodStacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native 方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot 虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 5. 程序计数器(Program Counter Register)：程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie 方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java内存模型Java内存模型(Java Memory Model，简称JMM)的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。 Java内存模型中规定: 1. 线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量 不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成 这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分,这两者基本上是没有关系的，如果两者一不定要勉强对就起来，那从变量，主内存，工作内存的定义来看，主内存对应Java堆中的对象实例数据部分，工作内存对应于虚拟机栈中的部分区域。 重排序在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 as-if-serial语义as-if-serial语义的意思是，所有的操作均可以为了优化而被重排序，但是你必须要保证重排序后执行的结果不能被改变，编译器、runtime、处理器都必须遵守as-if-serial语义。注意as-if-serial只保证单线程环境，多线程环境下无效。重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。 原子性、可见性与有序性原子性：一个操作或者多个操作要么全部执行要么全部不执行； 可见性：当多个线程同时访问一个共享变量时，如果其中某个线程更改了该共享变量，其他线程应该可以立刻看到这个改变； 有序性：程序的执行要按照代码的先后顺序执行； happens-before原则Java内存模型中定义的两项操作之间的次序关系，如果说操作A先行发生于操作B，操作A产生的影响能被操作B观察到，“影响”包含了修改了内存中共享变量的值、发送了消息、调用了方法等。 下面是Java内存模型下一些”天然的“happens-before关系，这些happens-before关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随意地重排序。 a.程序次序规则(Pragram Order Rule)：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环结构。 b.管程锁定规则(Monitor Lock Rule)：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面“是指时间上的先后顺序。 c.volatile变量规则(Volatile Variable Rule)：对一个volatile变量的写操作先行发生于后面对这个变量的读取操作，这里的”后面“同样指时间上的先后顺序。 d.线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作。 e.线程终于规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束，Thread.isAlive()的返回值等作段检测到线程已经终止执行。 f.线程中断规则(Thread Interruption Rule)：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测是否有中断发生。 g.对象终结规则(Finalizer Rule)：一个对象初始化完成(构造方法执行完成)先行发生于它的finalize()方法的开始。 g.传递性(Transitivity)：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 一个操作”时间上的先发生“不代表这个操作会是”先行发生“，那如果一个操作”先行发生“是否就能推导出这个操作必定是”时间上的先发生 “呢？也是不成立的，一个典型的例子就是指令重排序。所以时间上的先后顺序与happens-before原则之间基本没有什么关系，所以衡量并发安全问题一切必须以happens-before 原则为准。","link":"/2019/07/11/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8EJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"Java编程技巧","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 如何在整数左填充0问题如何在整数左填充0举例 1 = “0001” 答案一，String.format1String.format(&quot;%05d&quot;, yournumber); 用0填充，总长度为5https://docs.oracle.com/javase/8/docs/api/java/util/Formatter.html 答案二，ApacheCommonsLanguage如果需要在Java 1.5前使用，可以利用 Apache Commons Language 方法 1org.apache.commons.lang.StringUtils.leftPad(String str, int size, '0') 答案三，DecimalFormat12345678910import java.text.DecimalFormat;class TestingAndQualityAssuranceDepartment{ public static void main(String [] args) { int x=1; DecimalFormat df = new DecimalFormat(&quot;00&quot;); System.out.println(df.format(x)); }} 答案四，自己实现如果效率很重要的话，相比于 String.format 函数的可以自己实现 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @param in The integer value * @param fill The number of digits to fill * @return The given value left padded with the given number of digits */public static String lPadZero(int in, int fill){ boolean negative = false; int value, len = 0; if(in &gt;= 0){ value = in; } else { negative = true; value = - in; in = - in; len ++; } if(value == 0){ len = 1; } else{ for(; value != 0; len ++){ value /= 10; } } StringBuilder sb = new StringBuilder(); if(negative){ sb.append('-'); } for(int i = fill; i &gt; len; i--){ sb.append('0'); } sb.append(in); return sb.toString(); } 效率对比 12345678910111213141516171819202122public static void main(String[] args) { Random rdm; long start; // Using own function rdm = new Random(0); start = System.nanoTime(); for(int i = 10000000; i != 0; i--){ lPadZero(rdm.nextInt(20000) - 10000, 4); } System.out.println(&quot;Own function: &quot; + ((System.nanoTime() - start) / 1000000) + &quot;ms&quot;); // Using String.format rdm = new Random(0); start = System.nanoTime(); for(int i = 10000000; i != 0; i--){ String.format(&quot;%04d&quot;, rdm.nextInt(20000) - 10000); } System.out.println(&quot;String.format: &quot; + ((System.nanoTime() - start) / 1000000) + &quot;ms&quot;);} 结果 自己的实现：1697ms String.format：38134ms 答案，Google GuavaMaven： 12345&lt;dependency&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;version&gt;14.0.1&lt;/version&gt;&lt;/dependency&gt; 样例： 12Strings.padStart(&quot;7&quot;, 3, '0') returns &quot;007&quot;Strings.padStart(&quot;2020&quot;, 3, '0') returns &quot;2020&quot; 注意：Guava 是非常有用的库，它提供了很多有用的功能，包括了Collections, Caches, Functional idioms, Concurrency, Strings, Primitives, Ranges, IO, Hashing, EventBus等 如何用一行代码初始化一个ArrayList问题为了测试，我需要临时快速创建一个list。一开始我这样做： 1234ArrayList&lt;String&gt; places = new ArrayList&lt;String&gt;();places.add(&quot;Buenos Aires&quot;);places.add(&quot;Córdoba&quot;);places.add(&quot;La Plata&quot;); 之后我重构了下 12ArrayList&lt;String&gt; places = new ArrayList&lt;String&gt;( Arrays.asList(&quot;Buenos Aires&quot;, &quot;Córdoba&quot;, &quot;La Plata&quot;)); 是否有更加简便的方法呢？ 回答常见方式实际上，也许“最好”的方式，就是你写的这个方式，因为它不用再创建新的List: 1234ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;A&quot;);list.add(&quot;B&quot;);list.add(&quot;C&quot;); 只是这个方式看上去要多写些代码，让人郁闷 匿名内部类当然，还有其他方式，例如,写一个匿名内部类，然后在其中做初始化（也被称为 brace initialization）： 12345ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;() {{ add(&quot;A&quot;); add(&quot;B&quot;); add(&quot;C&quot;);}}; 但是，我不喜欢这个方式。只是为了做个初始化，却要在ArrayList的同一行后面加这么一坨代码。 Arrays.asList1List&lt;String&gt; places = Arrays.asList(&quot;Buenos Aires&quot;, &quot;Córdoba&quot;, &quot;La Plata&quot;); Collections.singletonList1List&lt;String&gt; places = Collections.singletonList(&quot;Buenos Aires&quot;); 注意：后面的这两种方式，得到的是一个定长的List(如果add操作会抛异常）。如果你需要一个不定长的List,可以这样做： 12ArrayList&lt;String&gt; places = new ArrayList&lt;&gt;(Arrays.asList(&quot;Buenos Aires&quot;, &quot;Córdoba&quot;, &quot;La Plata&quot;)); 为什么在java中存放密码更倾向于char[]而不是String问题在Swing中，password字段有一个getPassword()方法（返回char[]），而不是通常的getText()方法(返回String字符串)。同样的，我看到一个建议说不要使用字符串处理密码。为什么在涉及passwords时，都说字符串会对安全构成威胁？感觉使用char[]不是那么的方便。 回答String是不可变的。虽然String加载密码之后可以把这个变量扔掉，但是字符串并不会马上被GC回收，一但进程在GC执行到这个字符串之前被dump，dump出的的转储中就会含有这个明文的字符串。那如果我去“修改”这个字符串，比如把它赋一个新值，那么是不是就没有这个问题了？答案是否定的，因为String本身是不可修改的，任何基于String的修改函数都是返回一个新的字符串，原有的还会在内存里。 然而对于数组，你可以在抛弃它之前直接修改掉它里面的内容或者置为乱码，密码就不会存在了。但是如果你什么也不做直接交给gc的话，也会存在上面一样的问题。 所以，这是一个安全性的问题–但是，即使使用char[]也仅仅是降低了攻击者攻击的机会，而且仅仅对这种特定的攻击有效。 初始化静态map问题怎么在Java中初始化一个静态的map 我想到的两种方法如下，大家是否有更好的建议呢？ 方法一：static初始化器 方法二：实例初始化（匿名子类） 下面是描述上面两种方法的例子 12345678910111213141516import java.util.HashMap;import java.util.Map;public class Test{ private static final Map&lt;Integer, String&gt; myMap = new HashMap&lt;Integer, String&gt;(); static { myMap.put(1, &quot;one&quot;); myMap.put(2, &quot;two&quot;); } private static final Map&lt;Integer, String&gt; myMap2 = new HashMap&lt;Integer, String&gt;(){ { put(1, &quot;one&quot;); put(2, &quot;two&quot;); } };} 答案答案1匿名子类初始化器是java的语法糖，我搞不明白为什么要用匿名子类来初始化，而且，如果类是final的话，它将不起作用 我使用static初始化器来创建一个固定长度的静态map 123456789public class Test{ private static final Map&lt;Integer, String&gt; myMap; static{ Map&lt;Integer, String&gt; aMap = ...; aMap.put(1,&quot;one&quot;); aMap.put(2,&quot;two&quot;); myMap = Collections.unmodifiableMap(aMap); }} 答案2我喜欢用Guava（是 Collection 框架的增强）的方法初始化一个静态的，不可改变的map 12345static final Map&lt;Integer, String&gt; MY_MAP = ImmutableMap.of( 1, &quot;one&quot;, 2, &quot;two&quot;) 当map的 entry个数超过5个时，你就不能使用ImmutableMap.of。可以试试ImmutableMap.bulider() 1234567static final Map&lt;Integer, String&gt; MY_MAP = ImmutableMap.&lt;Integer, String&gt;builder() .put(1, &quot;one&quot;) .put(2, &quot;two&quot;) // ... .put(15, &quot;fifteen&quot;) .build(); 给3个布尔变量，当其中有2个或者2个以上为true才返回true问题给3个boolean变量，a,b,c，当其中有2个或2个以上为true时才返回true？ 最笨的方法：1234567891011boolean atLeastTwo(boolean a, boolean b, boolean c) { if ((a &amp;&amp; b) || (b &amp;&amp; c) || (a &amp;&amp; c)) { return true; } else { return false; }} 优雅解法11return a ? (b || c) : (b &amp;&amp; c); 优雅解法21return (a==b) ? a : c; 优雅解法31return a ^ b ? c : a 优雅解法41return a ? (b || c) : (b &amp;&amp; c); 获取完整的堆栈信息 问题捕获了异常后，如何获取完整的堆栈轨迹（stack trace） 回答1String fullStackTrace = org.apache.commons.lang.exception.ExceptionUtils.getFullStackTrace(e) 1Thread.currentThread().getStackTrace();","link":"/2019/05/22/Java%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"},{"title":"MyBatis二级缓存使用","text":"注意点： 在最新的3.x版本，实现二级缓存的配置也有了一些改变。 官方建议在service使用缓存，但是你也可以直接在mapper层缓存，这里的二级缓存就是直接在Mapper层进行缓存操作 Mybatis的二级缓存实现也十分简单，只要在springboot的配置文件打开二级缓存，即123mybatis-plus: configuration: cache-enabled: true 缓存接口的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class MybatisRedisCache implements Cache { // 读写锁 private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(true); //这里使用了redis缓存，使用springboot自动注入 @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; private String id; public MybatisRedisCache(final String id) { if (id == null) { throw new IllegalArgumentException(&quot;Cache instances require an ID&quot;); } this.id = id; } @Override public String getId() { return this.id; } @Override public void putObject(Object key, Object value) { if (redisTemplate == null) { //由于启动期间注入失败，只能运行期间注入，这段代码可以删除 redisTemplate = (RedisTemplate&lt;String, Object&gt;) ApplicationContextRegister.getApplicationContext().getBean(&quot;RedisTemplate&quot;); } if (value != null) { redisTemplate.opsForValue().set(key.toString(), value); } } @Override public Object getObject(Object key) { try { if (key != null) { return redisTemplate.opsForValue().get(key.toString()); } } catch (Exception e) { log.error(&quot;缓存出错 &quot;); } return null; } @Override public Object removeObject(Object key) { if (key != null) { redisTemplate.delete(key.toString()); } return null; } @Override public void clear() { log.debug(&quot;清空缓存&quot;); if (redisTemplate == null) { redisTemplate = (RedisTemplate&lt;String, Object&gt;) ApplicationContextRegister.getApplicationContext().getBean(&quot;functionDomainRedisTemplate&quot;); } Set&lt;String&gt; keys = redisTemplate.keys(&quot;*:&quot; + this.id + &quot;*&quot;); if (!CollectionUtils.isEmpty(keys)) { redisTemplate.delete(keys); } } @Override public int getSize() { Long size = redisTemplate.execute((RedisCallback&lt;Long&gt;) RedisServerCommands::dbSize); return size.intValue(); } @Override public ReadWriteLock getReadWriteLock() { return this.readWriteLock; }} mapper.xml文件声明缓存，这里3.x只需要这样配置1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.zsy.mapper.CarouselMapper&quot;&gt; &lt;cache-ref namespace=&quot;com.zsy.mapper.CarouselMapper&quot;/&gt;&lt;/mapper&gt; Mapper接口使用注解123@Repository@CacheNamespace(implementation=MybatisRedisCache.class,eviction=MybatisRedisCache.class)public interface CarouselMapper extends BaseMapper&lt;Carousel&gt; {}","link":"/2019/03/27/MyBatis-plus%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8/"},{"title":"Mybatis Plus的分页插件的小问题","text":"一、前言在spring Boot环境下快速应用Mybatis plus，篇幅中我们使用了BaseMapper，从而可以直接使用selectPage这样的分页，但如果你够细心的话，返回的数据确实是分页后的数据，但在控制台打印的SQL语句其实并没有真正的物理分页，而是通过缓存来获得全部数据中再进行的分页，这样对于大数据量操作时是不可取的，那么接下来就叙述一下，真正实现物理分页的方法。 二、分页配置官方在分页插件上如是描述：自定义查询语句分页（自己写sql/mapper），也就是针对自己在Mapper中写的方法，但经过测试，如果不配置分页插件，其默认采用的分页为RowBounds的分页即逻辑分页，也就是先把数据记录全部查询出来,然在再根据offset和limit截断记录返回（数据量大的时候会造成内存溢出），故而不可取，而通过分页插件的配置即可达到物理分页效果。 新建一个MybatisPlusConfig配置类文件，代码如下所示： 123456789101112131415161718192021222324252627package com.szss.admin.config.mybatisplus; import com.baomidou.mybatisplus.plugins.PaginationInterceptor;import org.mybatis.spring.annotation.MapperScan;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration; /** * @author Allen * @date 2018/3/14 */@Configuration@MapperScan(&quot;com.szss.admin.dao.*&quot;)public class MybatisPlusConfig { /** * mybatis-plus分页插件&lt;br&gt; * 文档：http://mp.baomidou.com&lt;br&gt; */ @Bean public PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); return paginationInterceptor; } } 至此再次对之前代码进行测试，就会发现本次生成的SQL语句有所变化，不再是直接查询所有结果而进行的逻辑分页，而是会自动根据数据库生成对应的物理分页SQL语句，具体可自行在控制台查看SQL体现，本例示例如下： 1234562018-03-14 12:27:04.459 DEBUG 6008 --- [ XNIO-2 task-7] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Preparing: SELECT COUNT(1) FROM admin_role WHERE deleted = 0 2018-03-14 12:27:04.474 DEBUG 6008 --- [ XNIO-2 task-7] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Parameters: 2018-03-14 12:27:04.487 DEBUG 6008 --- [ XNIO-2 task-7] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Preparing: WITH query AS (SELECT TOP 100 PERCENT ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __row_number__, ID AS id,role,name,description,enabled,deleted,creator_id AS creatorId,creator,date_created AS dateCreated,modifier_id AS modifierId,modifier,last_modified AS lastModified FROM admin_role WHERE deleted=0) SELECT * FROM query WHERE __row_number__ BETWEEN 6 AND 10 ORDER BY __row_number__ 2018-03-14 12:27:04.488 DEBUG 6008 --- [ XNIO-2 task-7] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Parameters: 2018-03-14 12:27:04.499 DEBUG 6008 --- [ XNIO-2 task-7] com.szss.admin.dao.RoleDAO.selectPage : &lt;== Total: 3 而在没有配置分页属性时执行的SQL信息输出内容为： 12342018-03-14 15:03:50.525 DEBUG 6892 --- [ XNIO-2 task-5] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Preparing: SELECT ID AS id,role,name,description,enabled,deleted,creator_id AS creatorId,creator,date_created AS dateCreated,modifier_id AS modifierId,modifier,last_modified AS lastModified FROM admin_role WHERE deleted=0 2018-03-14 15:03:50.540 DEBUG 6892 --- [ XNIO-2 task-5] com.szss.admin.dao.RoleDAO.selectPage : ==&gt; Parameters: 2018-03-14 15:03:50.557 DEBUG 6892 --- [ XNIO-2 task-5] com.szss.admin.dao.RoleDAO.selectPage : &lt;== Total: 8 通过swagger进行数据测试时返回的展示结果是一样的，但是控制台输出的SQL语句明显有所区别，当启用分页插件时，首先会进行一个count的总记录条件查询，然后再进行物理分页操作，查询结果为3条记录，而默认是直接获取8条全部数据在由Mybatis进行逻辑分页，这个在大数据量操作时显然是不可取的。 三、分页应用由于我们在DAO层继承了BaseMapper接口，而我们所需要的就是通过Service层来继承ServiceImpl接口，具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.szss.admin.service; import java.util.Date; import org.springframework.beans.BeanUtils;import org.springframework.stereotype.Service; import com.baomidou.mybatisplus.mapper.EntityWrapper;import com.baomidou.mybatisplus.plugins.Page;import com.baomidou.mybatisplus.service.impl.ServiceImpl;import com.szss.admin.dao.RoleDAO;import com.szss.admin.model.domain.RoleDO;import com.szss.admin.model.param.ListRoleParam;import com.szss.admin.model.param.RoleParam; /** * 角色服务 * * @author Allen * @date 2018/3/7 */@Servicepublic class RoleService extends ServiceImpl&lt;RoleDAO, RoleDO&gt; { /** * 新增角色信息 * @param roleParam 角色参数 * @return 是否成功 */ public Boolean insert(RoleParam roleParam) { RoleDO roleDO = new RoleDO(); roleParam.setDateCreated(new Date()); BeanUtils.copyProperties(roleParam, roleDO); return insert(roleDO); } /** * 更新角色信息 * @param roleParam 角色参数 * @return 是否成功 */ public Boolean update(RoleParam roleParam) { RoleDO roleDO = selectById(roleParam.getId()); roleParam.setLastModified(new Date()); BeanUtils.copyProperties(roleParam, roleDO); return updateById(roleDO); } /** * 查询角色列表(分页) * * @param roleParam 角色参数 * @return 查询角色分页列表 */ public Page&lt;RoleDO&gt; selectListPage(ListRoleParam roleParam) { RoleDO roleDO = new RoleDO(); BeanUtils.copyProperties(roleParam, roleDO); Page&lt;RoleDO&gt; page = new Page&lt;RoleDO&gt;((int)roleParam.getPi(), (int)roleParam.getPs()); EntityWrapper&lt;RoleDO&gt; eWrapper = new EntityWrapper&lt;RoleDO&gt;(roleDO); Page&lt;RoleDO&gt; roleDOList = selectPage(page, eWrapper); return roleDOList; } } 这样我们就可以直接使用ServiceImpl实现类中的基本Insert、Update、Delete等操作了，而无须在Service层注入DAO来实现数据库的DML操作了。同时这里selectPage返回的是Page对象与DAO中返回的List对象是有所不同的，等于已经进行了翻页方法的封装，将需要的Page结果直接回传给页面，省去自己编写分页的操作。 四、注意事项 1、上述中在查询构造器EW中，我们采用的是new EntityWrapper(roleDO)方法，而不是大多数示例的new EntityWrapper().eq(“name”,”张三”)的这种方式，因为这样就意味着前台name参数是必须要传值的，而在我们大多数设置查询时，用户输入的查询条件是不固定及不明确的，所以本示例中采用如上方法来进行动态生成查询条件，当roleDO前台未传入值时，不会生成对应的where条件，而一旦使用了eq这样的方法，无论前台是否传值都会生成对应的where条件导致操作异常的错误。 2、在使用上述方法时domain中的RoleDO通过开启AR(ActiveRecord)模式（&lt;Spring Boot环境下Mybatis Plus的快速应用&gt;已有说明），即RoleDO需要继承Model方法，可直接使用roleDO来进行基本CRUD和分页查询操作。 3、当开启AR(ActiveRecord)模式后，对于service层就无须再继承ServiceImpl接口了，可直接进行DML和DQL操作，具体示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.szss.admin.service; import com.baomidou.mybatisplus.mapper.EntityWrapper;import com.baomidou.mybatisplus.plugins.Page;import com.baomidou.mybatisplus.service.impl.ServiceImpl;import com.szss.admin.dao.RoleDAO;import com.szss.admin.model.domain.RoleDO;import com.szss.admin.model.dto.ListRoleDTO;import com.szss.admin.model.dto.PageInfo;import com.szss.admin.model.dto.RestCodeEnum;import com.szss.admin.model.dto.RoleDTO;import com.szss.admin.model.param.ListRoleParam;import com.szss.admin.model.param.RoleParam;import java.sql.Timestamp;import java.util.ArrayList;import java.util.Date;import java.util.List;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.util.CollectionUtils; /** * 角色服务 * * @author Allen * @date 2018/3/7 */@Servicepublic class RoleService /**extends ServiceImpl&lt;RoleDAO, RoleDO&gt;*/ { /** * 新增角色信息 * * @param roleParam 角色信息 */ public void insert(RoleParam roleParam) { roleParam.setDateCreated(new Date()); RoleDO roleDO = new RoleDO(); BeanUtils.copyProperties(roleParam, roleDO); roleDO.insert(); } /** * 更新角色信息 * * @param roleParam 角色信息 */ public void update(RoleParam roleParam) { RoleDO roleDO = new RoleDO(); roleParam.setLastModified(new Date()); BeanUtils.copyProperties(roleParam, roleDO); roleDO.updateById(); } /** * 查询角色列表(分页) * * @param roleParam * @return */ public Page&lt;RoleDO&gt; selectPage(ListRoleParam roleParam) { RoleDO roleDO = new RoleDO(); BeanUtils.copyProperties(roleParam, roleDO); Page&lt;RoleDO&gt; page = new Page&lt;RoleDO&gt;(roleParam.getPi().intValue(), roleParam.getPs().intValue()); EntityWrapper&lt;RoleDO&gt; eWrapper = new EntityWrapper&lt;RoleDO&gt;(roleDO); Page&lt;RoleDO&gt; roleDOList = roleDO.selectPage(page,eWrapper); return roleDOList; } } 至此就可以看出AR与非AR之间的区别了，当你引用了Model以后就等于已经实现了相关CRUD和分页查询操作了。至于喜欢哪种方式或哪种更适合你，可自由根据情况进行自主选择。","link":"/2019/05/08/Mybatis-Plus%E7%9A%84%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98/"},{"title":"OOM 的介绍","text":"OOM 分析Java 堆内存溢出在 Java 堆中只要不断的创建对象，并且 GC-Roots 到对象之间存在引用链，这样 JVM 就不会回收对象。 只要将-Xms(最小堆),-Xmx(最大堆) 设置为一样禁止自动扩展堆内存。 当使用一个 while(true) 循环来不断创建对象就会发生 OutOfMemory，还可以使用 -XX:+HeapDumpOnOutOfMemoryError 当发生 OOM 时会自动 dump 堆栈到文件中。 伪代码: 123456public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(10) ; while (true){ list.add(&quot;1&quot;) ; }} 当出现 OOM 时可以通过工具来分析 GC-Roots 引用链 ，查看对象和 GC-Roots 是如何进行关联的，是否存在对象的生命周期过长，或者是这些对象确实改存在的，那就要考虑将堆内存调大了。 12345678910111213141516Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at com.crossoverjie.oom.HeapOOM.main(HeapOOM.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Process finished with exit code 1 java.lang.OutOfMemoryError: Java heap space表示堆内存溢出。 更多内存溢出相关实战请看这里：强如 Disruptor 也发生内存溢出？ MetaSpace (元数据) 内存溢出 JDK8 中将永久代移除，使用 MetaSpace 来保存类加载之后的类信息，字符串常量池也被移动到 Java 堆。 PermSize 和 MaxPermSize 已经不能使用了，在 JDK8 中配置这两个参数将会发出警告。 JDK 8 中将类信息移到到了本地堆内存(Native Heap)中，将原有的永久代移动到了本地堆中成为 MetaSpace ,如果不指定该区域的大小，JVM 将会动态的调整。 可以使用 -XX:MaxMetaspaceSize=10M 来限制最大元数据。这样当不停的创建类时将会占满该区域并出现 OOM。 123456789101112131415public static void main(String[] args) { while (true){ Enhancer enhancer = new Enhancer() ; enhancer.setSuperclass(HeapOOM.class); enhancer.setUseCache(false) ; enhancer.setCallback(new MethodInterceptor() { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { return methodProxy.invoke(o,objects) ; } }); enhancer.create() ; }} 使用 cglib 不停的创建新类，最终会抛出: 1234567891011Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at net.sf.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:459) at net.sf.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:336) ... 11 moreCaused by: java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) ... 16 more 注意：这里的 OOM 伴随的是 java.lang.OutOfMemoryError: Metaspace 也就是元数据溢出。","link":"/2019/05/22/OOM-%E7%9A%84%E4%BB%8B%E7%BB%8D/"},{"title":"Spring 完美配置跨域请求","text":"在SpringBoot2.0 上的跨域 用以下代码配置 即可完美解决你的前后端跨域请求问题 在SpringBoot2.0 上的跨域 用以下代码配置 即可完美解决你的前后端跨域请求问题123456789101112131415161718192021222324252627282930313233import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * 实现基本的跨域请求 * @author linhongcun * */@Configurationpublic class CorsConfig { @Bean public CorsFilter corsFilter() { final UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource(); final CorsConfiguration corsConfiguration = new CorsConfiguration(); /*是否允许请求带有验证信息*/ corsConfiguration.setAllowCredentials(true); /*允许访问的客户端域名*/ corsConfiguration.addAllowedOrigin(&quot;*&quot;); /*允许服务端访问的客户端请求头*/ corsConfiguration.addAllowedHeader(&quot;*&quot;); /*允许访问的方法名,GET POST等*/ corsConfiguration.addAllowedMethod(&quot;*&quot;); urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, corsConfiguration); return new CorsFilter(urlBasedCorsConfigurationSource); }}","link":"/2019/03/28/Spring%20%E5%AE%8C%E7%BE%8E%E9%85%8D%E7%BD%AE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/"},{"title":"Spring Bean 生命周期","text":"Spring Bean 生命周期前言Spring Bean 的生命周期在整个 Spring 中占有很重要的位置，掌握这些可以加深对 Spring 的理解。 首先看下生命周期图： 再谈生命周期之前有一点需要先明确： Spring 只帮我们管理单例模式 Bean 的完整生命周期，对于 prototype 的 bean ，Spring 在创建好交给使用者之后则不会再管理后续的生命周期。 注解方式在 bean 初始化时会经历几个阶段，首先可以使用注解 @PostConstruct, @PreDestroy 来在 bean 的创建和销毁阶段进行调用: 1234567891011121314@Componentpublic class AnnotationBean { private final static Logger LOGGER = LoggerFactory.getLogger(AnnotationBean.class); @PostConstruct public void start(){ LOGGER.info(&quot;AnnotationBean start&quot;); } @PreDestroy public void destroy(){ LOGGER.info(&quot;AnnotationBean destroy&quot;); }} InitializingBean, DisposableBean 接口还可以实现 InitializingBean,DisposableBean 这两个接口，也是在初始化以及销毁阶段调用： 12345678910111213@Servicepublic class SpringLifeCycleService implements InitializingBean,DisposableBean{ private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleService.class); @Override public void afterPropertiesSet() throws Exception { LOGGER.info(&quot;SpringLifeCycleService start&quot;); } @Override public void destroy() throws Exception { LOGGER.info(&quot;SpringLifeCycleService destroy&quot;); }} 自定义初始化和销毁方法也可以自定义方法用于在初始化、销毁阶段调用: 123456789101112131415161718192021222324@Configurationpublic class LifeCycleConfig { @Bean(initMethod = &quot;start&quot;, destroyMethod = &quot;destroy&quot;) public SpringLifeCycle create(){ SpringLifeCycle springLifeCycle = new SpringLifeCycle() ; return springLifeCycle ; }}public class SpringLifeCycle{ private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycle.class); public void start(){ LOGGER.info(&quot;SpringLifeCycle start&quot;); } public void destroy(){ LOGGER.info(&quot;SpringLifeCycle destroy&quot;); }} 以上是在 SpringBoot 中可以这样配置，如果是原始的基于 XML 也是可以使用: 12&lt;bean class=&quot;com.crossoverjie.spring.SpringLifeCycle&quot; init-method=&quot;start&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 来达到同样的效果。 实现 *Aware 接口*Aware 接口可以用于在初始化 bean 时获得 Spring 中的一些对象，如获取 Spring 上下文等。 123456789101112@Componentpublic class SpringLifeCycleAware implements ApplicationContextAware { private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleAware.class); private ApplicationContext applicationContext ; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext ; LOGGER.info(&quot;SpringLifeCycleAware start&quot;); }} 这样在 springLifeCycleAware 这个 bean 初始化会就会调用 setApplicationContext 方法，并可以获得 applicationContext 对象。 BeanPostProcessor 增强处理器实现 BeanPostProcessor 接口，Spring 中所有 bean 在做初始化时都会调用该接口中的两个方法，可以用于对一些特殊的 bean 进行处理： 12345678910111213141516171819202122232425262728293031323334@Componentpublic class SpringLifeCycleProcessor implements BeanPostProcessor { private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleProcessor.class); /** * 预初始化 初始化之前调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if (&quot;annotationBean&quot;.equals(beanName)){ LOGGER.info(&quot;SpringLifeCycleProcessor start beanName={}&quot;,beanName); } return bean; } /** * 后初始化 bean 初始化完成调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (&quot;annotationBean&quot;.equals(beanName)){ LOGGER.info(&quot;SpringLifeCycleProcessor end beanName={}&quot;,beanName); } return bean; }} 执行之后观察结果： 123456789101112131415018-03-21 00:40:24.856 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor start beanName=annotationBean2018-03-21 00:40:24.860 [restartedMain] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean start2018-03-21 00:40:24.861 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor end beanName=annotationBean2018-03-21 00:40:24.864 [restartedMain] INFO c.c.s.aware.SpringLifeCycleAware - SpringLifeCycleAware start2018-03-21 00:40:24.867 [restartedMain] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService start2018-03-21 00:40:24.887 [restartedMain] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle start2018-03-21 00:40:25.062 [restartedMain] INFO o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 357292018-03-21 00:40:25.122 [restartedMain] INFO o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup2018-03-21 00:40:25.140 [restartedMain] INFO com.crossoverjie.Application - Started Application in 2.309 seconds (JVM running for 3.681)2018-03-21 00:40:25.143 [restartedMain] INFO com.crossoverjie.Application - start ok!2018-03-21 00:40:25.153 [Thread-8] INFO o.s.c.a.AnnotationConfigApplicationContext - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@3913adad: startup date [Wed Mar 21 00:40:23 CST 2018]; root of context hierarchy2018-03-21 00:40:25.155 [Thread-8] INFO o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean destroy 直到 Spring 上下文销毁时则会调用自定义的销毁方法以及实现了 DisposableBean 的 destroy() 方法。","link":"/2019/05/15/Spring-Bean-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"Spring Boot使用@Async实现异步调用：自定义线程池","text":"Spring Boot使用@Async实现异步调用：自定义线程池 如果通过自定义线程池的方式来控制异步调用的并发。 定义线程池第一步，先在Spring Boot主类中定义一个线程池，比如： 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } @EnableAsync @Configuration class TaskPoolConfig { @Bean(&quot;asyncExecutor&quot;) public Executor taskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); //设置核心线程数 executor.setCorePoolSize(10); //设置最大线程数 executor.setMaxPoolSize(20); //线程池所使用的缓冲队列 executor.setQueueCapacity(200); executor.setKeepAliveSeconds(60); // 线程名称前缀 executor.setThreadNamePrefix(&quot;asyncExecutor-&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); //用来设置线程池关闭的时候等待所有任务都完成再继续销毁其他的Bean，这样这些异步任务的销毁就会先于Redis线程池的销毁。 //等待任务在关机时完成--表明等待所有线程执行完 executor.setWaitForTasksToCompleteOnShutdown(true); //该方法用来设置线程池中任务的等待时间，如果超过这个时候还没有销毁就强制销毁，以确保应用最后能够被关闭，而不是阻塞住。 // 等待时间 （默认为0，此时立即停止），并没等待xx秒后强制停止 executor.setAwaitTerminationSeconds(180); // 初始化线程 executor.initialize(); return executor; }} 上面我们通过使用ThreadPoolTaskExecutor创建了一个线程池，同时设置了以下这些参数： 核心线程数10：线程池创建时候初始化的线程数 最大线程数20：线程池最大的线程数，只有在缓冲队列满了之后才会申请超过核心线程数的线程 缓冲队列200：用来缓冲执行任务的队列 允许线程的空闲时间60秒：当超过了核心线程出之外的线程在空闲时间到达之后会被销毁 线程池名的前缀：设置好了之后可以方便我们定位处理任务所在的线程池 线程池对拒绝任务的处理策略：这里采用了CallerRunsPolicy策略，当线程池没有处理能力的时候，该策略会直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 使用线程池在定义了线程池之后，我们如何让异步调用的执行任务使用这个线程池中的资源来运行呢？方法非常简单，我们只需要在@Async注解中指定线程池名即可，比如： 12345678910111213141516171819202122232425262728293031323334@Slf4j@Componentpublic class Task { public static Random random = new Random(); @Async(&quot;taskExecutor&quot;) public void doTaskOne() throws Exception { log.info(&quot;开始做任务一&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); log.info(&quot;完成任务一，耗时：&quot; + (end - start) + &quot;毫秒&quot;); } @Async(&quot;taskExecutor&quot;) public void doTaskTwo() throws Exception { log.info(&quot;开始做任务二&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); log.info(&quot;完成任务二，耗时：&quot; + (end - start) + &quot;毫秒&quot;); } @Async(&quot;taskExecutor&quot;) public void doTaskThree() throws Exception { log.info(&quot;开始做任务三&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); log.info(&quot;完成任务三，耗时：&quot; + (end - start) + &quot;毫秒&quot;); }} 单元测试最后，我们来写个单元测试来验证一下 1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class ApplicationTests { @Autowired private Task task; @Test public void test() throws Exception { task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); Thread.currentThread().join(); }} 执行上面的单元测试，我们可以在控制台中看到所有输出的线程名前都是之前我们定义的线程池前缀名开始的，说明我们使用线程池来执行异步任务的试验成功了！ 1234562018-03-27 22:01:15.620 INFO 73703 --- [ taskExecutor-1] com.didispace.async.Task : 开始做任务一2018-03-27 22:01:15.620 INFO 73703 --- [ taskExecutor-2] com.didispace.async.Task : 开始做任务二2018-03-27 22:01:15.620 INFO 73703 --- [ taskExecutor-3] com.didispace.async.Task : 开始做任务三2018-03-27 22:01:18.165 INFO 73703 --- [ taskExecutor-2] com.didispace.async.Task : 完成任务二，耗时：2545毫秒2018-03-27 22:01:22.149 INFO 73703 --- [ taskExecutor-3] com.didispace.async.Task : 完成任务三，耗时：6529毫秒2018-03-27 22:01:23.912 INFO 73703 --- [ taskExecutor-1] com.didispace.async.Task : 完成任务一，耗时：8292毫秒 完整示例：读者可以根据喜好选择下面的两个仓库中查看Chapter4-1-3项目： Github：https://github.com/dyc87112/SpringBoot-Learning/ Gitee：https://gitee.com/didispace/SpringBoot-Learning/","link":"/2019/08/21/Spring-Boot%E4%BD%BF%E7%94%A8-Async%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BA%BF%E7%A8%8B%E6%B1%A0-1/"},{"title":"SpringBoot Jar包瘦身 - 跟大文件说再见！","text":"前言SpringBoot部署起来配置非常少，如果服务器部署在公司内网，上传速度还行，但是如果部署在公网（阿里云等云服务器上），部署起来实在头疼、就是 编译出来的 Jar 包很大，如果工程引入了许多开源组件（SpringCloud等），那就更大了。这个时候如果想要对线上运行工程有一些微调，则非常痛苦 可以用以下方法减少jar内容瘦身准备1、首先我们要对Jar包有一个初步认识，它的内部结构如下1234567891011121314151617example.jar | +-META-INF | +-MANIFEST.MF +-org | +-springframework | +-boot | +-loader | +-&lt;spring boot loader classes&gt; +-BOOT-INF +-classes | +-mycompany | +-project | +-YourClasses.class +-lib // 依赖库的包 +-dependency1.jar +-dependency2.jar 运行该Jar时默认从BOOT-INF/classes加载class，从BOOT-INF/lib加载所依赖的Jar包。如果想要加入外部的依赖Jar，可以通过设置环境变量LOADER_PATH来实现。 如此一来，就可以确认我们的思路了： 把那些不变的依赖Jar包（比如spring依赖、数据库Driver等，这些在不升级版本的情况下是不会更新的）从Flat Jar中抽离到单独的目录，如libs 在启动Jar时，设置LOADER_PATH使用上一步的libs 1java -Dloader.path=&quot;libs/&quot; -jar ht-ui-web.jar 这样，我们最终打包的jar包体积就大大减少，每次迭代后只需要更新这个精简版的Jar即可。 需要在pom文件配置忽略的依赖包。 关键需要配置MANIFEST.MF 文件中加入lib路径。 然后正常启动jar包就可以了。 123456789101112131415161718192021222324252627&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--不打包资源文件--&gt; &lt;!--&lt;excludes&gt;--&gt; &lt;!--&lt;exclude&gt;*.**&lt;/exclude&gt;--&gt; &lt;!--&lt;exclude&gt;*/*.xml&lt;/exclude&gt;--&gt; &lt;!--&lt;/excludes&gt;--&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!--MANIFEST.MF 中 Class-Path 加入前缀--&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!--jar包不包含唯一版本标识--&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;!--指定入口类--&gt; &lt;mainClass&gt;com.XProApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;!--&lt;manifestEntries&gt;--&gt; &lt;!--&lt;!&amp;ndash;MANIFEST.MF 中 Class-Path 加入资源文件目录&amp;ndash;&gt;--&gt; &lt;!--&lt;Class-Path&gt;./resources/&lt;/Class-Path&gt;--&gt; &lt;!--&lt;/manifestEntries&gt;--&gt; &lt;/archive&gt; &lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt; &lt;/configuration&gt;&lt;/plugin&gt; 完整pom文件的内容如下。。配置完毕打包项目就会将lib包和项目包分开放到target中。然后分开上传内容。 以后就可以上传精简的jar包了```` org.apache.maven.plugins maven-compiler-plugin 3.1 org.apache.maven.plugins maven-jar-plugin true lib/ false com.XProApplication ${project.build.directory} &lt;!--拷贝依赖 copy-dependencies--&gt; &lt;!--也可以执行mvn copy-dependencies 命令打包依赖--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt; ${project.build.directory}/lib/ &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--spring boot repackage，依赖 maven-jar-plugin 打包的jar包 重新打包成 spring boot 的jar包--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--重写包含依赖，包含不存在的依赖，jar里没有pom里的依赖--&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;null&lt;/groupId&gt; &lt;artifactId&gt;null&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;!--使用外部配置文件，jar包里没有资源文件--&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!--配置jar包特殊标识 配置后，保留原文件，生成新文件 *-run.jar --&gt; &lt;!--配置jar包特殊标识 不配置，原文件命名为 *.jar.original，生成新文件 *.jar --&gt; &lt;!--&lt;classifier&gt;run&lt;/classifier&gt;--&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/build&gt; ```","link":"/2019/07/18/SpringBoot-Jar%E5%8C%85%E7%98%A6%E8%BA%AB-%E8%B7%9F%E5%A4%A7%E6%96%87%E4%BB%B6%E8%AF%B4%E5%86%8D%E8%A7%81%EF%BC%81/"},{"title":"SpringBoot是如何动起来的","text":"程序入口 SpringBoot是如何动起来的程序入口1SpringApplication.run(BeautyApplication.class, args); 执行此方法来加载整个SpringBoot的环境。1. 从哪儿开始？ SpringApplication.java123456789 /** * Run the Spring application, creating and refreshing a new * {@link ApplicationContext}. * @param args the application arguments (usually passed from a Java main method) * @return a running {@link ApplicationContext} */public ConfigurableApplicationContext run(String... args) { //... } 调用SpringApplication.java 中的 run 方法，目的是加载Spring Application，同时返回 ApplicationContext。 2. 执行了什么？2.1 计时记录整个Spring Application的加载时间！12345678StopWatch stopWatch = new StopWatch();stopWatch.start();// ...stopWatch.stop();if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch);} 2.2 声明指定 java.awt.headless，默认是true 一般是在程序开始激活headless模式，告诉程序，现在你要工作在Headless mode下，就不要指望硬件帮忙了，你得自力更生，依靠系统的计算能力模拟出这些特性来。1234private void configureHeadlessProperty() { System.setProperty(SYSTEM_PROPERTY_JAVA_AWT_HEADLESS, System.getProperty( SYSTEM_PROPERTY_JAVA_AWT_HEADLESS, Boolean.toString(this.headless)));} 2.4 配置监听并发布应用启动事件SpringApplicationRunListener 负责加载 ApplicationListener事件。123456789101112131415SpringApplicationRunListeners listeners = getRunListeners(args);// 开始listeners.starting();// 处理所有 property sources 配置和 profiles 配置，准备环境，分为标准 Servlet 环境和标准环境ConfigurableEnvironment environment = prepareEnvironment(listeners,applicationArguments);// 准备应用上下文prepareContext(context, environment, listeners, applicationArguments,printedBanner);// 完成listeners.started(context);// 异常handleRunFailure(context, ex, exceptionReporters, listeners);// 执行listeners.running(context); getRunListeners 中根据 type = SpringApplicationRunListener.class 去拿到了所有的 Listener 并根据优先级排序。对应的就是 META-INF/spring.factories 文件中的 org.springframework.boot.SpringApplicationRunListener=org.springframework.boot.context.event.EventPublishingRunListener 123456789101112private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; }复制代码 在 ApplicationListener 中 , 可以针对任何一个阶段插入处理代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public interface SpringApplicationRunListener { /** * Called immediately when the run method has first started. Can be used for very * early initialization. */ void starting(); /** * Called once the environment has been prepared, but before the * {@link ApplicationContext} has been created. * @param environment the environment */ void environmentPrepared(ConfigurableEnvironment environment); /** * Called once the {@link ApplicationContext} has been created and prepared, but * before sources have been loaded. * @param context the application context */ void contextPrepared(ConfigurableApplicationContext context); /** * Called once the application context has been loaded but before it has been * refreshed. * @param context the application context */ void contextLoaded(ConfigurableApplicationContext context); /** * The context has been refreshed and the application has started but * {@link CommandLineRunner CommandLineRunners} and {@link ApplicationRunner * ApplicationRunners} have not been called. * @param context the application context. * @since 2.0.0 */ void started(ConfigurableApplicationContext context); /** * Called immediately before the run method finishes, when the application context has * been refreshed and all {@link CommandLineRunner CommandLineRunners} and * {@link ApplicationRunner ApplicationRunners} have been called. * @param context the application context. * @since 2.0.0 */ void running(ConfigurableApplicationContext context); /** * Called when a failure occurs when running the application. * @param context the application context or {@code null} if a failure occurred before * the context was created * @param exception the failure * @since 2.0.0 */ void failed(ConfigurableApplicationContext context, Throwable exception);} 3. 每个阶段执行的内容3.1 listeners.starting();在加载Spring Application之前执行，所有资源和环境未被加载。3.2 prepareEnvironment(listeners, applicationArguments);创建 ConfigurableEnvironment； 将配置的环境绑定到Spring Application中；123456789101112131415private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) { // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (this.webApplicationType == WebApplicationType.NONE) { environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); } ConfigurationPropertySources.attach(environment); return environment; } 3.3 prepareContext配置忽略的Bean；123456789private void configureIgnoreBeanInfo(ConfigurableEnvironment environment) { if (System.getProperty( CachedIntrospectionResults.IGNORE_BEANINFO_PROPERTY_NAME) == null) { Boolean ignore = environment.getProperty(&quot;spring.beaninfo.ignore&quot;, Boolean.class, Boolean.TRUE); System.setProperty(CachedIntrospectionResults.IGNORE_BEANINFO_PROPERTY_NAME, ignore.toString()); } } 打印日志-加载的资源1Banner printedBanner = printBanner(environment); 根据不同的WebApplicationType创建Context1context = createApplicationContext(); 3.4 refreshContext支持定制刷新123456789/** * Register a shutdown hook with the JVM runtime, closing this context * on JVM shutdown unless it has already been closed at that time. * &lt;p&gt;This method can be called multiple times. Only one shutdown hook * (at max) will be registered for each context instance. * @see java.lang.Runtime#addShutdownHook * @see #close() */ void registerShutdownHook(); 3.5 afterRefresh刷新后的实现方法暂未实现12345678/** * Called after the context has been refreshed. * @param context the application context * @param args the application arguments */ protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) { } 3.6 listeners.started(context);到此为止， Spring Application的环境和资源都加载完毕了； 发布应用上下文启动完成事件； 执行所有 Runner 运行器 - 执行所有 ApplicationRunner 和 CommandLineRunner 这两种运行器12// 启动callRunners(context, applicationArguments); 3.7 listeners.running(context);触发所有 SpringApplicationRunListener 监听器的 running 事件方法","link":"/2019/03/28/SpringBoot%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A8%E8%B5%B7%E6%9D%A5%E7%9A%84/"},{"title":"SpringBoot是怎么在实例化时候将bean加载进入容器中","text":"之前写过的很多spring文章，都是基于应用方面的，这次的话，就带大家来一次对spring的源码追踪，看一看spring到底是怎么进行的初始化，如何创建的bean，相信很多刚刚接触spring的朋友，或者没什么时间的朋友都很想知道spring到底是如何工作的。 首先，按照博主一贯的作风，当然是使用最新的spring版本，这次就使用spring4.2.5…其次，也是为了方便，采用spring-boot-1.3.3进行追踪，和spring 4.2.5是相同的。 不用担心框架不同，大家如果是使用的xml方式进行配置的话，可以去你的ContextListener里面进行追踪，spring-boot只是对 spring所有框架进行了一个集成，如果实在进行不了前面几个步骤的话，可以从文章第6步的AbstractApplicationContext开始看起， 这里就是spring最最重要的部分。 1、默认的spring启动器，DemoApplication： 该方法是spring-boot的启动器，我们进入。 2、进入了SpringApplication.java： 这里创建了一个SpringApplication，执行run方法，返回的是一个ConfigurableApplicationContext，这只是一个接口而已，根据名称来看，称作可配置的应用程序上下文。 3、我们不看new SpringApplication(Sources)过程了，有兴趣可以自己研究一下，里面主要是判断了当前的运行环境是否为web，当然，博主这次的环境是web，然后看run： try语句块内的内容最为重要，因为创建了我们的context对象，此时需要进入的方法为 context = createAndRefreshContext(listeners, applicationArguments) 4、 接着往下看，看到context = createApplicationContext这行，进入，因为我们刚刚在创建SpringApplication时并没有给 this.applicationContextClass赋值，所以此时this.applicationContextClass = null，那么便会创建指定的两个applicationContext中的一个，返回一个刚刚创建的context，这个context便是我们的基 础，因为门现在为web环境，所以创建的context为 AnnotationConfigEmbeddedWebApplicationContext。 5、第4步创建了一个context，需要指出的是，context里面默认带有一个beanFactory，而这个beanFactory的类型为DefaultListableBeanFactory。 然后继续看我们的createAndRefreshContext方法，忽略别的代码，最重要的地方为refresh(context)： 6、进入refresh(context)，不管你进入那个实现类，最终进入的都是AbstractApplicationContext.java： 该方法中，我们这次需要注意的地方有两个： 1、invokeBeanFactoryPostProcessors(beanFactory); 2、finishBeanFactoryInitialization(beanFactory); 两处传入的beanFactory为上面的context中的DefaultListableBeanFactory。 7、进入invokeBeanFactoryPostProcessors(beanFactory)： 然后找到第98行的invokeBeanDefinitionRegistryPostProcessors(priorityOrderedPostProcessors, registry)，该方法看名字就是注册bean，进入。 8、 该方法内部有一个for循环，进入内部方法 postProcessor.postProcesBeanDefinitionRegistry(registry)，此时传入的registry就是我们context中的beanfactory，因为其实现了BeanDefinitionRegistry接口。而此时的postProcessor实现类为ConfigurationClassPostProcessor.java。 9、进入之后直接看最后面的一个方法，名称为processConfigBeanDefinitions(registry)，翻译过来就是配置beanDefinitions的流程。 10、在processConfigBeanDefinitions(registry)里，314行创建了一个parser解析器，用来解析bean。并在第321行进行了调用，那么我们进入parse方法。 11、进入parse方法之后，会发现内层还有parse方法，不要紧，继续进入内层的parse，然后会发现它们均调用了processConfigurationClass(ConfigurationClass configClass)方法： 12、 在processConfigurationClass(ConfigurationClass configClass)方法内，找到do循环，然后进入doProcessConfigurationClass方法，此时，便会出现许多我们常用的注 解了，spring会找到这些注解，并对它们进行解析。例如第268行的componentScanParser.parse方法，在这里会扫描我们的注 解类，并将带有@bean注解的类进行registry。 13、进入 componentScanParser.parse，直接进入结尾的scannner.doScan，然后便会扫描basepackages，并将扫描 到的bean生成一个一个BeanDefinitionHolder，BeanDefinitionHolder中包含有我们bean的一些相关信息、以 及spring赋予其的额外信息，例如别名： 14、 虽然已经创建了BeanDefinitionHolder，但并没有添加到我们的beanFactory中，所以需要执行263行的 registerBeanDefinition(definitionHolder, this.registry)，进入后继续跳转： 然后看registry.registerBeanDefinition方法，因为我们的beanFactory为DefaultListableBeanFactory，所以进入对应的实现类。 15、在进入的registry.registerBeanDefinition方法中，关键点在851行或871行： this.beanDefinitionMap.put(beanName, beanDefinition); 这个方法将扫描到的bean存放到了一个beanName为key、beanDefinition为value的map中，以便执行DI(dependency inject)。 16、现在我们回到第6步的第二条分支，此处是非懒加载的bean初始化位置，注意，我们之前只是对bean的信息进行了获取，然后创建的对象为BeanDefinition，却不是bean的实例，而现在则是创建bean的实例。 进入方法后找到829行的getBean(weaverAwareName)： 17、getBean =&gt; getBeanFactory.getBean =&gt; doGetBean，然后找到306行的createBean，这里不讲语法，不要奇怪为什么这个createBean不能进入实现代码。 18、这之后的代码都比较容易追踪，直接给一条调用链： doCreateBean(482) =&gt; createBeanInstance(510) =&gt; autowireConstructor(1034,1046) =&gt; autowireConstructor(1143) =&gt; instantiate(267) =&gt; instantiateClass(122) =&gt; newInstance(147) 括号内的数字代表行号，方便大家进行追踪，最后看到是反射newInstance取得的对象实例： 平时总说spring反射获取bean，其实也就是听别人这么说而已，还是自己见到才踏实，万一别人问你是不是通过Class.forName获取的呢？ 19、属性注入，位于第18条的doCreateBean方法内，找到第543行，populateBean便译为填充Bean，进入后便能看到和我们平时代码对应的条件了，例如byType注入、byName注入： 这里还没有进行依赖注入，仅仅是准备一些必要的信息，找到1214行的ibp.postProcessPropertyValues方法 20、这里有很多实现类可以选择，因为博主平时是使用@Autowired注解，所以这里选择AutowiredAnnotationBeanPostProcessor，如果你使用@Resource的话，就选择CommonBeanPostProcessor： 21、进入该方法后，首先获取一些元信息metadata，通过findAutowiringMetadata获取，然后调用metadata.inject进行注入： 22、继续进入inject方法后，继续找到88行的element.inject方法并进入，实现类选择AutowiredFieldElement，该类是一个内部类： 在这个方法中，最重要的内容在第567~570行内，我们可以看到，这里其实也就是jdk的反射特性。至此，spring的 bean初始化-&gt;注入 便完成了。 这次的博客内容很长(其实是自己追踪代码时间太久)，感谢大家耐心看完，能有所收获的话便最好不过了。另外，若是有什么补充的话欢迎进行回复。","link":"/2019/04/23/SpringBoot%E6%98%AF%E6%80%8E%E4%B9%88%E5%9C%A8%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%97%B6%E5%80%99%E5%B0%86bean%E5%8A%A0%E8%BD%BD%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E4%B8%AD/"},{"title":"SpringCloud","text":"https://cloud.tencent.com/developer/article/1154457 https://cloud.tencent.com/developer/article/1350910","link":"/2019/05/05/SpringCloud/"},{"title":"个人完善的springboot拦截器","text":"使用Sping Boot2.0 搭建权限拦截的时候 发现 与之前的版本不一样了 123456789101112131415161718192021222324252627282930313233343536373839404142434445## 所有功能完成 配置登录认证### 配置拦截器###### 在spring boot2.0 之后 通过继承这个WebMvcConfigurer类 就可以完成拦截- 新建包com.example.interceptor;- 创建login拦截类```javapackage com.example.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class LoginInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //请求进入这个拦截器 HttpSession session = request.getSession(); if(session.getAttribute(&quot;user&quot;) == null){ //判断session中有没有user信息// System.out.println(&quot;进入拦截器&quot;); if(&quot;XMLHttpRequest&quot;.equalsIgnoreCase(request.getHeader(&quot;X-Requested-With&quot;))){ response.sendError(401); } response.sendRedirect(&quot;/&quot;); //没有user信息的话进行路由重定向 return false; } return true; //有的话就继续操作 } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { }} 在com.example包中添加拦截控制器 1234567891011121314151617181920212223242526package com.example;import com.example.interceptor.LoginInterceptor;import com.example.interceptor.RightsInterceptor;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.*;@Configuration //使用注解 实现拦截public class WebAppConfigurer implements WebMvcConfigurer { @Autowired RightsInterceptor rightsInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //登录拦截的管理器 InterceptorRegistration registration = registry.addInterceptor(new LoginInterceptor()); //拦截的对象会进入这个类中进行判断 registration.addPathPatterns(&quot;/**&quot;); //所有路径都被拦截 registration.excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/error&quot;,&quot;/static/**&quot;,&quot;/logout&quot;); //添加不拦截路径 }} 在WebAppConfigurer.java中增加内容123456789101112131415161718192021222324252627282930313233package com.example;import com.example.interceptor.LoginInterceptor;import com.example.interceptor.RightsInterceptor;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.*;@Configuration //使用注解 实现拦截public class WebAppConfigurer implements WebMvcConfigurer { @Autowired RightsInterceptor rightsInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //登录拦截的管理器 InterceptorRegistration registration = registry.addInterceptor(new LoginInterceptor()); //拦截的对象会进入这个类中进行判断 registration.addPathPatterns(&quot;/**&quot;); //所有路径都被拦截 registration.excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/error&quot;,&quot;/static/**&quot;,&quot;/logout&quot;); //添加不拦截路径// super.addInterceptors(registry); //权限拦截的管理器 InterceptorRegistration registration1 = registry.addInterceptor(rightsInterceptor); registration1.addPathPatterns(&quot;/**&quot;); //所有路径都被拦截 registration1.excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/error&quot;,&quot;/static/**&quot;,&quot;/logout&quot;); //添加不拦截路径 }}","link":"/2019/03/27/Springboot2.0%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"title":"Swagger使用指南","text":"Swagger使用指南 现代化的研发组织架构中，一个研发团队基本包括了产品组、后端组、前端组、APP端研发、测试组、UI组等，各个细分组织人员各司其职，共同完成产品的全周期工作。如何进行组织架构内的有效高效沟通就显得尤其重要。其中，如何构建一份合理高效的接口文档更显重要。 接口文档横贯各个端的研发人员，但是由于接口众多，细节不一，有时候理解起来并不是那么容易，引起‘内战’也在所难免， 并且维护也是一大难题。 类似RAP文档管理系统，将接口文档进行在线维护，方便了前端和APP端人员查看进行对接开发，但是还是存在以下几点问题： 文档是接口提供方手动导入的，是静态文档，没有提供接口测试功能； 维护的难度不小 Swagger的出现可以完美解决以上传统接口管理方式存在的痛点。本文介绍Spring Boot整合Swagger2的流程，连带填坑。 使用流程如下： 1）引入相应的maven包： 1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 2）编写Swagger2的配置类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.trace.configuration;import io.swagger.annotations.Api;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/*** Created by Trace on 2018-05-16.&lt;br/&gt;* Desc: swagger2配置类*/@SuppressWarnings({&quot;unused&quot;})@Configuration @EnableSwagger2public class Swagger2Config { @Value(&quot;${swagger2.enable}&quot;) private boolean enable; @Bean(&quot;UserApis&quot;) public Docket userApis() { return new Docket(DocumentationType.SWAGGER_2) .groupName(&quot;用户模块&quot;) .select() .apis(RequestHandlerSelectors.withClassAnnotation(Api.class)) .paths(PathSelectors.regex(&quot;/user.*&quot;)) .build() .apiInfo(apiInfo()) .enable(enable); } @Bean(&quot;CustomApis&quot;) public Docket customApis() { return new Docket(DocumentationType.SWAGGER_2) .groupName(&quot;客户模块&quot;) .select() .apis(RequestHandlerSelectors.withClassAnnotation(Api.class)) .paths(PathSelectors.regex(&quot;/custom.*&quot;)) .build() .apiInfo(apiInfo()) .enable(enable); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;XXXXX系统平台接口文档&quot;) .description(&quot;提供子模块1/子模块2/子模块3的文档, 更多请关注公众号: 随行享阅&quot;) .termsOfServiceUrl(&quot;https://xingtian.github.io/trace.github.io/&quot;) .version(&quot;1.0&quot;) .build(); }} 如上可见：通过注解@EnableSwagger2开启swagger2，apiInfo是接口文档的基本说明信息，包括标题、描述、服务网址、联系人、版本等信息； 在Docket创建中，通过groupName进行分组，paths属性进行过滤，apis属性可以设置扫描包，或者通过注解的方式标识；通过enable属性，可以在application-{profile}.properties文件中设置相应值，主要用于控制生产环境不生成接口文档。 3）controller层类和方法添加相关注解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.trace.controller;import com.trace.bind.ResultModel;import com.trace.entity.po.Area;import com.trace.entity.po.User;import com.trace.service.UserService;import io.swagger.annotations.Api;import io.swagger.annotations.ApiImplicitParam;import io.swagger.annotations.ApiImplicitParams;import io.swagger.annotations.ApiOperation;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;import java.util.List;/** * Created by Trace on 2017-12-01.&lt;br/&gt; * Desc: 用户管理controller */@SuppressWarnings(&quot;unused&quot;)@RestController @RequestMapping(&quot;/user&quot;)@Api(tags = &quot;用户管理&quot;)public class UserController { @Resource private UserService userService; @GetMapping(&quot;/query/{id}&quot;) @ApiOperation(&quot;通过ID查询&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;int&quot;, paramType = &quot;path&quot;) public ResultModel&lt;User&gt; findById(@PathVariable int id) { User user = userService.findById(id); return ResultModel.success(&quot;id查询成功&quot;, user); } @GetMapping(&quot;/query/ids&quot;) @ApiOperation(&quot;通过ID列表查询&quot;) public ResultModel&lt;List&lt;User&gt;&gt; findByIdIn(int[] ids) { List&lt;User&gt; users = userService.findByIdIn(ids); return ResultModel.success(&quot;in查询成功&quot;, users); } @GetMapping(&quot;/query/user&quot;) @ApiOperation(&quot;通过用户实体查询&quot;) public ResultModel&lt;List&lt;User&gt;&gt; findByUser(User user) { List&lt;User&gt; users = userService.findByUser(user); return ResultModel.success(&quot;通过实体查询成功&quot;, users); } @GetMapping(&quot;/query/all&quot;) @ApiOperation(&quot;查询所有用户&quot;) public ResultModel&lt;List&lt;User&gt;&gt; findAll() { List&lt;User&gt; users = userService.findAll(); return ResultModel.success(&quot;全体查找成功&quot;, users); } @GetMapping(&quot;/query/username&quot;) @ApiOperation(&quot;通过用户名称模糊查询&quot;) @ApiImplicitParam(name = &quot;userName&quot;, value = &quot;用户名称&quot;) public ResultModel&lt;List&lt;User&gt;&gt; findByUserName(String userName) { List&lt;User&gt; users = userService.findByUserName(userName); return ResultModel.success(users); } @PostMapping(&quot;/insert&quot;) @ApiOperation(&quot;新增默认用户&quot;) public ResultModel&lt;Integer&gt; insert() { User user = new User(); user.setUserName(&quot;zhongshiwen&quot;); user.setNickName(&quot;zsw&quot;); user.setRealName(&quot;钟仕文&quot;); user.setPassword(&quot;zsw123456&quot;); user.setGender(&quot;男&quot;); Area area = new Area(); area.setLevel((byte) 5); user.setArea(area); userService.save(user); return ResultModel.success(&quot;新增用户成功&quot;, user.getId()); } @PutMapping(&quot;/update&quot;) @ApiOperation(&quot;更新用户信息&quot;) public ResultModel&lt;Integer&gt; update(User user) { int row = userService.update(user); return ResultModel.success(row); } @PutMapping(&quot;/update/status&quot;) @ApiOperation(&quot;更新单个用户状态&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true), @ApiImplicitParam(name = &quot;status&quot;, value = &quot;状态&quot;, required = true) }) public ResultModel&lt;User&gt; updateStatus(int id, byte status) { User user = userService.updateStatus(id, status); return ResultModel.success(user); } @DeleteMapping(&quot;/delete&quot;) @ApiOperation(&quot;删除单个用户&quot;) @ApiImplicitParam(value = &quot;用户ID&quot;, required = true) public ResultModel&lt;Integer&gt; delete(int id) { return ResultModel.success(userService.delete(id)); }} 4）返回对象ResultModel 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.trace.bind;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import lombok.Getter;import lombok.Setter;/*** Created by Trace on 2017-12-01.&lt;br/&gt;* Desc: 接口返回结果对象*/@SuppressWarnings(&quot;unused&quot;)@Getter @Setter @ApiModel(description = &quot;返回结果&quot;)public final class ResultModel&lt;T&gt; { @ApiModelProperty(&quot;是否成功: true or false&quot;) private boolean result; @ApiModelProperty(&quot;描述性原因&quot;) private String message; @ApiModelProperty(&quot;业务数据&quot;) private T data; private ResultModel(boolean result, String message, T data) { this.result = result; this.message = message; this.data = data; } public static&lt;T&gt; ResultModel&lt;T&gt; success(T data) { return new ResultModel&lt;&gt;(true, &quot;SUCCESS&quot;, data); } public static&lt;T&gt; ResultModel&lt;T&gt; success(String message, T data) { return new ResultModel&lt;&gt;(true, message, data); } public static ResultModel failure() { return new ResultModel&lt;&gt;(false, &quot;FAILURE&quot;, null); } public static ResultModel failure(String message) { return new ResultModel&lt;&gt;(false, message, null); }} 5）ApiModel属性对象 – User实体 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.trace.entity.po;import com.trace.mapper.base.NotPersistent;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.time.LocalDate;import java.time.LocalDateTime;import java.util.List;/** * Created by Trace on 2017-12-01.&lt;br/&gt; * Desc: 用户表tb_user */@SuppressWarnings(&quot;unused&quot;)@Data @NoArgsConstructor @AllArgsConstructor@ApiModelpublic class User { @ApiModelProperty(&quot;用户ID&quot;) private Integer id; @ApiModelProperty(&quot;账户名&quot;) private String userName; @ApiModelProperty(&quot;用户昵称&quot;) private String nickName; @ApiModelProperty(&quot;真实姓名&quot;) private String realName; @ApiModelProperty(&quot;身份证号码&quot;) private String identityCard; @ApiModelProperty(&quot;性别&quot;) private String gender; @ApiModelProperty(&quot;出生日期&quot;) private LocalDate birth; @ApiModelProperty(&quot;手机号码&quot;) private String phone; @ApiModelProperty(&quot;邮箱&quot;) private String email; @ApiModelProperty(&quot;密码&quot;) private String password; @ApiModelProperty(&quot;用户头像地址&quot;) private String logo; @ApiModelProperty(&quot;账户状态 0:正常; 1:冻结; 2:注销&quot;) private Byte status; @ApiModelProperty(&quot;个性签名&quot;) private String summary; @ApiModelProperty(&quot;用户所在区域码&quot;) private String areaCode; @ApiModelProperty(&quot;注册时间&quot;) private LocalDateTime registerTime; @ApiModelProperty(&quot;最近登录时间&quot;) private LocalDateTime lastLoginTime; @NotPersistent @ApiModelProperty(hidden = true) private transient Area area; //用户所在地区 @NotPersistent @ApiModelProperty(hidden = true) private transient List&lt;Role&gt; roles; //用户角色列表} 简单说下Swagger2几个重要注解： @Api：用在请求的类上，表示对类的说明 tags “说明该类的作用，可以在UI界面上看到的注解” value “该参数没什么意义，在UI界面上也看到，所以不需要配置” @ApiOperation：用在请求的方法上，说明方法的用途、作用 value=”说明方法的用途、作用” notes=”方法的备注说明” @ApiImplicitParams：用在请求的方法上，表示一组参数说明 @ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 header –&gt; 请求参数的获取：@RequestHeader query –&gt; 请求参数的获取：@RequestParam path（用于restful接口）–&gt; 请求参数的获取：@PathVariable body（不常用） form（不常用） dataType：参数类型，默认String，其它值dataType=”Integer” defaultValue：参数的默认值 @ApiResponses：用在请求的方法上，表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如”请求参数没填好” response：抛出异常的类 @ApiModel：主要有两种用途： 用于响应类上，表示一个返回响应数据的信息 入参实体：使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候 @ApiModelProperty：用在属性上，描述响应类的属性 **最终呈现结果： ** 如前所述：通过maven导入了swagger-ui： 12345&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 那么，启动应用后，会自动生成http://{root-path}/swagger-ui.html页面，访问后，效果如下所示： 可以在线测试接口，如通过ID查询的接口/user/query/{id}","link":"/2019/04/19/Swagger%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"},{"title":"docker命令","text":"docker基本命令 docker logs 检查排错。如果启动不起容器，可以试着检查排错 docker安装jenkins及其相关问题解决 https://www.cnblogs.com/youcong/p/10182091.html systemctl stop firewalld.service 关闭防火墙 docker inspect 容器id 查询容器信息 docker stop 容器id 停止容器id docker rm 容器id 删除容器id systemctl restart docker 重启docker容器 docker exec -it 容器ID /bin/bash 进入容器 docker rm $(sudo docker ps -a -q) 删除所有未运行的容器 docker search elasticsearch 搜索镜像文件 docker run 创建并启动一个容器，在run后面加上-d参数，则会创建一个守护式容器在后台运行。 docker ps -a 查看已经创建的容器 docker ps -s 查看已经启动的容器 docker start con_name 启动容器名为con_name的容器 docker stop con_name 停止容器名为con_name的容器 docker rm con_name 删除容器名为con_name的容器 docker rename old_name new_name 重命名一个容器 docker attach con_name 将终端附着到正在运行的容器名为con_name的容器的终端上面去，前提是创建该容器时指定了相应的sh docker logs –tail=”10” 容器名称 查询容器日志信息","link":"/2019/04/25/docker%E5%91%BD%E4%BB%A4/"},{"title":"dubbo 支持哪些通信协议？支持哪些序列化协议？","text":"面试题dubbo 支持哪些通信协议？支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？ 面试官心理分析上一个问题，说说 dubbo 的基本工作原理，那是你必须知道的，至少要知道 dubbo 分成哪些层，然后平时怎么发起 rpc 请求的，注册、发现、调用，这些是基本的。接着就可以针对底层进行深入的问问了，比如第一步就可以先问问序列化协议这块，就是平时 RPC 的时候怎么走的？ 面试题剖析序列化，就是把数据结构或者是一些对象，转换为二进制串的过程，而反序列化是将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程。###dubbo 支持不同的通信协议 dubbo 协议 默认就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 NIO 异步通信，可以支撑高并发请求。长连接，通俗点说，就是建立连接过后可以持续发送请求，无须再建立连接。 dubbo-keep-connection而短连接，每次要发送请求之前，需要先重新建立一次连接。 dubbo-not-keep-connection rmi 协议走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hessian 协议走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。 http 协议走 json 序列化。 webservice走 SOAP 文本序列化。 dubbo 支持的序列化协议dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。 说一下 Hessian 的数据结构Hessian 的对象序列化机制有 8 种原始类型： 原始二进制数据 boolean 64-bit date（64 位毫秒值的日期） 64-bit double32-bit int 64-bit long null UTF-8 编码的 string 另外还包括 3 种递归类型： list for lists and arraysmap for maps and dictionaries object for objects 还有一种特殊的类型： ref：用来表示对共享对象的引用。 为什么 PB 的效率是最高的？可能有一些同学比较习惯于 JSON or XML 数据存储格式，对于 Protocal Buffer 还比较陌生。Protocal Buffer 其实是 Google 出品的一种轻量并且高效的结构化数据存储格式，性能比 JSON、XML 要高很多。其实 PB 之所以性能如此好，主要得益于两个：第一，它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍；第二，它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。","link":"/2019/01/18/dubbo-%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%EF%BC%9F%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%EF%BC%9F/"},{"title":"java防止接口被篡改--接口签名(简单版本）续","text":"一、前言 此次来说一下另一种简单粗暴的签名方案。相对于之前的签名方案，对body、paramenter、path variable的获取都做了简化的处理。也就是说这种方式针所有数据进行了签名，并不能指定某些数据进行签名。 二、签名规则 1、线下分配appid和appsecret，针对不同的调用方分配不同的appid和appsecret 2、加入timestamp（时间戳），10分钟内数据有效 3、加入流水号nonce（防止重复提交），至少为10位。针对查询接口，流水号只用于日志落地，便于后期日志核查。 针对办理类接口需校验流水号在有效期内的唯一性，以避免重复请求。 4、加入signature，所有数据的签名信息。 以上红色字段放在请求头中。 三、签名的生成 signature字段生成规则如下。 1、数据部分 Path Variable：按照path中的字典顺序将所有value进行拼接 Parameter：按照key=values（多个value按照字典顺序拼接）字典顺序进行拼接 Body：从request inputstream中获取保存为String形式 如果存在多种数据形式，则按照body、parameter、path variable的顺序进行再拼接，得到所有数据的拼接值。 上述拼接的值记作 Y。 2、请求头部分 X=”appid=xxxnonce=xxxtimestamp=xxx” 3、生成签名 最终拼接值=XY 最后将最终拼接值按照如下方法进行加密得到签名。 signature=org.apache.commons.codec.digest.HmacUtils.AesEncodeUtil(app secret, 拼接的值); 四、签名算法实现 注：省去了X=”appid=xxxnonce=xxxtimestamp=xxx”这部分。1、自定义Request对象为什么要自定义request对象，因为我们要获取request inputstream（默认只能获取一次） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class BufferedHttpServletRequest extends HttpServletRequestWrapper { private ByteBuf buffer; private final AtomicBoolean isCached = new AtomicBoolean(); public BufferedHttpServletRequest(HttpServletRequest request, int initialCapacity) { super(request); int contentLength = request.getContentLength(); int min = Math.min(initialCapacity, contentLength); if (min &lt; 0) { buffer = Unpooled.buffer(0); } else { buffer = Unpooled.buffer(min, contentLength); } } @Override public ServletInputStream getInputStream() throws IOException { //Only returning data from buffer if it is readonly, which means the underlying stream is EOF or closed. if (isCached.get()) { return new NettyServletInputStream(buffer); } return new ContentCachingInputStream(super.getInputStream()); } public void release() { buffer.release(); } private class ContentCachingInputStream extends ServletInputStream { private final ServletInputStream is; public ContentCachingInputStream(ServletInputStream is) { this.is = is; } @Override public int read() throws IOException { int ch = this.is.read(); if (ch != -1) { //Stream is EOF, set this buffer to readonly state buffer.writeByte(ch); } else { isCached.compareAndSet(false, true); } return ch; } @Override public void close() throws IOException { //Stream is closed, set this buffer to readonly state try { is.close(); } finally { isCached.compareAndSet(false, true); } } @Override public boolean isFinished() { throw new UnsupportedOperationException(&quot;Not yet implemented!&quot;); } @Override public boolean isReady() { throw new UnsupportedOperationException(&quot;Not yet implemented!&quot;); } @Override public void setReadListener(ReadListener readListener) { throw new UnsupportedOperationException(&quot;Not yet implemented!&quot;); } }} 替换默认的request对象123456789101112131415@Configurationpublic class FilterConfig { @Bean public RequestCachingFilter requestCachingFilter() { return new RequestCachingFilter(); } @Bean public FilterRegistrationBean requestCachingFilterRegistration( RequestCachingFilter requestCachingFilter) { FilterRegistrationBean bean = new FilterRegistrationBean(requestCachingFilter); bean.setOrder(1); return bean; }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class RequestCachingFilter extends OncePerRequestFilter { private static Logger LOGGER = LoggerFactory.getLogger(RequestCachingFilter.class); @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { boolean isFirstRequest = !isAsyncDispatch(request); HttpServletRequest requestToUse = request; if (isFirstRequest &amp;&amp; !(request instanceof BufferedHttpServletRequest)) { requestToUse = new BufferedHttpServletRequest(request, 1024); } try { filterChain.doFilter(requestToUse, response); } catch (Exception e) { LOGGER.error(&quot;RequestCachingFilter&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;, e); } finally { this.printRequest(requestToUse); if (requestToUse instanceof BufferedHttpServletRequest) { ((BufferedHttpServletRequest) requestToUse).release(); } } } private void printRequest(HttpServletRequest request) { String body = StringUtils.EMPTY; try { if (request instanceof BufferedHttpServletRequest) { body = IOUtils.toString(request.getInputStream(), StandardCharsets.UTF_8); } } catch (IOException e) { LOGGER.error(&quot;printRequest 获取body异常...&quot;, e); } JSONObject requestJ = new JSONObject(); JSONObject headers = new JSONObject(); Collections.list(request.getHeaderNames()) .stream() .forEach(name -&gt; headers.put(name, request.getHeader(name))); requestJ.put(&quot;headers&quot;, headers); requestJ.put(&quot;parameters&quot;, request.getParameterMap()); requestJ.put(&quot;body&quot;, body); requestJ.put(&quot;remote-user&quot;, request.getRemoteUser()); requestJ.put(&quot;remote-addr&quot;, request.getRemoteAddr()); requestJ.put(&quot;remote-host&quot;, request.getRemoteHost()); requestJ.put(&quot;remote-port&quot;, request.getRemotePort()); requestJ.put(&quot;uri&quot;, request.getRequestURI()); requestJ.put(&quot;url&quot;, request.getRequestURL()); requestJ.put(&quot;servlet-path&quot;, request.getServletPath()); requestJ.put(&quot;method&quot;, request.getMethod()); requestJ.put(&quot;query&quot;, request.getQueryString()); requestJ.put(&quot;path-info&quot;, request.getPathInfo()); requestJ.put(&quot;context-path&quot;, request.getContextPath()); LOGGER.info(&quot;Request-Info: &quot; + JSON.toJSONString(requestJ, SerializerFeature.PrettyFormat)); }} 2、签名切面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Aspect@Componentpublic class SignatureAspect { private static final Logger LOGGER = LoggerFactory.getLogger(StringUtils.class); @Around(&quot;execution(* com..controller..*.*(..)) &quot; + &quot;&amp;&amp; (@annotation(org.springframework.web.bind.annotation.RequestMapping)&quot; + &quot;|| @annotation(org.springframework.web.bind.annotation.GetMapping)&quot; + &quot;|| @annotation(org.springframework.web.bind.annotation.PostMapping)&quot; + &quot;|| @annotation(org.springframework.web.bind.annotation.DeleteMapping)&quot; + &quot;|| @annotation(org.springframework.web.bind.annotation.PatchMapping))&quot; ) public Object doAround(ProceedingJoinPoint pjp) throws Throwable { try { this.checkSign(); return pjp.proceed(); } catch (Throwable e) { LOGGER.error(&quot;SignatureAspect&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;, e); throw e; } } private void checkSign() throws Exception { HttpServletRequest request = ((ServletRequestAttributes) (RequestContextHolder.currentRequestAttributes())).getRequest(); String oldSign = request.getHeader(&quot;X-SIGN&quot;); if (StringUtils.isBlank(oldSign)) { throw new RuntimeException(&quot;取消签名Header[X-SIGN]信息&quot;); } //获取body（对应@RequestBody） String body = null; if (request instanceof BufferedHttpServletRequest) { body = IOUtils.toString(request.getInputStream(), StandardCharsets.UTF_8); } //获取parameters（对应@RequestParam） Map&lt;String, String[]&gt; params = null; if (!CollectionUtils.isEmpty(request.getParameterMap())) { params = request.getParameterMap(); } //获取path variable（对应@PathVariable） String[] paths = null; ServletWebRequest webRequest = new ServletWebRequest(request, null); Map&lt;String, String&gt; uriTemplateVars = (Map&lt;String, String&gt;) webRequest.getAttribute( HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE, RequestAttributes.SCOPE_REQUEST); if (!CollectionUtils.isEmpty(uriTemplateVars)) { paths = uriTemplateVars.values().toArray(new String[]{}); } try { String newSign = SignUtil.sign(body, params, paths); if (!newSign.equals(oldSign)) { throw new RuntimeException(&quot;签名不一致...&quot;); } } catch (Exception e) { throw new RuntimeException(&quot;验签出错...&quot;, e); } }} 分别获取了request inputstream中的body信息、parameter信息、path variable信息。签名核心工具类 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SignUtil { private static final String DEFAULT_SECRET = &quot;1qaz@WSX#$%&amp;&quot;; public static String sign(String body, Map&lt;String, String[]&gt; params, String[] paths) { StringBuilder sb = new StringBuilder(); if (StringUtils.isNotBlank(body)) { sb.append(body).append('#'); } if (!CollectionUtils.isEmpty(params)) { params.entrySet() .stream() .sorted(Map.Entry.comparingByKey()) .forEach(paramEntry -&gt; { String paramValue = String.join(&quot;,&quot;, Arrays.stream(paramEntry.getValue()).sorted().toArray(String[]::new)); sb.append(paramEntry.getKey()).append(&quot;=&quot;).append(paramValue).append('#'); }); } if (ArrayUtils.isNotEmpty(paths)) { String pathValues = String.join(&quot;,&quot;, Arrays.stream(paths).sorted().toArray(String[]::new)); sb.append(pathValues); } String createSign = HmacUtils.hmacSha256Hex(DEFAULT_SECRET, sb.toString()); return createSign; } public static void main(String[] args) { String body = &quot;{\\n&quot; + &quot;\\t\\&quot;name\\&quot;: \\&quot;hjzgg\\&quot;,\\n&quot; + &quot;\\t\\&quot;age\\&quot;: 26\\n&quot; + &quot;}&quot;; Map&lt;String, String[]&gt; params = new HashMap&lt;&gt;(); params.put(&quot;var3&quot;, new String[]{&quot;3&quot;}); params.put(&quot;var4&quot;, new String[]{&quot;4&quot;}); String[] paths = new String[]{&quot;1&quot;, &quot;2&quot;}; System.out.println(sign(body, params, paths)); }} 五、签名验证 简单写了一个包含body参数，parameter参数，path variable参数的controller123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping(&quot;example&quot;)public class ExampleController { @PostMapping(value = &quot;test/{var1}/{var2}&quot;, produces = MediaType.ALL_VALUE) public String myController(@PathVariable String var1 , @PathVariable String var2 , @RequestParam String var3 , @RequestParam String var4 , @RequestBody User user) { return String.join(&quot;,&quot;, var1, var2, var3, var4, user.toString()); } private static class User { private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return new ToStringBuilder(this) .append(&quot;name&quot;, name) .append(&quot;age&quot;, age) .toString(); } }} 通过 签名核心工具类SignUtil 的main方法生成一个签名，通过如下命令验证 12345678curl -X POST \\ 'http://localhost:8080/example/test/1/2?var3=3&amp;var4=4' \\ -H 'Content-Type: application/json' \\ -H 'X-SIGN: 4955125a3aa2782ab3def51dc958a34ca46e5dbb345d8808590fb53e81cc2687' \\ -d '{ &quot;name&quot;: &quot;hjzgg&quot;, &quot;age&quot;: 26}' 此文引自 https://www.cnblogs.com/hujunzheng/p/10178584.html","link":"/2019/05/14/java%E9%98%B2%E6%AD%A2%E6%8E%A5%E5%8F%A3%E8%A2%AB%E7%AF%A1%E6%94%B9-%E6%8E%A5%E5%8F%A3%E7%AD%BE%E5%90%8D-%E7%AE%80%E5%8D%95%E7%89%88%E6%9C%AC%EF%BC%89%E7%BB%AD/"},{"title":"jenkins","text":"Jenkins 是 Devops 神器，本篇文章介绍如何安装和使用 Jenkins 部署 Spring Boot 项目 Jenkins 搭建、部署分为四个步骤； 第一步，Jenkins 安装 第二步，插件安装和配置 第三步，Push SSH 第四步，部署项目 第一步 ，Jenkins 安装准备环境： JDK:1.8Jenkins:2.83Centos:7.3maven 3.5 Jdk 默认已经安装完成 配置 Maven版本要求 Maven3.5.0 软件下载 1wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz 安装 1234## 解压tar vxf apache-maven-3.5.0-bin.tar.gz## 移动mv apache-maven-3.5.0 /usr/local/maven3 修改环境变量，在/etc/profile中添加以下几行 123MAVEN_HOME=/usr/local/maven3export MAVEN_HOMEexport PATH=${PATH}:${MAVEN_HOME}/bin 记得执行source /etc/profile使环境变量生效。 验证最后运行mvn -v验证maven是否安装成功 配置防护墙关闭防护墙 12345678#centos7systemctl stop firewalld.service==============================#以下为：centOS 6.5关闭防火墙步骤#关闭命令： service iptables stop #永久关闭防火墙：chkconfig iptables off 两个命令同时运行，运行完成后查看防火墙关闭状态 1service iptables status Jenkins 安装下载 12cd /optwget http://mirrors.jenkins.io/war/2.83/jenkins.war 启动服务 1java -jar jenkins.war &amp; Jenkins 就启动成功了！它的war包自带Jetty服务器 第一次启动 Jenkins 时，出于安全考虑，Jenkins 会自动生成一个随机的按照口令。注意控制台输出的口令，复制下来，然后在浏览器输入密码： 12345678910111213141516INFO: ***************************************************************************************************************************************************************************************Jenkins initial setup is required. An admin user has been created and a password generated.Please use the following password to proceed to installation:0cca37389e6540c08ce6e4c96f46da0fThis may also be found at: /root/.jenkins/secrets/initialAdminPassword*************************************************************************************************************************************************************************************** 访问浏览器访问：http://localhost:8080/ 输入：0cca37389e6540c08ce6e4c96f46da0f 进入用户自定义插件界面，建议选择安装官方推荐插件，因为安装后自己也得安装: 接下来是进入插件安装进度界面: 插件一次可能不会完全安装成功，可以点击Retry再次安装。直到全部安装成功 等待一段时间之后，插件安装完成，配置用户名密码: 输入：admin/admin 系统管理-》全局工具配置 jdk路径， 第二步，插件安装和配置有很多插件都是选择的默认的安装的，所以现在需要我们安装的插件不多，Git plugin 和 Maven Integration plugin，publish over SSH。 插件安装：系统管理 &gt; 插件管理 &gt; 可选插件,勾选需要安装的插件，点击直接安装或者下载重启后安装 配置全局变量系统管理 &gt; 全局工具配置 JDK 配置本地 JDK 的路径，去掉勾选自动安装 Maven 配置本地maven的路径，去掉勾选自动安装 其它内容可以根据自己的情况选择安装。 使用密钥方式登录目标发布服务器ssh 的配置可使用密钥，也可以使用密码，这里我们使用密钥来配置，在配置之前先配置好jenkins服务器和应用服务器的密钥认证Jenkins服务器上生成密钥对，使用ssh-keygen -t rsa命令 输入下面命令 一直回车，一个矩形图形出现就说明成功，在~/.ssh/下会有私钥id_rsa和公钥id_rsa.pub 1ssh-keygen -t rsa 将jenkins服务器的公钥id_rsa.pub中的内容复制到应用服务器 的~/.ssh/下的 authorized_keys文件 12ssh-copy-id -i id_rsa.pub 192.168.0.xxchmod 644 authorized_keys 在应用服务器上重启 ssh 服务，service sshd restart现在 Jenkins 服务器可免密码直接登陆应用服务器 之后在用 ssh B尝试能否免密登录 B 服务器，如果还是提示需要输入密码，则有以下原因 a. 非 root 账户可能不支持 ssh 公钥认证（看服务器是否有限制） b. 传过来的公钥文件权限不够，可以给这个文件授权下 chmod 644 authorized_keys c. 使用 root 账户执行 ssh-copy-id -i ~/.ssh/id_rsa.pub 这个指令的时候如果需要输入密码则要配置sshd_config 123vi /etc/ssh/sshd_config#内容PermitRootLogin no 修改完后要重启 sshd 服务 1service sshd restart 最后，如果可以 SSH IP 免密登录成功说明 SSH 公钥认证成功。 上面这种方式比较复杂，其实在 Jenkins 后台直接添加操作即可，参考下面方式 使用用户名+密码方式登录目标发布服务器(1)点击”高级”展开配置 (2)配置SSH的登陆密码 配置完成后可点击“Test Configuration”测试到目标主机的连接，出现”success“则成功连接，如果有多台应用服务器，可以点击”增加“，配置多个“SSH Servers” 点击“保存”以保存配置。 第三步，Push SSH系统管理 &gt; 系统设置 选择 Publish over SSH Passphrase 不用设置Path to key 写上生成的ssh路径：/root/.ssh/id_rsa 下面的 SSH Servers 是重点 Name 随意起名代表这个服务，待会要根据它来选择 Hostname 配置应用服务器的地址 Username 配置 linux 登陆用户名 Remote Directory 不填 点击下方增加可以添加多个应用服务器的地址 jenkins+docker+nodejs项目的自动部署环境https://my.oschina.net/gaochunzhang/blog/2246923 构建环境如果没有Node选项，前往系统管理–Global Tool Configuration设置 选择构建环境： 构建环境 Build Authorization Token Root Plugin 插件使用说明此插件是用来让你的远程git发布文件通知jenkins的时候允许匿名访问，原本路径为job/NAME/build?token=SECRET。不幸的是，Jenkins按层次结构检查URI，并且访问job/NAME/ 这个的时候需要进行身份验证。 此插件提供备用URI模式，该模式不受通常的整体或作业读取权限的约束。只需发出Http GET或POST即可buildByToken/build?job=NAME&amp;token=SECRET。无论安全设置如何，匿名用户都可以访问此URI，因此您只需要正确的令牌。 Build Authorization Token Root Plugin 插件使用说明 使用例子 buildByToken/build?job=NAME&amp;token=SECRET 第四步，部署项目首页点击新建：输入项目名称 下方选择构建一个 Maven 项目，点击确定。 勾选丢弃旧的构建，选择是否备份被替换的旧包。我这里选择备份最近的10个 源码管理，选择 SVN，配置 SVN 相关信息，点击 add 可以输入 SVN 的账户和密码 SVN 地址：http://192.168.0.xx/svn/xxx@HEAD,`@HEAD`意思取最新版本 构建环境中勾选“Add timestamps to the Console Output”，代码构建的过程中会将日志打印出来 在 Build 中输入打包前的 mvn 命令，如： 1clean install -Dmaven.test.skip=true -Ptest 意思是：排除测试的包内容，使用后缀为 test 的配置文件。 Post Steps 选择 Run only if build succeeds 点击Add post-build step，选择 Send files or execute commands over SSH Name 选择上面配置的 Push SSH Source files配置:target/xxx-0.0.1-SNAPSHOT.jar 项目jar包名Remove prefix:target/Remote directory:Jenkins-in/ 代码应用服务器的目录地址，Exec command：Jenkins-in/xxx.sh 应用服务器对应的脚本。 需要在应用服务器创建文件夹：Jenkins-in，在文件夹中复制一下脚本内容：xxx.sh 12345678910111213141516171819202122232425DATE=$(date +%Y%m%d)export JAVA_HOME PATH CLASSPATHJAVA_HOME=/usr/java/jdk1.8.0_131PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATHDIR=/root/xxxJARFILE=xxx-0.0.1-SNAPSHOT.jarif [ ! -d $DIR/backup ];then mkdir -p $DIR/backupficd $DIRps -ef | grep $JARFILE | grep -v grep | awk '{print $2}' | xargs kill -9mv $JARFILE backup/$JARFILE$DATEmv -f /root/Jenkins-in/$JARFILE .java -jar $JARFILE &gt; out.log &amp;if [ $? = 0 ];then sleep 30 tail -n 50 out.logficd backup/ls -lt|awk 'NR&gt;5{print $NF}'|xargs rm -rf 1234567891011121314151617181920#!/bin/bashJAR_NAME=demo-0.0.1SERVER_NAME=mmly# 项目目录JAR_PAHT=/var/jenkins_home/workspace/mmly/targetecho &quot;查询进程id--》$JAR_NAME&quot;PID=$(ps -ef | grep $JAR_NAME.jar | grep -v grep | awk '{ print $2 }')if [ -z &quot;$PID&quot; ]then echo Application is already stoppedelse echo kill $PID kill $PIDfi# echo &quot;复制jar包到执行目录：cp &quot;nohup java -jar $JAR_PAHT/$JAR_NAME.jar &gt; myout.file 2&gt;&amp;1 &amp; 这段脚本的意思，就是 kill 旧项目，删除旧项目，启动新项目，备份老项目。 全文完。 参考：https://blog.csdn.net/LLQ_200/article/details/76921487","link":"/2019/04/25/jenkins/"},{"title":"为什么处理排序的数组要比非排序的快","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 为什么处理排序的数组要比非排序的快问题 以下是**c++**的一段非常神奇的代码。由于一些奇怪原因，对数据排序后奇迹般的让这段代码快了近6倍！！ 1234567891011121314151617181920212223242526272829303132333435#include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main(){ // Generate data const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; // !!! With this, the next loop runs faster std::sort(data, data + arraySize); // Test clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) { // Primary loop for (unsigned c = 0; c &lt; arraySize; ++c) { if (data[c] &gt;= 128) sum += data[c]; } } double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; &quot;sum = &quot; &lt;&lt; sum &lt;&lt; std::endl;} 没有std::sort(data, data + arraySize);,这段代码运行了11.54秒. 有这个排序的代码，则运行了1.93秒.我原以为这也许只是语言或者编译器的不一样的问题，所以我又用Java试了一下。 以下是Java代码段 123456789101112131415161718192021222324252627282930313233343536import java.util.Arrays;import java.util.Random;public class Main{ public static void main(String[] args) { // Generate data int arraySize = 32768; int data[] = new int[arraySize]; Random rnd = new Random(0); for (int c = 0; c &lt; arraySize; ++c) data[c] = rnd.nextInt() % 256; // !!! With this, the next loop runs faster Arrays.sort(data); // Test long start = System.nanoTime(); long sum = 0; for (int i = 0; i &lt; 100000; ++i) { // Primary loop for (int c = 0; c &lt; arraySize; ++c) { if (data[c] &gt;= 128) sum += data[c]; } } System.out.println((System.nanoTime() - start) / 1000000000.0); System.out.println(&quot;sum = &quot; + sum); }} 结果相似，没有很大的差别。 我首先得想法是排序把数据放到了cache中，但是我下一个想法是我之前的想法是多么傻啊，因为这个数组刚刚被构造。 到底这是为什么呢？ 为什么排序的数组会快于没有排序的数组？ 这段代码是为了求一些无关联的数据的和，排不排序应该没有关系啊。 回答什么是分支预测？看看这个铁路分岔口Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license. 为了理解这个问题，想象一下，如果我们回到19世纪. 你是在分岔口的操作员。当你听到列车来了，你没办法知道这两条路哪一条是正确的。然后呢，你让列车停下来，问列车员哪条路是对的，然后你才转换铁路方向。 火车很重有很大的惯性。所以他们得花费很长的时间开车和减速。 是不是有个更好的办法呢？你猜测哪个是火车正确的行驶方向 如果你猜对了，火车继续前行 如果你猜错了，火车得停下来，返回去，然后你再换条路。 如果你每次都猜对了，那么火车永远不会停下来。如果你猜错太多次，那么火车会花费很多时间来停车，返回，然后再启动 考虑一个if条件语句：在处理器层面上，这是一个分支指令：当处理器看到这个分支时，没办法知道哪个将是下一条指令。该怎么办呢？貌似只能暂停执行，直到前面的指令完成，然后再继续执行正确的下一条指令？现代处理器很复杂，因此它需要很长的时间”热身”、”冷却” 是不是有个更好的办法呢？你猜测下一个指令在哪！ 如果你猜对了，你继续执行。 如果你猜错了，你需要flush the pipeline，返回到那个出错的分支，然后你才能继续。 如果你每次都猜对了，那么你永远不会停如果你猜错了太多次，你就要花很多时间来滚回，重启。 这就是分支预测。我承认这不是一个好的类比，因为火车可以用旗帜来作为方向的标识。但是在电脑中，处理器不能知道哪一个分支将走到最后。 所以怎样能很好的预测，尽可能地使火车必须返回的次数变小？你看看火车之前的选择过程，如果这个火车往左的概率是99%。那么你猜左，反之亦然。如果每3次会有1次走这条路，那么你也按这个三分之一的规律进行。 换句话说，你试着定下一个模式，然后按照这个模式去执行。这就差不多是分支预测是怎么工作的。 大多数的应用都有很好的分支预测。所以现代的分支预测器通常能实现大于90%的命中率。但是当面对没有模式识别、无法预测的分支，那分支预测基本就没用了。 如果你想知道更多:Branch predictor” article on Wikipedia. 有了前面的说明，问题的来源就是这个if条件判断语句12if (data[c] &gt;= 128) sum += data[c]; 注意到数据是分布在0到255之间的。当数据排好序后，基本上前一半大的的数据不会进入这个条件语句，而后一半的数据，会进入该条件语句. 连续的进入同一个执行分支很多次，这对分支预测是非常友好的。可以更准确地预测，从而带来更高的执行效率。 快速理解一下1234567T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N N N N N ... N N T T T ... T T T ... = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT (easy to predict) 但是当数据是完全随机的，分支预测就没什么用了。因为他无法预测随机的数据。因此就会有大概50%的概率预测出错。 1234data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118, 14, 150, 177, 182, 133, ...branch = T, T, N, T, T, T, T, N, T, N, N, T, T, T, N ... = TTNTTTTNTNNTTTN ... (completely random - hard to predict) 我们能做些什么呢如果编译器无法优化带条件的分支，如果你愿意牺牲代码的可读性换来更好的性能的话，你可以用下面的一些技巧。 把 12if (data[c] &gt;= 128) sum += data[c]; 替换成 12int t = (data[c] - 128) &gt;&gt; 31;sum += ~t &amp; data[c]; 这消灭了分支，把它替换成按位操作. （说明：这个技巧不是非常严格的等同于原来的if条件语句。但是在data[]当前这些值下是OK的） 使用的设备参数是：Core i7 920 @ 3.5 GHzC++ - Visual Studio 2010 - x64 Release 1234567891011// Branch - Randomseconds = 11.777// Branch - Sortedseconds = 2.352// Branchless - Randomseconds = 2.564// Branchless - Sortedseconds = 2.587 Java - Netbeans 7.1.1 JDK 7 - x64 1234567891011// Branch - Randomseconds = 10.93293813// Branch - Sortedseconds = 5.643797077// Branchless - Randomseconds = 3.113581453// Branchless - Sortedseconds = 3.186068823 结论： 用了分支(if)：没有排序和排序的数据，效率有很大的区别 用了上面提到的按位操作替换：排序与否，效率没有很大的区别 在使用C++的情况下，按位操作还是要比排好序的分支操作要慢。 一般的建议是尽量避免在关键循环上出现对数据很依赖的分支。（就像这个例子） 更新： GCC 4.6.1 用了 -O3 or -ftree-vectorize，在64位机器上，数据有没有排序，都是一样快。 ………等各种例子 说明了现代编译器越发成熟强大，可以在这方面充分优化代码的执行效率 相关内容CPU的流水线指令执行 想象现在有一堆指令等待CPU去执行，那么CPU是如何执行的呢？具体的细节可以找一本计算机组成原理来看。CPU执行一堆指令时，并不是单纯地一条一条取出来执行，而是按照一种流水线的方式，在CPU真正指令前，这条指令就像工厂里流水线生产的产品一样，已经被经过一些处理。简单来说，一条指令可能经过过程：取指(Fetch)、解码(Decode)、执行(Execute)、放回(Write-back)。 假设现在有指令序列ABCDEFG。当CPU正在执行(execute)指令A时，CPU的其他处理单元（CPU是由若干部件构成的）其实已经预先处理到了指令A后面的指令，例如B可能已经被解码，C已经被取指。这就是流水线执行，这可以保证CPU高效地执行指令。 分支预测 如上所说，CPU在执行一堆顺序执行的指令时，因为对于执行指令的部件来说，其基本不需要等待，因为诸如取指、解码这些过程早就被做了。但是，当CPU面临非顺序执行的指令序列时，例如之前提到的跳转指令，情况会怎样呢？ 取指、解码这些CPU单元并不知道程序流程会跳转，只有当CPU执行到跳转指令本身时，才知道该不该跳转。所以，取指解码这些单元就会继续取跳转指令之后的指令。当CPU执行到跳转指令时，如果真的发生了跳转，那么之前的预处理（取指、解码）就白做了。这个时候，CPU得从跳转目标处临时取指、解码，然后才开始执行，这意味着：CPU停了若干个时钟周期！ 这其实是个问题，如果CPU的设计放任这个问题，那么其速度就很难提升起来。为此，人们发明了一种技术，称为branch prediction，也就是分支预测。分支预测的作用，就是预测某个跳转指令是否会跳转。而CPU就根据自己的预测到目标地址取指令。这样，即可从一定程度提高运行速度。当然，分支预测在实现上有很多方法。 stackoverflow链接： 这个问题的所有回答中，最高的回答，获取了上万个vote，还有很多个回答，非常疯狂，大家觉得不过瘾可以移步到这里查看 http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array 引用于 https://github.com/giantray/stackoverflow-java-top-qa 欢迎关注 http://yunlongn.github.io","link":"/2019/05/22/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%84%E7%90%86%E6%8E%92%E5%BA%8F%E7%9A%84%E6%95%B0%E7%BB%84%E8%A6%81%E6%AF%94%E9%9D%9E%E6%8E%92%E5%BA%8F%E7%9A%84%E5%BF%AB/"},{"title":"为什么说Java中只有值传递","text":"为什么说Java中只有值传递对于初学者来说，要想把这个问题回答正确，是比较难的。在第二天整理答案的时候，我发现我竟然无法通过简单的语言把这个事情描述的很容易理解，遗憾的是，我也没有在网上找到哪篇文章可以把这个事情讲解的通俗易懂。所以，就有了我写这篇文章的初衷。这篇文章中，我从什么是方法的实际参数和形式参数开始，给你讲解为什么说Java中只有值传递。 辟谣时间关于这个问题，在StackOverflow上也引发过广泛的讨论，看来很多程序员对于这个问题的理解都不尽相同，甚至很多人理解的是错误的。还有的人可能知道Java中的参数传递是值传递，但是说不出来为什么。 在开始深入讲解之前，有必要纠正一下大家以前的那些错误看法了。如果你有以下想法，那么你有必要好好阅读本文。 错误理解一：值传递和引用传递，区分的条件是传递的内容，如果是个值，就是值传递。如果是个引用，就是引用传递。 错误理解二：Java是引用传递。 错误理解三：传递的参数如果是普通类型，那就是值传递，如果是对象，那就是引用传递。 实参与形参我们都知道，在Java中定义方法的时候是可以定义参数的。比如Java中的main方法，public static void main(String[] args)，这里面的args就是参数。参数在程序语言中分为形式参数和实际参数。 形式参数：是在定义函数名和函数体的时候使用的参数,目的是用来接收调用该函数时传入的参数。 实际参数：在调用有参函数时，主调函数和被调函数之间有数据传递关系。在主调函数中调用一个函数时，函数名后面括号中的参数称为“实际参数”。 简单举个例子： 12345678public static void main(String[] args) { ParamTest pt = new ParamTest(); pt.sout(&quot;Hollis&quot;);//实际参数为 Hollis}public void sout(String name) { //形式参数为 name System.out.println(name);} 实际参数是调用有参方法的时候真正传递的内容，而形式参数是用于接收实参内容的参数。 值传递与引用传递上面提到了，当我们调用一个有参函数的时候，会把实际参数传递给形式参数。但是，在程序语言中，这个传递过程中传递的两种情况，即值传递和引用传递。我们来看下程序语言中是如何定义和区分值传递和引用传递的。 值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递（pass by reference）是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 有了上面的概念，然后大家就可以写代码实践了，来看看Java中到底是值传递还是引用传递 ，于是，最简单的一段代码出来了： 123456789101112public static void main(String[] args) { ParamTest pt = new ParamTest(); int i = 10; pt.pass(10); System.out.println(&quot;print in main , i is &quot; + i);}public void pass(int j) { j = 20; System.out.println(&quot;print in pass , j is &quot; + j);} 上面的代码中，我们在pass方法中修改了参数j的值，然后分别在pass方法和main方法中打印参数的值。输出结果如下： 12print in pass , j is 20print in main , i is 10 可见，pass方法内部对name的值的修改并没有改变实际参数i的值。那么，按照上面的定义，有人得到结论：Java的方法传递是值传递。 但是，很快就有人提出质疑了（哈哈，所以，不要轻易下结论咯。）。然后，他们会搬出以下代码： 1234567891011121314public static void main(String[] args) { ParamTest pt = new ParamTest(); User hollis = new User(); hollis.setName(&quot;Hollis&quot;); hollis.setGender(&quot;Male&quot;); pt.pass(hollis); System.out.println(&quot;print in main , user is &quot; + hollis);}public void pass(User user) { user.setName(&quot;hollischuang&quot;); System.out.println(&quot;print in pass , user is &quot; + user);} 同样是一个pass方法，同样是在pass方法内修改参数的值。输出结果如下： 12print in pass , user is User{name='hollischuang', gender='Male'}print in main , user is User{name='hollischuang', gender='Male'} 经过pass方法执行后，实参的值竟然被改变了，那按照上面的引用传递的定义，实际参数的值被改变了，这不就是引用传递了么。于是，根据上面的两段代码，有人得出一个新的结论：Java的方法中，在传递普通类型的时候是值传递，在传递对象类型的时候是引用传递。 但是，这种表述仍然是错误的。不信你看下面这个参数类型为对象的参数传递： 123456789101112public static void main(String[] args) { ParamTest pt = new ParamTest(); String name = &quot;Hollis&quot;; pt.pass(name); System.out.println(&quot;print in main , name is &quot; + name);}public void pass(String name) { name = &quot;hollischuang&quot;; System.out.println(&quot;print in pass , name is &quot; + name);} 上面的代码输出结果为 12print in pass , name is hollischuangprint in main , name is Hollis 这又作何解释呢？同样传递了一个对象，但是原始参数的值并没有被修改，难道传递对象又变成值传递了？ Java中的值传递上面，我们举了三个例子，表现的结果却不一样，这也是导致很多初学者，甚至很多高级程序员对于Java的传递类型有困惑的原因。 其实，我想告诉大家的是，上面的概念没有错，只是代码的例子有问题。来，我再来给大家画一下概念中的重点，然后再举几个真正恰当的例子。 值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递（pass by reference）是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 那么，我来给大家总结一下，值传递和引用传递之前的区别的重点是什么。 我们上面看过的几个pass的例子中，都只关注了实际参数内容是否有改变。如传递的是User对象，我们试着改变他的name属性的值，然后检查是否有改变。其实，在实验方法上就错了，当然得到的结论也就有问题了。 为什么说实验方法错了呢？这里我们来举一个形象的例子。再来深入理解一下值传递和引用传递，然后你就知道为啥错了。 你有一把钥匙，当你的朋友想要去你家的时候，如果你直接把你的钥匙给他了，这就是引用传递。这种情况下，如果他对这把钥匙做了什么事情，比如他在钥匙上刻下了自己名字，那么这把钥匙还给你的时候，你自己的钥匙上也会多出他刻的名字。 你有一把钥匙，当你的朋友想要去你家的时候，你复刻了一把新钥匙给他，自己的还在自己手里，这就是值传递。这种情况下，他对这把钥匙做什么都不会影响你手里的这把钥匙。 但是，不管上面那种情况，你的朋友拿着你给他的钥匙，进到你的家里，把你家的电视砸了。那你说你会不会受到影响？而我们在pass方法中，改变user对象的name属性的值的时候，不就是在“砸电视”么。 还拿上面的一个例子来举例，我们真正的改变参数，看看会发生什么？ 12345678910111213141516public static void main(String[] args) { ParamTest pt = new ParamTest(); User hollis = new User(); hollis.setName(&quot;Hollis&quot;); hollis.setGender(&quot;Male&quot;); pt.pass(hollis); System.out.println(&quot;print in main , user is &quot; + hollis);}public void pass(User user) { user = new User(); user.setName(&quot;hollischuang&quot;); user.setGender(&quot;Male&quot;); System.out.println(&quot;print in pass , user is &quot; + user);} 上面的代码中，我们在pass方法中，改变了user对象，输出结果如下： 12print in pass , user is User{name='hollischuang', gender='Male'}print in main , user is User{name='Hollis', gender='Male'} 我们来画一张图，看一下整个过程中发生了什么，然后我再告诉你，为啥Java中只有值传递。 稍微解释下这张图，当我们在main中创建一个User对象的时候，在堆中开辟一块内存，其中保存了name和gender等数据。然后hollis持有该内存的地址0x123456（图1）。当尝试调用pass方法，并且hollis作为实际参数传递给形式参数user的时候，会把这个地址0x123456交给user，这时，user也指向了这个地址（图2）。然后在pass方法内对参数进行修改的时候，即user = new User();，会重新开辟一块0X456789的内存，赋值给user。后面对user的任何修改都不会改变内存0X123456的内容（图3）。 上面这种传递是什么传递？肯定不是引用传递，如果是引用传递的话，在user=new User()的时候，实际参数的引用也应该改为指向0X456789，但是实际上并没有。 通过概念我们也能知道，这里是把实际参数的引用的地址复制了一份，传递给了形式参数。所以，上面的参数其实是值传递，把实参对象引用的地址当做值传递给了形式参数。 我们再来回顾下之前的那个“砸电视”的例子，看那个例子中的传递过程发生了什么。 同样的，在参数传递的过程中，实际参数的地址0X1213456被拷贝给了形参，只是，在这个方法中，并没有对形参本身进行修改，而是修改的形参持有的地址中存储的内容。 所以，值传递和引用传递的区别并不是传递的内容。而是实参到底有没有被复制一份给形参。在判断实参内容有没有受影响的时候，要看传的的是什么，如果你传递的是个地址，那么就看这个地址的变化会不会有影响，而不是看地址指向的对象的变化。就像钥匙和房子的关系。 那么，既然这样，为啥上面同样是传递对象，传递的String对象和User对象的表现结果不一样呢？我们在pass方法中使用name = &quot;hollischuang&quot;;试着去更改name的值，阴差阳错的直接改变了name的引用的地址。因为这段代码，会new一个String，在把引用交给name，即等价于name = new String(&quot;hollischuang&quot;);。而原来的那个”Hollis”字符串还是由实参持有着的，所以，并没有修改到实际参数的值。 所以说，Java中其实还是值传递的，只不过对于对象参数，值的内容是对象的引用。 总结无论是值传递还是引用传递，其实都是一种求值策略(Evaluation strategy)。在求值策略中，还有一种叫做按共享传递(call by sharing)。其实Java中的参数传递严格意义上说应该是按共享传递。 按共享传递，是指在调用函数时，传递给函数的是实参的地址的拷贝（如果实参在栈中，则直接拷贝该值）。在函数内部对参数进行操作时，需要先拷贝的地址寻找到具体的值，再进行操作。如果该值在栈中，那么因为是直接拷贝的值，所以函数内部对参数进行操作不会对外部变量产生影响。如果原来拷贝的是原值在堆中的地址，那么需要先根据该地址找到堆中对应的位置，再进行操作。因为传递的是地址的拷贝所以函数内对值的操作对外部变量是可见的。 简单点说，Java中的传递，是值传递，而这个值，实际上是对象的引用。 而按共享传递其实只是按值传递的一个特例罢了。所以我们可以说Java的传递是按共享传递，或者说Java中的传递是值传递。 参考资料Evaluation strategy 关于值传递和引用传递 按值传递、按引用传递、按共享传递 Is Java “pass-by-reference” or “pass-by-value”?","link":"/2019/06/13/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4Java%E4%B8%AD%E5%8F%AA%E6%9C%89%E5%80%BC%E4%BC%A0%E9%80%92/"},{"title":"实现一个免费的图片上传Web Server","text":"一. 框架 选用express框架 12npm initnpm install express --save 二. 简单测试请求 在当前目录新建index.js文件 12345678910const express = require(&quot;express&quot;);const app = express();app.get(&quot;/&quot;, (req, res) =&gt; { res.send(&quot;Hello Node.js&quot;);});const port = 3000;app.listen(port); 复制代码在终端输入： node index.js 在浏览器中打开 127.0.0.1:3000 三.使用form上传图片12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot;&gt; &lt;title&gt;upload&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;http://127.0.0.1:3000/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;div&gt; &lt;input type=&quot;file&quot; name=&quot;avatar&quot; accept=&quot;image/*&quot;&gt; &lt;/div&gt; &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 将index.js中的接口更新成 123app.post(&quot;/upload&quot;, (req, res) =&gt; { res.send('上传成功')}); 注意：index.js中的文件只要改了，就要重新启动服务 试着上传一下： 四. 将前端发送的图片储存在服务器中 这里需要用到一个叫multer的库 1npm install multer --save 根据他的文档，改一下index.js: 1234567891011121314151617const express = require(&quot;express&quot;);const multer = require(&quot;multer&quot;);// 这里定义图片储存的路径，是以当前文件为基本目录const upload = multer({ dest: &quot;uploads/&quot; });const app = express();/* upload.single('avatar') 接受以avatar命名的文件，也就是input中的name属性的值 avatar这个文件的信息可以冲req.file中获取*/app.post(&quot;/upload&quot;, upload.single(&quot;avatar&quot;), (req, res) =&gt; { console.log(req.file); res.send(&quot;上传成功&quot;);});const port = 3000;app.listen(port); 改完之后重新启动服务，再重新上传： 可以看到req.file中就是上传的文件信息。 同时，你会发现当前目录下，会多一个文件夹叫uoloads 那个很长名字的文件，就是刚刚前端传的图片。只要改一下后缀名就可以预览了： 五. 将储存的图片名返回给前端一般上传完头像会有一个预览功能，那么只需要后端将上传后的图片名发送给前端，前端重新请求一下图片就好了，前面都是用form默认的提交，这个提交存在一个问题就是，提交完成后页面会发生跳转。所以现在一般都是用ajax进行上传。 123456789101112131415161718// js代码upload.addEventListener('submit', (e) =&gt; { // 阻止form 的默认行为 e.preventDefault(); // 创建FormData对象 var formData = new FormData(); var fileInput = document.querySelector('input[name=&quot;avatar&quot;]'); formData.append(fileInput.name, fileInput.files[0]); // 创建XMLHttpRequest var xhr = new XMLHttpRequest(); xhr.open('POST', upload.action); xhr.onload = function() { console.log(xhr.response) } xhr.send(formData);}) 小提示：如果HTML的元素有id属性，那么可以不用document.querySelector去选中它，可以直接使用，就像全局变量一样。 1234// index.jsapp.post(&quot;/upload&quot;, upload.single(&quot;avatar&quot;), (req, res) =&gt; { res.json({name: req.file.filename }); // 使用json格式返回数据。 }); 这时候重新发送，会出现一个问题： 由于代码是写在 JS Bin上的，使用AJAX请求不同域名的接口，会出现跨域情况，解决这个问题需要，在index.js中加上一个头部，就是报错信息中的Access-Control-Allow-Origin： 1234app.post(&quot;/upload&quot;, upload.single(&quot;avatar&quot;), (req, res) =&gt; { res.set('Access-Control-Allow-Origin', '*'); res.json({name: req.file.filename });}); * 表示所有其他域名都可访问，也可以将*改为其他允许的域名。 重新发送： 这样成功的上传了图片，并且拿到了上传后的图片名。 这里可以使用一个库cors，来完成添加响应头的操作： npm install cors –save 修改index.js 123456789101112131415161718const express = require(&quot;express&quot;);const multer = require(&quot;multer&quot;);const cors = require('cors'); // 新增// 这里定义图片储存的路径，是以当前文件为基本目录const upload = multer({ dest: &quot;uploads/&quot; });const app = express();app.use(cors()); // 新增/* upload.single('avatar') 接受以avatar命名的文件，也就是input中的name属性的值 avatar这个文件的信息可以冲req.file中获取*/app.post(&quot;/upload&quot;, upload.single(&quot;avatar&quot;), (req, res) =&gt; { res.json({name: req.file.filename });});const port = 3000;app.listen(port); 六. 展示上传后的图片新定义一个接口： 123456789101112app.get(&quot;/preview/:name&quot;, (req, res) =&gt; { res.sendFile(`uploads/${req.params.name}`, { root: __dirname, headers:{ 'Content-Type': 'image/jpeg', }, }, (error)=&gt;{ if(error){ res.status(404).send('Not found') } });}); /preview:name 这种方式定义接口的路径，请求过来的时候，就可以从 req.params.name 中拿到 /preview/xxxx 中的xxxx了。修改下HTML: 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot;&gt; &lt;title&gt;JS Bin&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form id=&quot;upload&quot; action=&quot;http://127.0.0.1:3000/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;div&gt; &lt;input type=&quot;file&quot; name=&quot;avatar&quot; accept=&quot;image/*&quot;&gt; &lt;/div&gt; &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt; &lt;/form&gt; &lt;img src=&quot;&quot; id=&quot;avatarImg&quot;&gt; &lt;!-- 新增 --&gt;&lt;/body&gt;&lt;/html&gt; 改下js 123456789101112131415161718upload.addEventListener('submit', (e) =&gt; { // 阻止form 的默认行为 e.preventDefault(); // 创建FormData对象 var formData = new FormData(); var fileInput = document.querySelector('input[name=&quot;avatar&quot;]'); formData.append(fileInput.name, fileInput.files[0]); // 创建XMLHttpRequest var xhr = new XMLHttpRequest(); xhr.open('POST', upload.action); xhr.onload = function() { var imgName = JSON.parse(xhr.response).name; // 新增 avatarImg.setAttribute('src', 'http://127.0.0.1:3000/preview/' + imgName); // 新增 } xhr.send(formData);}) 结果： 六. 将代码部署到Heroku Heroku是一个支持多种编程语言的云平台即服务。最重要的它是免费的。这是他的官方网站Heroku，注意不科学上网的话，可会超级慢或者进不去。而且科学上网要全局模式.. 在部署的时候，有三个选择，我选择选择GitHub 由于选择GitHub，那么还需要创建一个仓库，把代码放上去。 放上去之间还要改一下代码： 因为部署是交给heroku的，所以端口号不能写死： const port = process.env.PORT || 3000; 在package.json添加一个npm start命令 1&quot;start&quot;: &quot;node index.js&quot; 7.在GitHub上创建仓库并上传代码，过程略,别忘了写.gitignore文件 8.这是我的仓库地址 9.在heroku中选择仓库并且选择分支master，部署 10.预览 这个就是部署好的域名了。 用这个域名试一试 大功告成。可惜的就是heroku得上网才行。","link":"/2019/04/11/%E4%BD%BF%E7%94%A8heroku%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%9A%84%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0Web-Server/"},{"title":"使用nio进行大文件复制","text":"NIO概述什么是NIO? Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。 Java NIO: Channels and Buffers（通道和缓冲区） 标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。 Java NIO: Non-blocking IO（非阻塞IO） Java NIO可以让你非阻塞的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情。当数据被写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。 Java NIO: Selectors（选择器） Java NIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个的线程可以监听多个数据通道。 注意:传统IT是单向。 NIO类似 Buffer的概述1）容量（capacity）：表示Buffer最大数据容量，缓冲区容量不能为负，并且建立后不能修改。2）限制（limit）：第一个不应该读取或者写入的数据的索引，即位于limit后的数据不可以读写。缓冲区的限制不能为负，并且不能大于其容量（capacity）。3）位置（position）：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制（limit）。4）标记（mark）与重置（reset）：标记是一个索引，通过Buffer中的mark()方法指定Buffer中一个特定的position，之后可以通过调用reset()方法恢复到这个position。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * (缓冲区)buffer 用于NIO存储数据 支持多种不同的数据类型 &lt;br&gt; * 1.byteBuffer &lt;br&gt; * 2.charBuffer &lt;br&gt; * 3.shortBuffer&lt;br&gt; * 4.IntBuffer&lt;br&gt; * 5.LongBuffer&lt;br&gt; * 6.FloatBuffer &lt;br&gt; * 7.DubooBuffer &lt;br&gt; * 上述缓冲区管理的方式 几乎&lt;br&gt; * 通过allocate（） 获取缓冲区 &lt;br&gt; * 二、缓冲区核心的方法 put 存入数据到缓冲区 get &lt;br&gt; 获取缓冲区数据 flip 开启读模式 * 三、缓冲区四个核心属性&lt;br&gt; * capacity:缓冲区最大容量，一旦声明不能改变。 limit:界面(缓冲区可以操作的数据大小) limit后面的数据不能读写。 * position:缓冲区正在操作的位置 */public class Test004 { public static void main(String[] args) { // 1.指定缓冲区大小1024 ByteBuffer buf = ByteBuffer.allocate(1024); System.out.println(&quot;--------------------&quot;); System.out.println(buf.position()); System.out.println(buf.limit()); System.out.println(buf.capacity()); // 2.向缓冲区存放5个数据 buf.put(&quot;abcd1&quot;.getBytes()); System.out.println(&quot;--------------------&quot;); System.out.println(buf.position()); System.out.println(buf.limit()); System.out.println(buf.capacity()); // 3.开启读模式 buf.flip(); System.out.println(&quot;----------开启读模式...----------&quot;); System.out.println(buf.position()); System.out.println(buf.limit()); System.out.println(buf.capacity()); byte[] bytes = new byte[buf.limit()]; buf.get(bytes); System.out.println(new String(bytes, 0, bytes.length)); System.out.println(&quot;----------重复读模式...----------&quot;); // 4.开启重复读模式 buf.rewind(); System.out.println(buf.position()); System.out.println(buf.limit()); System.out.println(buf.capacity()); byte[] bytes2 = new byte[buf.limit()]; buf.get(bytes2); System.out.println(new String(bytes2, 0, bytes2.length)); // 5.clean 清空缓冲区 数据依然存在,只不过数据被遗忘 System.out.println(&quot;----------清空缓冲区...----------&quot;); buf.clear(); System.out.println(buf.position()); System.out.println(buf.limit()); System.out.println(buf.capacity()); System.out.println((char)buf.get()); }} 直接缓冲区与非直接缓冲耗时计算123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.itmayiedu;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.MappedByteBuffer;import java.nio.channels.FileChannel;import java.nio.channels.FileChannel.MapMode;import java.nio.file.Paths;import java.nio.file.StandardOpenOption;import org.junit.Test;public class Test003 { //直接缓冲区 @Test public void test002() throws IOException { long statTime=System.currentTimeMillis(); //创建管道 FileChannel inChannel= FileChannel.open(Paths.get(&quot;f://1.mp4&quot;), StandardOpenOption.READ); FileChannel outChannel= FileChannel.open(Paths.get(&quot;f://2.mp4&quot;), StandardOpenOption.READ,StandardOpenOption.WRITE, StandardOpenOption.CREATE); //定义映射文件 MappedByteBuffer inMappedByte = inChannel.map(MapMode.READ_ONLY,0, inChannel.size()); MappedByteBuffer outMappedByte = outChannel.map(MapMode.READ_WRITE,0, inChannel.size()); //直接对缓冲区操作 byte[] dsf=new byte[inMappedByte.limit()]; inMappedByte.get(dsf); outMappedByte.put(dsf); inChannel.close(); outChannel.close(); long endTime=System.currentTimeMillis(); System.out.println(&quot;操作直接缓冲区耗时时间:&quot;+(endTime-statTime)); } //直接缓冲内置函数版 @Test public void test004() throws IOException { long statTime=System.currentTimeMillis(); //创建管道 FileChannel inChannel= FileChannel.open(Paths.get(&quot;D:\\\\demo6.rar&quot;), StandardOpenOption.READ); FileChannel outChannel= FileChannel.open(Paths.get(&quot;D:\\\\Portable.rar&quot;), StandardOpenOption.READ,StandardOpenOption.WRITE, StandardOpenOption.CREATE); //定义映射文件 outChannel.transferFrom(inChannel, 0 , inChannel.size()); inChannel.close(); outChannel.close(); long endTime=System.currentTimeMillis(); System.out.println(&quot;操作直接缓冲区耗时时间:&quot;+(endTime-statTime)); } // 非直接缓冲区 读写操作 @Test public void test001() throws IOException { long statTime=System.currentTimeMillis(); // 读入流 FileInputStream fst = new FileInputStream(&quot;f://1.mp4&quot;); // 写入流 FileOutputStream fos = new FileOutputStream(&quot;f://2.mp4&quot;); // 创建通道 FileChannel inChannel = fst.getChannel(); FileChannel outChannel = fos.getChannel(); // 分配指定大小缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); while (inChannel.read(buf) != -1) { // 开启读取模式 buf.flip(); // 将数据写入到通道中 outChannel.write(buf); buf.clear(); } // 关闭通道 、关闭连接 inChannel.close(); outChannel.close(); fos.close(); fst.close(); long endTime=System.currentTimeMillis(); System.out.println(&quot;操作非直接缓冲区耗时时间:&quot;+(endTime-statTime)); }}","link":"/2019/03/29/%E4%BD%BF%E7%94%A8nio%E8%BF%9B%E8%A1%8C%E5%A4%A7%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6/"},{"title":"使用阿里云的图片识别成表格OCR","text":"为了简便财务总是要对照着别人发来的表格图片制作成自己的表格 图片识别 识别成表格 表格识别 ocr 将图片表格转换成excel 使用阿里云api 购买（印刷文字识别-表格识别） https://market.aliyun.com/products/57124001/cmapi024968.html 获得阿里云图片识别表格的appcode 效果图如下 整合的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235package com.xai.wuye.controller.api;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.JSONException;import com.alibaba.fastjson.JSONObject;import com.xai.wuye.common.JsonResult;import com.xai.wuye.exception.ResultException;import com.xai.wuye.model.AParamimport com.xai.wuye.service.CarService;import com.xai.wuye.util.HttpUtils;import org.apache.http.HttpResponse;import org.apache.http.util.EntityUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.io.FileSystemResource;import org.springframework.http.HttpHeaders;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.multipart.MultipartFile;import java.io.*;import java.util.Date;import java.util.HashMap;import java.util.Map;import static org.apache.tomcat.util.codec.binary.Base64.encodeBase64;@Controller@EnableAsync@RequestMapping(&quot;/api/ocr&quot;)public class AliOCRImages { @Autowired CarService carService; private String OcrPath = &quot;/home/runApp/car/orc/&quot;; @ResponseBody @RequestMapping(&quot;table&quot;) public JsonResult getFirstLicence(@RequestParam(value = &quot;file&quot;, required = false) MultipartFile file) { if (file == null || file.isEmpty()||file.getSize() &gt; 1204*1204*3) throw new ResultException(0,&quot;文件为null，且不能大于3M&quot;); String filename = file.getOriginalFilename(); String filepath = OcrPath+&quot;temp/&quot;+filename; File newFile = new File(filepath); try { file.transferTo(newFile); String host = &quot;https://form.market.alicloudapi.com&quot;; String path = &quot;/api/predict/ocr_table_parse&quot;; // 输入阿里的code String appcode = &quot;4926a667ee6c41329c278361*****&quot;; String imgFile = &quot;图片路径&quot;; Boolean is_old_format = false;//如果文档的输入中含有inputs字段，设置为True， 否则设置为False //请根据线上文档修改configure字段 JSONObject configObj = new JSONObject(); configObj.put(&quot;format&quot;, &quot;xlsx&quot;); configObj.put(&quot;finance&quot;, false); configObj.put(&quot;dir_assure&quot;, false); String config_str = configObj.toString(); // configObj.put(&quot;min_size&quot;, 5); //String config_str = &quot;&quot;; String method = &quot;POST&quot;; Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); //最后在header中的格式(中间是英文空格)为Authorization:APPCODE 83359fd73fe94948385f570e3c139105 headers.put(&quot;Authorization&quot;, &quot;APPCODE &quot; + appcode); Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); // 对图像进行base64编码 String imgBase64 = &quot;&quot;; try { byte[] content = new byte[(int) newFile.length()]; FileInputStream finputstream = new FileInputStream(newFile); finputstream.read(content); finputstream.close(); imgBase64 = new String(encodeBase64(content)); } catch (IOException e) { e.printStackTrace(); return null; } // 拼装请求body的json字符串 JSONObject requestObj = new JSONObject(); try { if(is_old_format) { JSONObject obj = new JSONObject(); obj.put(&quot;image&quot;, getParam(50, imgBase64)); if(config_str.length() &gt; 0) { obj.put(&quot;configure&quot;, getParam(50, config_str)); } JSONArray inputArray = new JSONArray(); inputArray.add(obj); requestObj.put(&quot;inputs&quot;, inputArray); }else{ requestObj.put(&quot;image&quot;, imgBase64); if(config_str.length() &gt; 0) { requestObj.put(&quot;configure&quot;, config_str); } } } catch (JSONException e) { e.printStackTrace(); } String bodys = requestObj.toString(); try { /** * 重要提示如下: * HttpUtils请从 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/src/main/java/com/aliyun/api/gateway/demo/util/HttpUtils.java * 下载 * * 相应的依赖请参照 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/pom.xml */ HttpResponse response = HttpUtils.doPost(host, path, method, headers, querys, bodys); int stat = response.getStatusLine().getStatusCode(); if(stat != 200){ System.out.println(&quot;Http code: &quot; + stat); System.out.println(&quot;http header error msg: &quot;+ response.getFirstHeader(&quot;X-Ca-Error-Message&quot;)); System.out.println(&quot;Http body error msg:&quot; + EntityUtils.toString(response.getEntity())); return null; } String res = EntityUtils.toString(response.getEntity()); JSONObject res_obj = JSON.parseObject(res); Long fileName = System.currentTimeMillis(); if(is_old_format) { JSONArray outputArray = res_obj.getJSONArray(&quot;outputs&quot;); String output = outputArray.getJSONObject(0).getJSONObject(&quot;outputValue&quot;).getString(&quot;dataValue&quot;); JSONObject out = JSON.parseObject(output); System.out.println(out.toJSONString()); }else{ String tmp_base64path = OcrPath + fileName; File tmp_base64file = new File(tmp_base64path); if(!tmp_base64file.exists()){ tmp_base64file.getParentFile().mkdirs(); } tmp_base64file.createNewFile(); // write FileWriter fw = new FileWriter(tmp_base64file, true); BufferedWriter bw = new BufferedWriter(fw); bw.write(res_obj.getString(&quot;tables&quot;)); bw.flush(); bw.close(); fw.close(); String exelFilePath = OcrPath + fileName + &quot;_1.xlsx&quot;; Runtime.getRuntime().exec(&quot;touch &quot;+exelFilePath).destroy(); Process exec = Runtime.getRuntime().exec(&quot;sed -i -e 's/\\\\\\\\n/\\\\n/g' &quot; + tmp_base64path); exec.waitFor(); exec.destroy(); Process exec1 = null; String[] cmd = { &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;base64 -d &quot; + tmp_base64path + &quot; &gt; &quot; + exelFilePath }; exec1 = Runtime.getRuntime().exec(cmd); exec1.waitFor(); exec1.destroy(); return JsonResult.success(fileName); } } catch (Exception e) { e.printStackTrace(); } } catch (IOException e) { e.printStackTrace(); } return null; } @ResponseBody @RequestMapping(&quot;getId&quot;) public ResponseEntity&lt;FileSystemResource&gt; getFirstLicence(String id) { String exelFilePath = OcrPath + id + &quot;_1.xlsx&quot;; return export(new File(exelFilePath)); } public ResponseEntity&lt;FileSystemResource&gt; export(File file) { if (file == null) { return null; } HttpHeaders headers = new HttpHeaders(); headers.add(&quot;Cache-Control&quot;, &quot;no-cache, no-store, must-revalidate&quot;); headers.add(&quot;Content-Disposition&quot;, &quot;attachment; filename=&quot; + System.currentTimeMillis() + &quot;.xls&quot;); headers.add(&quot;Pragma&quot;, &quot;no-cache&quot;); headers.add(&quot;Expires&quot;, &quot;0&quot;); headers.add(&quot;Last-Modified&quot;, new Date().toString()); headers.add(&quot;ETag&quot;, String.valueOf(System.currentTimeMillis())); return ResponseEntity .ok() .headers(headers) .contentLength(file.length()) .contentType(MediaType.parseMediaType(&quot;application/octet-stream&quot;)) .body(new FileSystemResource(file)); } public static JSONObject getParam(int type, String dataValue) { JSONObject obj = new JSONObject(); try { obj.put(&quot;dataType&quot;, type); obj.put(&quot;dataValue&quot;, dataValue); } catch (JSONException e) { e.printStackTrace(); } return obj; }} 大功告成 以下是静态页面代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;!-- import CSS --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/element-ui/lib/theme-chalk/index.css&quot;&gt; &lt;title&gt;table&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;el-upload class=&quot;upload-demo&quot; drag action=&quot;https://www.***.com/car/api/ocr/table&quot; :file-list=&quot;imagelist&quot; :on-preview=&quot;pre&quot; &gt; &lt;i class=&quot;el-icon-upload&quot;&gt;&lt;/i&gt; &lt;div class=&quot;el-upload__text&quot;&gt;将文件拖到此处，或&lt;em&gt;点击上传&lt;/em&gt;&lt;/div&gt; &lt;div class=&quot;el-upload__tip&quot; slot=&quot;tip&quot;&gt;只能上传jpg/png文件，且不超过500kb&lt;/div&gt; &lt;/el-upload&gt; &lt;div class=&quot;img-content&quot; v-for=&quot;(item,key) in imagelist&quot; :key=&quot;key&quot;&gt; &lt;img :src=&quot;item.url&quot;&gt; &lt;div class=&quot;name&quot;&gt; &lt;div&gt;{{ item.name }}&lt;/div&gt; &lt;el-button type=&quot;text&quot; @click=&quot;handleFileName(item,key)&quot;&gt;修改名字&lt;/el-button&gt; &lt;/div&gt; &lt;!-- 删除icon --&gt; &lt;div class=&quot;del&quot;&gt; &lt;i @click=&quot;handleFileRemove(item,key)&quot; class=&quot;el-icon-delete2&quot;&gt;&lt;/i&gt; &lt;/div&gt; &lt;!-- 放大icon --&gt; &lt;div class=&quot;layer&quot; @click=&quot;handleFileEnlarge(item.url)&quot;&gt; &lt;i class=&quot;el-icon-view&quot;&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; &lt;!-- import Vue before Element --&gt; &lt;script src=&quot;https://unpkg.com/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;!-- import JavaScript --&gt; &lt;script src=&quot;https://unpkg.com/element-ui/lib/index.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue({ el: '#app', data: function() { return { visible: false, imagelist: [ ] } }, methods: { pre(res) { console.log(res.response.msg) window.open(&quot;https://www.***.com/api/ocr/getId?id=&quot;+res.response.data); } } }) &lt;/script&gt;&lt;/html&gt;","link":"/2019/04/08/%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E7%9A%84%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB%E6%88%90%E8%A1%A8%E6%A0%BC/"},{"title":"写博客的一些推荐","text":"写博客的一些个人推荐1、使用markdown 你如果经常上github这个神奇的网站。你会看到README.md ，没错，就是 markdown写的 大家可以问问身边的大牛们，哪个不用markdown?就连渣渣程序猿的我也在用。 用它写博客，你会感受到一个字：爽！如果你还没有用过markdown，听我的，抓紧试一试。 2、使用七牛云 使用markdown的问题来了，图片存在哪？毕竟我们写博客会粘贴各种各样的图片，这个问题大家不用担心。 我个人是使用七牛云来存储。因为有10G的免费空间， 肯定是够你愉快的玩耍了。 如果你用的不是很顺手，你也可以使用阿里云。也可以用各种偏门的方法，比如把图片放到github上然后弄下链接来。 不过你想整理下文件的话 还是最好用一个文件资源服务器把。 3、使用PicGo 每次都需要登录七牛云官网，然后点击上传，上传多张图片之后，也不知道哪张是哪张了。开源的大神早已为我们找到解决办法，使用PicGo.不仅支持七牛云，还有各种云。够你用的了。 4、学会使用思维导图 使用ProcessOn 身为程序员的我们，写文章肯定用到流程图，思维导图，UML类图等各种图，ProcessOn满足你所有的需求。 ProcessOn是一个在线作图工具的聚合平台，它可以在线画流程图、思维导图、UI原型图、UML、网络拓扑图、组织结构图等等 还可以把作品分享给团队成员或好友，无论何时何地大家都可以对作品进行编辑、阅读和评论 5、 md2all 如果大家平时还维护这自己的个人公众号，肯定知道公众号里面代码格式的痛苦，没关系。开源的世界大牛们已经为我们找到解决方案。使用md2all ,可以直接将markdown转成适应所有格式的文章。 我们公司的编辑器就没有markdown，你完全可以用这个转换下。 同时还有一个我感觉不错的转换markdown的。程序员DD写的 http://blog.didispace.com/tools/online-markdown/ 6、 感觉没什么好写的？也不知道写什么？ 不要老觉着自己技术差，写出的东西太基础，没有价值，不要这种担心，技术渣渣的我都敢去写博客。你为什么不敢呢？比如java中的for循环，你如果写一篇博客把它介绍的很详细，让读者一读就明白了for循环的执行顺序。也是一篇好的博客。 不要觉得自己东西没有人看。就没有价值，这你就大错特错了。。每次遇到一个技术难关，攻破后虽然很简单。以为能牢记很久，但是时间一场就真的忘记了。如果你你有做记录记录了下来。哪怕只是只有代码。你看一眼也能马上唤起你当时的记忆。","link":"/2019/03/29/%E5%86%99%E5%8D%9A%E5%AE%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E6%8E%A8%E8%8D%90/"},{"title":"启动时查看配置文件application.yml","text":"Spring Boot Application 事件和监听器 在多环境的情况下。 可能需要切换配置文件的一个对应的属性来切换环境 面临的问题就是 如何在springboot加载完配置文件的时候就可以立即校验对应的属性值 SmartApplicationListener实现监听解耦 我们只需在加载完成之后去加入一个监听器。 就可以得到application.yml的内容。 不然再这个事件之前。都是拿不到对应的内容的 一、SmartApplicationListener介绍 Spring ApplicationEvent以及对应的Listener提供了一个事件监听、发布订阅的实现，内部实现方式是观察者模式，可以解耦业务系统之间的业务，提供系统的可拓展性、复用性以及可维护性。 在application.yml文件读取完会触发一个事件ConfigFileApplicationListener 该监听器实现文件的读取。 SmartApplicationListener是高级监听器，是ApplicationListener的子类，能够实现有序监听 SmartApplicationListener提供了两个方法： 123456789/** * 指定支持哪些类型的事件 */boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; var1);/** * 指定支持发生事件所在的类型 */boolean supportsSourceType(Class&lt;?&gt; var1); 二、ConfigFileApplicationListener ConfigFileApplicationListener是用来 读取配置文件的。 可以这样来粗劣的介绍一下 详情可以请看 springboot启动时是如何加载配置文件application.yml文件 三、直奔主题 新增一个监听器 既然我们要在配置文件加载之后搞事情那么我们直接复制ConfigFileApplicationListener 的实现方式 删除一下不需要处理的操作（大概就是以下代码） 并且order在ConfigFileApplicationListener 之后 1234567891011121314151617public class AfterConfigListener implements SmartApplicationListener,Ordered { public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) { return ApplicationEnvironmentPreparedEvent.class.isAssignableFrom(eventType) || ApplicationPreparedEvent.class.isAssignableFrom(eventType); } public void onApplicationEvent(ApplicationEvent event) { if (event instanceof ApplicationEnvironmentPreparedEvent) { } if (event instanceof ApplicationPreparedEvent) { } } @Override public int getOrder() { // 写在加载配置文件之后 return ConfigFileApplicationListener.DEFAULT_ORDER + 1; }} 这样子就完成了配置文件之后的代码监听。 SmartApplicationListener又是实现了ApplicationListener的监听的，那么我们可以在onApplicationEvent执行代码。 完善代码如下。 监听并且获取配置文件内容 12345678910111213141516171819202122232425public class AfterConfigListener implements SmartApplicationListener,Ordered { public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) { return ApplicationEnvironmentPreparedEvent.class.isAssignableFrom(eventType) || ApplicationPreparedEvent.class.isAssignableFrom(eventType); } public void onApplicationEvent(ApplicationEvent event) { if (event instanceof ApplicationEnvironmentPreparedEvent) { String banks = ((ApplicationEnvironmentPreparedEvent) event).getEnvironment().getProperty(&quot;spring.name&quot;); if (ToolUtil.isEmpty(BankEnum.getValue(banks))) { throw new RuntimeException(&quot;请检查 com.enums.BankEnum 中是否拥有该banks环境名字！&quot;); } } if (event instanceof ApplicationPreparedEvent) { } } @Override public int getOrder() { // 写在加载配置文件之后 return ConfigFileApplicationListener.DEFAULT_ORDER + 1; }} 并且在main方法中加入该监听器 123456789public class XProApplication { public static void main(String[] args) { SpringApplication springApplication = new SpringApplication(XProApplication.class); springApplication.addListeners(new AfterConfigListener()); springApplication.run(args); }}","link":"/2020/03/02/%E5%90%AF%E5%8A%A8%E6%97%B6%E6%9F%A5%E7%9C%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6application-yml/"},{"title":"拦截器和过滤器的区别","text":"1.过滤器：依赖于servlet容器。在实现上基于函数回调，可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次。使用过滤器的目的是用来做一些过滤操作，获取我们想要获取的数据，比如：在过滤器中修改字符编码；在过滤器中修改HttpServletRequest的一些参数，包括：过滤低俗文字、危险字符等 2.拦截器：依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架。在实现上基于Java的反射机制，属于面向切面编程（AOP）的一种运用。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入（DI）进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。但是缺点是只能对controller请求进行拦截，对其他的一些比如直接访问静态资源的请求则没办法进行拦截处理3.过滤器和拦截器的区别： ①拦截器是基于java的反射机制的，而过滤器是基于函数回调。 ②拦截器不依赖与servlet容器，过滤器依赖与servlet容器。 ③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 ④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 ⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。 ⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。过滤器 过滤器123456@Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)throws IOException, ServletException { System.out.println(&quot;before...&quot;); chain.doFilter(request, response); System.out.println(&quot;after...&quot;); } chain.doFilter(request, response);这个方法的调用作为分水岭。事实上调用Servlet的doService()方法是在chain.doFilter(request, response);这个方法中进行的。 拦截器拦截器是被包裹在过滤器之中的。 1234567891011121314@Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception { System.out.println(&quot;preHandle&quot;); returntrue; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)throws Exception { System.out.println(&quot;postHandle&quot;); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)throws Exception { System.out.println(&quot;afterCompletion&quot;); } a.preHandle()这个方法是在过滤器的chain.doFilter(request, response)方法的前一步执行，也就是在 [System.out.println(“before…”)][chain.doFilter(request, response)]之间执行。 b.preHandle()方法之后，在return ModelAndView之前进行，可以操控Controller的ModelAndView内容。 c.afterCompletion()方法是在过滤器返回给前端前一步执行，也就是在[chain.doFilter(request, response)][System.out.println(“after…”)]之间执行。 SpringMVC的机制是由同一个Servlet来分发请求给不同的Controller，其实这一步是在Servlet的service()方法中执行的。所以过滤器、拦截器、service()方法，dispatc()方法的执行顺序应该是这样的，大致画了个图：其实非常好测试，自己写一个过滤器，一个拦截器，然后在这些方法中都加个断点，一路F8下去就得出了结论。","link":"/2019/05/20/%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"教你你快捷编程 --- 将List&lt;User&gt; 对象的id快速抽取出来","text":"在编程过程中 我们总是会遇到 需要将某个集合中的对象的id或者某个属性快速抽取出来。 那么我们使用jdk8 的方法 快速的抽取你想要的属性集合 啥也不说了 上代码！ List&lt;Admin&gt; adminList -&gt; Set&lt;Integer&gt; adminSet (id) 12345678910111213141516171819202122232425262728@Datapublic class Admin { private Integer id; private Integer name;} public static void main(String[] args) { List&lt;Admin&gt; adminList = new ArrayList&lt;&gt;(); Admin adminRoleDO = new Admin(); adminList.add(adminRoleDO); adminList.add(adminRoleDO); adminList.add(adminRoleDO); adminList.add(adminRoleDO); // 我们需要将这个对象的id 抽取出来变成一个集合。 // 假设我们需要一个不重复的 id集合 Set&lt;Integer&gt; adminSet = adminRoleList.stream().map(Admin::getId).collect(Collectors.toSet()); // 如果转换为Map对象 id为key name为value方法如下 Map&lt;Integer,Integer&gt; adminMap = from.stream().collect(Collectors.toMap(Admin::getId, Admin::getName)); }","link":"/2019/06/01/%E6%95%99%E4%BD%A0%E4%BD%A0%E5%BF%AB%E6%8D%B7%E7%BC%96%E7%A8%8B-%E5%B0%86List-User-%E5%AF%B9%E8%B1%A1%E7%9A%84id%E5%BF%AB%E9%80%9F%E6%8A%BD%E5%8F%96%E5%87%BA%E6%9D%A5/"},{"title":"浅谈SpringBoot的Cors跨域设置","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 1、什么是跨越？ 一个网页向另一个不同域名/不同协议/不同端口的网页请求资源，这就是跨域。 跨域原因产生：在当前域名请求网站中，默认不允许通过ajax请求发送其他域名。 SpringBoot的Cors跨域设置 SpringBoot可以基于Cors解决跨域问题，Cors是一种机制，告诉我们的后台，哪边（origin ）来的请求可以访问服务器的数据。 全局配置 配置实例如下： 123456789101112@Configurationpublic class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/**&quot;) .allowedOrigins(&quot;*&quot;) .allowCredentials(true) .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;) .maxAge(3600); }} 首先实现了WebMvcConfigurer 接口，WebMvcConfigurer 这个接口十分强大，里面还有很多可用的方法，在SpringBoot2.0里面可以解决WebMvcConfigurerAdapter曾经的部分任务。其中一个方法就是addCorsMappings()，是专门为开发人员解决跨域而诞生的接口。其中构造参数为CorsRegistry。 看下CorsRegistry源码，十分简单： 12345678910111213141516171819public class CorsRegistry { private final List&lt;CorsRegistration&gt; registrations = new ArrayList&lt;&gt;(); public CorsRegistration addMapping(String pathPattern) { CorsRegistration registration = new CorsRegistration(pathPattern); this.registrations.add(registration); return registration; } protected Map&lt;String, CorsConfiguration&gt; getCorsConfigurations() { Map&lt;String, CorsConfiguration&gt; configs = new LinkedHashMap&lt;&gt;(this.registrations.size()); for (CorsRegistration registration : this.registrations) { configs.put(registration.getPathPattern(), registration.getCorsConfiguration()); } return configs; }} 可以看出CorsRegistry 有个属性registrations ，按道理可以根据不同的项目路径进行定制访问行为，但是我们示例直接将pathPattern 设置为 /**，也就是说已覆盖项目所有路径，只需要创建一个CorsRegistration就好。getCorsConfigurations(),这个方法是获取所有CorsConfiguration的Map集合，key值为传入路径pathPattern。 回到示例代码CorsConfig中，registry对象addMapping()增加完传入路径pathPattern之后，return了一个CorsRegistration对象，是进行更多的配置，看一下CorsRegistration的代码，看看我们能配些什么？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class CorsRegistration { //传入的路径 private final String pathPattern; //配置信息实体类 private final CorsConfiguration config; //构造方法 public CorsRegistration(String pathPattern) { this.pathPattern = pathPattern; //原生注释看到了一个 @CrossOrigin 这个注解，待会看看是什么 // Same implicit default values as the @CrossOrigin annotation + allows simple methods this.config = new CorsConfiguration().applyPermitDefaultValues(); } //允许哪些源网站访问，默认所有 public CorsRegistration allowedOrigins(String... origins) { this.config.setAllowedOrigins(Arrays.asList(origins)); return this; } //允许何种方式访问，默认简单方式，即：GET，HEAD，POST public CorsRegistration allowedMethods(String... methods) { this.config.setAllowedMethods(Arrays.asList(methods)); return this; } //设置访问header，默认所有 public CorsRegistration allowedHeaders(String... headers) { this.config.setAllowedHeaders(Arrays.asList(headers)); return this; } //设置response headers，默认没有（什么都不设置） public CorsRegistration exposedHeaders(String... headers) { this.config.setExposedHeaders(Arrays.asList(headers)); return this; } //是否浏览器应该发送credentials，例如cookies Access-Control-Allow-Credentials public CorsRegistration allowCredentials(boolean allowCredentials) { this.config.setAllowCredentials(allowCredentials); return this; } //设置等待时间，默认1800秒 public CorsRegistration maxAge(long maxAge) { this.config.setMaxAge(maxAge); return this; } protected String getPathPattern() { return this.pathPattern; } protected CorsConfiguration getCorsConfiguration() { return this.config; }} 局部配置 刚才遇到一个@CrossOrigin这个注解，看看它是干什么的？ 12345678910111213141516171819202122232425262728293031323334353637383940@Target({ ElementType.METHOD, ElementType.TYPE })@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CrossOrigin { /** @deprecated as of Spring 5.0, in favor of {@link CorsConfiguration#applyPermitDefaultValues} */ @Deprecated String[] DEFAULT_ORIGINS = { &quot;*&quot; }; /** @deprecated as of Spring 5.0, in favor of {@link CorsConfiguration#applyPermitDefaultValues} */ @Deprecated String[] DEFAULT_ALLOWED_HEADERS = { &quot;*&quot; }; /** @deprecated as of Spring 5.0, in favor of {@link CorsConfiguration#applyPermitDefaultValues} */ @Deprecated boolean DEFAULT_ALLOW_CREDENTIALS = false; /** @deprecated as of Spring 5.0, in favor of {@link CorsConfiguration#applyPermitDefaultValues} */ @Deprecated long DEFAULT_MAX_AGE = 1800 /** * Alias for {@link #origins}. */ @AliasFor(&quot;origins&quot;) String[] value() default {}; @AliasFor(&quot;value&quot;) String[] origins() default {}; String[] allowedHeaders() default {}; String[] exposedHeaders() default {}; RequestMethod[] methods() default {}; String allowCredentials() default &quot;&quot;; long maxAge() default -1;} 这个注解可以作用于方法或者类上，实现局部跨域，你会发现除了设置路径（因为没必要了，都定位到局部了）其他的参数与全局类似。","link":"/2019/06/12/%E6%B5%85%E8%B0%88SpringBoot%E7%9A%84Cors%E8%B7%A8%E5%9F%9F%E8%AE%BE%E7%BD%AE/"},{"title":"消息队列面试相关","text":"使用消息队列的原因其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用MQ可能会很麻烦，但是你现在用了MQ之后带给了你很多的好处先说一下消息队列的常见使用场景吧，其实场景有很多，但是比较核心的有3个：解耦、异步、削峰、解耦 现场画个图来说明一下： A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？A系统负责人濒临崩溃中。。。再来点更加崩溃的事儿，A系统要时时刻刻考虑BCDE四个系统如果挂了咋办？我要不要重发？我要不要把消息存起来？头发都白了啊。。。 面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个MQ去进行系统的解耦。在简历中体现出来这块东西，用MQ作解耦。异步：现场画个图来说明一下， A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3 + 300 + 450 + 200 = 953ms，接近1s，用户感觉搞个什么东西，慢死了慢死了。_削峰_：每天0点到11点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到11点~1点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。。。尴尬了，系统会死。。。 消息队列有什么优点和缺点优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰缺点呢？显而易见的 系统可用性降低：系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，人ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了咋整？MQ挂了，整套系统崩溃了，你不就完了么。系统复杂性提高：硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已一致性问题：A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，咋整？你这数据就不一致了。所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，最好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了10倍。但是关键时刻，用，还是得用的。。。 kafka、activemq、rabbitmq、rocketmq都有什么优点和缺点啊？常见的MQ其实就这几种，别的还有很多其他MQ，但是比较冷门的，那么就别多说了作为一个码农，你起码得知道各种mq的优点和缺点吧，咱们来画个表格看看 | 特性 |ActiveMQ|RabbitMQ|RocketMQ|Kafka|| —— | —— | —— | —— |—— || 单机吞吐量|万级，吞吐量比RocketMQ和Kafka要低了一个数量级 | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级|10万级，RocketMQ也是可以支撑高吞吐的一种MQ | 10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景|| topic数量对吞吐量的影响|||topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic|topic从几十个到几百个的时候，吞吐量会大幅度下降所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源||时效性|ms级|微秒级，这是rabbitmq的一大特点，延迟是最低的|ms级|延迟在ms级以内||可用性|高，基于主从架构实现高可用性|高，基于主从架构实现高可用性|非常高，分布式架构|非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用||消息可靠性|有较低的概率丢失数据||经过参数优化配置，可以做到0丢失|经过参数优化配置，消息可以做到0丢失||功能支持|MQ领域的功能极其完备|基于erlang开发，所以并发能力很强，性能极其好，延时很低|MQ功能较为完善，还是分布式的，扩展性好|功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准||优劣势总结|非常成熟，功能强大，在业内大量的公司以及项目中都有应用偶尔会有较低概率丢失消息而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用|erlang语言开发，性能极其好，延时很低；吞吐量到万级，MQ功能比较完备而且开源提供的管理界面非常棒，用起来很好用社区相对比较活跃，几乎每个月都发布几个版本分在国内一些互联网公司近几年用rabbitmq也比较多一些但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。|接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的|kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集|","link":"/2019/06/07/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%9D%A2%E8%AF%95%E7%9B%B8%E5%85%B3/"},{"title":"线上服务器进行分库分表（达到亿级数据）","text":"如何设计可以动态扩容缩容的分库分表方案？ （1）选择一个数据库中间件，调研、学习、测试 （2）设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，3个库每个库4个表 （3）基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写 （4）完成单库单表到分库分表的迁移，双写方案 （5）线上系统开始基于分库分表对外提供服务 （6）扩容了，扩容成6个库，每个库需要12个表，你怎么来增加更多库和表呢？ 1）停机扩容晚上的时候挂公告 说晚上扩容整改。然后后台停机 进行数据迁移 这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然分库分表就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。 从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万 写个工具，多弄几台机器并行跑，1小时数据就导完了 3个库+12个表，跑了一段时间了，数据量都1亿~2亿了。光是导2亿数据，都要导个几个小时，6点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10点才可以搞完 2）优化后的方案使用数据双写 然后新的分库分表的数据库和原数据库 一起用 有新的数据就两边都写入。并且开一个服务 进行将旧的数据 逐渐迁移到新的库之中 一开始上来就是32个库，每个库32个表，1024张表 我可以告诉各位同学说，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题 每个库正常承载的写入并发量是1000，那么32个库就可以承载32 * 1000 = 32000的写并发，如果每个库承载1500的写并发，32 * 1500 = 48000的写并发，接近5万/s的写入并发，前面再加一个MQ，削峰，每秒写入MQ 8万条数据，每秒消费5万条数据。 有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128个库，256个库，512个库 1024张表，假设每个表放500万数据，在MySQL里可以放50亿条数据 每秒的5万写并发，总共50亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了 谈分库分表的扩容，第一次分库分表，就一次性给他分个够，32个库，1024张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了 一个实践是利用32 * 32来分库分表，即分为32个库，每个库里一个表分为32张表。一共就是1024张表。根据某个id先根据32取模路由到库，再根据32取模路由到库里的表。 刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个mysql服务器可能建了n个库，比如16个库。后面如果要拆分，就是不断在库和mysql服务器之间做迁移就可以了。然后系统配合改一下配置即可。 比如说最多可以扩展到32个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到1024个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是1024个表么。 这么搞，是不用自己写代码做数据迁移的，都交给dba来搞好了，但是dba确实是需要做一些库表迁移的工作，但是总比你自己写代码，抽数据导数据来的效率高得多了。 哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。 对2 ^ n取模 orderId 模 32 = 库orderId / 32 模 32 = 表 259 3 81189 5 5352 0 114593 17 15 1、设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是32库 * 32表，对于大部分公司来说，可能几年都够了 2、路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表 3、扩容的时候，申请增加更多的数据库服务器，装好mysql，倍数扩容，4台服务器，扩到8台服务器，16台服务器 4、由dba负责将原先数据库服务器的库，迁移到新的数据库服务器上去，很多工具，库迁移，比较便捷 5、我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址 6、重新发布系统，上线，原先的路由规则变都不用变，直接可以基于2倍的数据库服务器的资源，继续进行线上系统的提供服务","link":"/2019/01/21/%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%EF%BC%88%E8%BE%BE%E5%88%B0%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%EF%BC%89/"},{"title":"编译安装Keepalived2.0.0","text":"简介 Keepalived是基于vrrp协议的一款高可用软件。Keepailived有一台主服务器和多台备份服务器，在主服务器和备份服务器上面部署相同的服务配置，使用一个虚拟IP地址对外提供服务，当主服务器出现故障时，虚拟IP地址会自动漂移到备份服务器。 VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议），VRRP是为了解决静态路由的高可用。VRRP的基本架构虚拟路由器由多个路由器组成，每个路由器都有各自的IP和共同的VRID(0-255)，其中一个VRRP路由器通过竞选成为MASTER，占有VIP，对外提供路由服务，其他成为BACKUP，MASTER以IP组播（组播地址：224.0.0.18）形式发送VRRP协议包，与BACKUP保持心跳连接，若MASTER不可用（或BACKUP接收不到VRRP协议包），则BACKUP通过竞选产生新的MASTER并继续对外提供路由服务，从而实现高可用。 vrrp协议的相关术语 虚拟路由器：Virtual Router虚拟路由器标识：VRID(0-255)物理路由器： master ：主设备 backup ：备用设备 priority：优先级 VIP：Virtual IPVMAC：Virutal MAC (00-00-5e-00-01-VRID)GraciousARP 安全认证 简单字符认证、HMAC机制，只对信息做认证 MD5（leepalived不支持） 工作模式 主/备：单虚拟路径器 主/主：主/备（虚拟路径器），备/主（虚拟路径器） 工作类型 抢占式：当出现比现有主服务器优先级高的服务器时，会发送通告抢占角色成为主服务器 非抢占式： 核心组件 vrrp stack：vrrp协议的实现 ipvs wrapper：为集群内的所有节点生成IPVS规则 checkers：对IPVS集群的各RS做健康状态检测 控制组件：配置文件分析器，用来实现配置文件的分析和加载 IO复用器 内存管理组件，用来管理keepalived高可用是的内存管理 注意 各节点时间必须同步 确保各节点的用于集群服务的接口支持MULTICAST通信（组播） 安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@masga ~]# yum install openssl-devel popt-devel libnl libnl-devel libnfnetlink-devel gcc -y[root@masga ~]# cd /usr/local/src/[root@masga src]# wget http://www.keepalived.org/software/keepalived-2.0.0.tar.gz[root@masga src]# tar zxvf keepalived-2.0.0.tar.gz[root@masga src]# mkdir -p ../keepalived[root@masga src]# cd keepalived-2.0.0[root@masga keepalived-2.0.0]# ./configure --prefix=/usr/local/keepalivedKeepalived configuration------------------------Keepalived version : 2.0.0Compiler : gccPreprocessor flags : Compiler flags : -Wall -Wunused -Wstrict-prototypes -Wextra -Winit-self -g -O2 -D_GNU_SOURCE -fPIE -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches Linker flags : -pieExtra Lib : -lcrypto -lssl -lnlUse IPVS Framework : YesIPVS use libnl : YesIPVS syncd attributes : NoIPVS 64 bit stats : Nofwmark socket support : YesUse VRRP Framework : YesUse VRRP VMAC : YesUse VRRP authentication : YesWith ip rules/routes : YesUse BFD Framework : NoSNMP vrrp support : NoSNMP checker support : NoSNMP RFCv2 support : NoSNMP RFCv3 support : NoDBUS support : NoSHA1 support : NoUse Json output : Nolibnl version : 1Use IPv4 devconf : NoUse libiptc : NoUse libipset : Noinit type : systemdBuild genhash : YesBuild documentation : No[root@masga keepalived-2.0.0]# make &amp;&amp; make install[root@masga keepalived-2.0.0]# cp /usr/local/src/keepalived-2.0.0/keepalived/etc/init.d/keepalived /etc/init.d/[root@masga keepalived-2.0.0]# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/[root@masga keepalived-2.0.0]# mkdir /etc/keepalived[root@masga keepalived-2.0.0]# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/[root@masga keepalived-2.0.0]# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/[root@masga keepalived-2.0.0]# echo &quot;/etc/init.d/keepalived start&quot; &gt;&gt; /etc/rc.local[root@masga keepalived-2.0.0]# chmod +x /etc/rc.d/init.d/keepalived[root@masga keepalived-2.0.0]# chkconfig keepalived on","link":"/2019/04/25/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Keepalived2-0-0/"},{"title":"网站跨域的五种解决方式","text":"1、什么是跨越？ 一个网页向另一个不同域名/不同协议/不同端口的网页请求资源，这就是跨域。 跨域原因产生：在当前域名请求网站中，默认不允许通过ajax请求发送其他域名。 网络请求示意图 2、为什么会产生跨域请求？ 因为浏览器使用了同源策略 3、什么是同源策略？ 同源策略是Netscape提出的一个著名的安全策略，现在所有支持JavaScript的浏览器都会使用这个策略。同源策略是浏览器最核心也最基本的安全功能，如果缺少同源策略，浏览器的正常功能可能受到影响。可以说web是构建在同源策略的基础之上的，浏览器只是针对同源策略的一种实现。 4、为什么浏览器要使用同源策略？ 是为了保证用户的信息安全，防止恶意网站窃取数据，如果网页之间不满足同源要求，将不能: 1、共享Cookie、LocalStorage、IndexDB 2、获取DOM 3、AJAX请求不能发送 同源策略的非绝对性： 123456&lt;script&gt;&lt;/script&gt;&lt;img/&gt;&lt;iframe/&gt;&lt;link/&gt;&lt;video/&gt;&lt;audio/&gt; 等带有src属性的标签可以从不同的域加载和执行资源。其他插件的同源策略：flash、java applet、silverlight、googlegears等浏览器加载的第三方插件也有各自的同源策略，只是这些同源策略不属于浏览器原生的同源策略，如果有漏洞则可能被黑客利用，从而留下XSS攻击的后患 所谓的同源指：域名、网络协议、端口号相同，三条有一条不同就会产生跨域。 例如：你用浏览器打开http://baidu.com，浏览器执行JavaScript脚本时发现脚本向http://cloud.baidu.com域名发请求，这时浏览器就会报错，这就是跨域报错。 解决方案有五：1、前端使用jsonp （不推荐使用） 当我们正常地请求一个JSON数据的时候，服务端返回的是一串 JSON类型的数据，而我们使用 JSONP模式来请求数据的时候服务端返回的是一段可执行的 JavaScript代码。因为jsonp 跨域的原理就是用的动态加载 script的src ，所以我们只能把参数通过 url的方式传递,所以jsonp的 type类型只能是get示例：123456789$.ajax({ url: 'http://192.168.1.114/yii/demos/test.php', //不同的域 type: 'GET', // jsonp模式只有GET 是合法的 data: { 'action': 'aaron' }, dataType: 'jsonp', // 数据类型 jsonp: 'backfunc', // 指定回调函数名，与服务器端接收的一致，并回传回来}) 使用JSONP 模式来请求数据的整个流程：客户端发送一个请求，规定一个可执行的函数名（这里就是 jQuery做了封装的处理，自动帮你生成回调函数并把数据取出来供success属性方法来调用,而不是传递的一个回调句柄），服务器端接受了这个 backfunc函数名，然后把数据通过实参的形式发送出去 （在jquery 源码中， jsonp的实现方式是动态添加&lt;script&gt;标签来调用服务器提供的 js脚本。jquery 会在window对象中加载一个全局的函数，当 &lt;script&gt;代码插入时函数执行，执行完毕后就 &lt;script&gt;会被移除。同时jquery还对非跨域的请求进行了优化，如果这个请求是在同一个域名下那么他就会像正常的 Ajax请求一样工作。） 2、后台Http请求转发 使用HttpClinet转发进行转发(简单的例子 不推荐使用这种方式) 1234567891011try { HttpClient client = HttpClients.createDefault(); //client对象 HttpGet get = new HttpGet(&quot;http://localhost:8080/test&quot;); //创建get请求 CloseableHttpResponse response = httpClient.execute(get); //执行get请求 String mes = EntityUtils.toString(response.getEntity()); //将返回体的信息转换为字符串 System.out.println(mes);} catch (ClientProtocolException e) { e.printStackTrace();} catch (IOException e) { e.printStackTrace();} 3、后台配置同源Cors （推荐） 在SpringBoot2.0 上的跨域 用以下代码配置 即可完美解决你的前后端跨域请求问题 在SpringBoot2.0 上的跨域 用以下代码配置 即可完美解决你的前后端跨域请求问题 123456789101112131415161718192021222324252627282930313233import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * 实现基本的跨域请求 * @author linhongcun * */@Configurationpublic class CorsConfig { @Bean public CorsFilter corsFilter() { final UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource(); final CorsConfiguration corsConfiguration = new CorsConfiguration(); /*是否允许请求带有验证信息*/ corsConfiguration.setAllowCredentials(true); /*允许访问的客户端域名*/ corsConfiguration.addAllowedOrigin(&quot;*&quot;); /*允许服务端访问的客户端请求头*/ corsConfiguration.addAllowedHeader(&quot;*&quot;); /*允许访问的方法名,GET POST等*/ corsConfiguration.addAllowedMethod(&quot;*&quot;); urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, corsConfiguration); return new CorsFilter(urlBasedCorsConfigurationSource); }} 4、使用SpringCloud网关 服务网关(zuul)又称路由中心，用来统一访问所有api接口，维护服务。 Spring Cloud Zuul通过与Spring Cloud Eureka的整合，实现了对服务实例的自动化维护，所以在使用服务路由配置的时候，我们不需要向传统路由配置方式那样去指定具体的服务实例地址，只需要通过Ant模式配置文件参数即可 5、使用nginx做转发 现在有两个网站想互相访问接口 在http://a.a.com:81/A中想访问 http://b.b.com:81/B 那么进行如下配置即可 然后通过访问 www.my.com/A 里面即可访问 www.my.com/B123456789101112server { listen 80; server_name www.my.com; location /A { proxy_pass http://a.a.com:81/A; index index.html index.htm; } location /B { proxy_pass http://b.b.com:81/B; index index.html index.htm; } } 如果是两个端口想互相访问接口 在http://b.b.com:80/Api中想访问 http://b.b.com:81/Api 那么进行如下配置即可 使用nginx转发机制就可以完成跨域问题12345678server { listen 80; server_name b.b.com; location /Api { proxy_pass http://b.b.com:81/Api; index index.html index.htm; } }","link":"/2019/04/25/%E7%BD%91%E7%AB%99%E8%B7%A8%E5%9F%9F%E7%9A%84%E5%9B%9B%E7%A7%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/"},{"title":"网站防止恶意登陆或防盗链的使用","text":"使用场景：明明引用了一个正确的图片地址，但显示出来的却是一个红叉或写有“此图片仅限于网站用户交流沟通使用”之类的“假图片”。用嗅探软件找到了多媒体资源的真实地址用下载软件仍然不能下载。下载一些资源时总是出错，如果确认地址没错的话，大多数情况都是遇上防盗链系统了。常见的防盗链系统，一般使用在图片、音视频、软件等相关的资源上。 实现原理：把当前请求的主机与服务器的主机进行比对，如果不一样则就是恶意链接，反之则是正常链接。 不说了，直接上代码： 1234567891011121314String address=request.getHeader(&quot;referer&quot;); //获取页面的请求地址 String pathAdd=&quot;&quot;; //定义空字符串 if(address!=null){ //判断当前的页面的请求地址为空时 URL urlOne=new URL(address);//实例化URL方法 pathAdd=urlOne.getHost(); //获取请求页面的服务器主机 } String address1=request.getRequestURL().toString(); //获取当前页面的地址 String pathAdd1=&quot;&quot;; if(address1!=null){ URL urlTwo=new URL(address1); pathAdd1=urlTwo.getHost(); //获取当前服务器的主机 } if(!pathAdd.equals(pathAdd1)){ //判断当前页面的主机与服务器的主机是否相同 } 根据这个原理 可以设置企业白名单 使用Request对象设置页面的防盗链 所谓的防盗链就是当你以一个非正常渠道去访问某一个Web资源的时候，服务器会将你的请求忽略并且将你的当前请求变为按正常渠道访问时的请求并返回到相应的页面，用户只有通过该页面中的相关操作去访问想要请求的最终资源。 例如，你有一个访问某资源的网址，但是你事先不知道这个网址是有防盗链的，那么当你输入该网址时你可能会发现，并没有马上跳转到你想要的资源页面而是一些无关的信息页面，但是就是在这些信息页面中你发现有一个超链接或是其他操作可以跳转到你所访问的最终资源页面。 这就是防盗链技术了，好了来看一个具体应用： 123456789101112131415161718192021222324252627282930313233Request.java package net.csdn.request;import java.io.IOException; import java.io.PrintWriter;import java.util.Enumeration import javax.servlet.RequestDispatcher; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class Request extends HttpServlet { public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {getDoorChain(request, response);} private void getDoorChain(HttpServletRequest request, HttpServletResponse response) throws IOException { String referer = request.getHeader(&quot;referer&quot;); if(referer==null || !referer.endsWith(&quot;http://localhost:8080/Request/index.jsp&quot;)){ response.sendRedirect(&quot;http://localhost:8080/Request/index.jsp&quot;); return; } response.setCharacterEncoding(&quot;utf-8&quot;); response.setContentType(&quot;text/html;charset =utf-8&quot;); PrintWriter pw = response.getWriter(); pw.write(&quot;喜剧片《东成西就》&quot;); } public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } } 123456789101112131415161718192021222324252627282930313233index.jsp &lt;%@ page language=&quot;java&quot; import=&quot;java.util.*&quot; pageEncoding=&quot;utf-8&quot;%&gt; &lt;% String path = request.getContextPath(); String basePath = request.getScheme()+&quot;://&quot;+request.getServerName()+&quot;:&quot; +request.getServerPort()+path+&quot;/&quot;; %&gt; &lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt; &lt;html&gt; &lt;head&gt; &lt;base href=&quot;&lt;%=basePath%&gt;&quot;&gt; &lt;title&gt;My JSP 'index.jsp' starting page&lt;/title&gt; &lt;meta http-equiv=&quot;pragma&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot;&gt; &lt;meta http-equiv=&quot;expires&quot; content=&quot;0&quot;&gt; &lt;meta http-equiv=&quot;keywords&quot; content=&quot;keyword1,keyword2,keyword3&quot;&gt; &lt;meta http-equiv=&quot;description&quot; content=&quot;This is my page&quot;&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;styles.css&quot;&gt; --&gt; &lt;/head&gt; &lt;body&gt; 这里是防盗链技术的应用检测！ &lt;br&gt; &lt;a href =&quot;/Request/Request&quot; &gt;喜剧片 &lt;/a&gt; &lt;/body&gt; &lt;/html&gt; 例如我最终想要通过http://lcoalhost:8080/Request/Request这个网址获取到我想要的《东成西就》 的资源可是当我真正的输入这个网址时，却转到了： http://localhost:8080/Request/index.jsp这个页面 只有当你点击“喜剧片”这个超链接时才会真正的得到你想要的资源页面 什么是Referer？这里的 Referer 指的是HTTP头部的一个字段，也称为HTTP来源地址（HTTP Referer），用来表示从哪儿链接到目前的网页，采用的格式是URL。换句话说，借着 HTTP Referer 头部网页可以检查访客从哪里而来，这也常被用来对付伪造的跨网站请求。 什么是空Referer，什么时候会出现空Referer？ 首先，我们对空Referer的定义为，Referer 头部的内容为空，或者，一个HTTP请求中根本不包含Referer头部。 那么什么时候HTTP请求会不包含Referer字段呢？根据Referer的定义，它的作用是指示一个请求是从哪里链接过来，那么当一个请求并不是由链接触发产生的，那么自然也就不需要指定这个请求的链接来源。 比如，直接在浏览器的地址栏中输入一个资源的URL地址，那么这种请求是不会包含Referer字段的，因为这是一个“凭空产生”的HTTP请求，并不是从一个地方链接过去的。 在防盗链设置中，允许空Referer和不允许空Referer有什么区别？ 在防盗链中，如果允许包含空的Referer，那么通过浏览器地址栏直接访问该资源URL是可以访问到的； 但如果不允许包含空的Referer，那么通过浏览器直接访问也是被禁止的。","link":"/2019/05/10/%E7%BD%91%E7%AB%99%E9%98%B2%E6%AD%A2%E6%81%B6%E6%84%8F%E7%99%BB%E9%99%86%E6%88%96%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"自己搭建一个 SpringCloud 商城 --- 第一天","text":"最近看到了一个 微服务制作的商城 onemall https://gitee.com/zhijiantianya/onemall 这是一个未完善的商城。 突然 自己也想搭建一个SpringCloud 商城 搭建项目环境 创建项目 12345678910111213141516171819├─nnmall----------------------------父项目，公共依赖│ ││ ├─nnmall-eureka-----------------------微服务配置中心│ ││ ├─nnmall-system│ │ ││ │ ├─nnmall-system-api-------------------管理员api│ │ ││ │ ├─nnmall-system-impl------------------管理员实现类│ │ ││ │ ├─nnmall-system-sdk-------------------管理员提供的权限拦截注解│ │ ││ │ └─nnmall-system-web-------------------管理员web│ ││ ├─nnmall-common--------------------------公共包│ │ ││ │ ├─mall-spring-core--------------------核心包 全局异常拦截与拦截器│ │ ││ │ └─nnmall-common-core------------------一些常用对象和类 创建gitlab仓库 权限服务 先完成商城后台管理 加入管理员权限拦截 增加、删除、更改、查询 记录遇到的种种坑 一定要注意扫包的路径 在springboot 扫包路径最好是填写一下 不然他不扫你的jar包里面的注解 1234567891011121314151617import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.openfeign.EnableFeignClients;import org.springframework.scheduling.annotation.EnableAsync;@SpringBootApplication(scanBasePackages = {&quot;cn.yunlongn.mall.admin&quot;, &quot;cn.yunlongn.mall.spring.core&quot;})@EnableAsync(proxyTargetClass = true)@EnableEurekaClient@EnableFeignClients(basePackages = {&quot;cn.yunlongn.mall.admin&quot;})public class SystemApplication { public static void main(String[] args) { SpringApplication.run(SystemApplication.class, args); }} 在feign的调用中遇到的问题有 如果你的服务返回了错误信息。那么你的返回结果可能就不一定会有错误提示。 最好是转发一下你服务的错误提示。 转发方法如下 继承feign 的异常处理类 使用feign的时候 最好是能做一个fallback处理使用hystrix 的熔断机制。当服务不能即时响应的时候 可以自己设置一个返回信息 （请参考https://blog.csdn.net/asdfsadfasdfsa/article/details/79286960） 1234567891011121314151617181920212223242526272829303132333435363738import cn.yunlongn.mall.common.core.exception.ServiceException;import com.alibaba.fastjson.JSONException;import com.alibaba.fastjson.JSONObject;import feign.Response;import feign.Util;import feign.codec.ErrorDecoder;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.context.annotation.Configuration;import java.io.IOException;/** * 定义feign的异常处理类 在feign出异常的时候进入此类 * 例如feign的密码错误 */@Configurationpublic class FeignErrorDecoder implements ErrorDecoder { @Override public Exception decode(String methodKey, Response response) { try { // 这里直接拿到我们抛出的异常信息 String message = Util.toString(response.body().asReader()); try { JSONObject jsonObject = JSONObject.parseObject(message); return new ServiceException(jsonObject.getInteger(&quot;code&quot;),jsonObject.getString(&quot;message&quot;)); } catch (JSONException e) { e.printStackTrace(); } } catch (IOException ignored) { } return decode(methodKey, response); }}","link":"/2019/05/31/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA-SpringCloud-%E5%95%86%E5%9F%8E-%E7%AC%AC%E4%B8%80%E5%A4%A9/"},{"title":"解决git push代码到github上一直提示输入用户名及密码的问题","text":"我们将github上的工程clone到本地后，修改完代码后想要push到github，但一直会有提示输入用户名及密码.原因分析 出现这种情况的原因是我们使用了http的方式clone代码到本地，相应的，也是使用http的方式将代码push到服务器。 如图所示，在github系统上克隆代码的地址默认采用的是http的方式，我们一般这样clone代码： git clone https://github.com/yychuyu/linux-system-programming.git 这就容易导致这个问题的出现。 而如果采用ssh方式的话，是这样clone代码的： git clone git@github.com:yychuyu/linux-system-programming.git 解决办法 解决办法很简单，将http方式改为ssh方式即可。 先查看当前方式： git remote -v 把http方式改为ssh方式。先移除旧的http的origin： git remote rm origin 再添加新的ssh方式的origin： git remote add origin git@github.com:yunlongn/myHexo.git 改动完之后直接执行git push是无法推送代码的，需要设置一下上游要跟踪的分支，与此同时会自动执行一次git push命令，此时已经不用要求输入用户名及密码啦！ git push --set-upstream origin master","link":"/2019/04/29/%E8%A7%A3%E5%86%B3git-push%E4%BB%A3%E7%A0%81%E5%88%B0github%E4%B8%8A%E4%B8%80%E7%9B%B4%E6%8F%90%E7%A4%BA%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%8F%8A%E5%AF%86%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98/"},{"title":"记一次事务的坑 Transaction rolled back because it has been marked as rollback-only","text":"最近在项目中发现了一则报错：“org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only”。根据报错信息来看是spring框架中的事务管理报错：事务回滚了，因为它被标记为回滚状态。 报错原因多层嵌套事务中，如果使用了默认的事务传播方式，当内层事务抛出异常，外层事务捕捉并正常执行完毕时，就会报出rollback-only异常。 spring框架是使用AOP的方式来管理事务，如果一个被事务管理的方法正常执行完毕，方法结束时spring会将方法中的sql进行提交。如果方法执行过程中出现异常，则回滚。spring框架的默认事务传播方式是PROPAGATION_REQUIRED：如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。在项目中，一般我们都会使用默认的传播方式，这样无论外层事务和内层事务任何一个出现异常，那么所有的sql都不会执行。在嵌套事务场景中，内层事务的sql和外层事务的sql会在外层事务结束时进行提交或回滚。如果内层事务抛出异常e，在内层事务结束时，spring会把事务标记为“rollback-only”。这时如果外层事务捕捉了异常e，那么外层事务方法还会继续执行代码，直到外层事务也结束时，spring发现事务已经被标记为“rollback-only”，但方法却正常执行完毕了，这时spring就会抛出“org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only”。代码示例如下： 12345678910111213141516171819Class ServiceA { @Resource(name = &quot;serviceB&quot;) private ServiceB b; @Transactional public void a() { try { b.b() } catch (Exception ignore) { } }}Class ServiceB { @Transactional public void b() { throw new RuntimeException(); }} 当调用a()时，就会报出“rollback-only”异常。 解决方案 如果希望内层事务抛出异常时中断程序执行，直接在外层事务的catch代码块中抛出e. 如果希望程序正常执行完毕，并且希望外层事务结束时全部提交，需要在内层事务中做异常捕获处理。 如果希望内层事务回滚，但不影响外层事务提交，需要将内层事务的传播方式指定为PROPAGATION_NESTED。注：PROPAGATION_NESTED基于数据库savepoint实现的嵌套事务，外层事务的提交和回滚能够控制嵌内层事务，而内层事务报错时，可以返回原始savepoint，外层事务可以继续提交。 在我的项目中之所以会报“rollback-only”异常的根本原因是代码风格不一致的原因。外层事务对错误的处理方式是返回true或false来告诉上游执行结果，而内层事务是通过抛出异常来告诉上游（这里指外层事务）执行结果，这种差异就导致了“rollback-only”异常。虽然最后事务依然是回滚了，不影响程序对sql的处理，但外层事务的上游本期望返回true和false，却收到了UnexpectedRollbackException异常，(╯￣Д￣)╯︵ ┻━┻。 附：事务传播方式 @see org.springframework.transaction.annotation.Propagation | 事务传播方式 | 说明 | | ——– | —– || PROPAGATION_REQUIRED | 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是默认的传播方式 || PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行 || PROPAGATION_MANDATORY | 使用当前的事务，如果当前没有事务，就抛出异常 || PROPAGATION_REQUIRES_NEW | 新建事务，如果当前存在事务，把当前事务挂起 || PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 || PROPAGATION_NEVER | 以非事务方式执行，如果当前存在事务，则抛出异常 || PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 || PROPAGATION_NESTED | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 |","link":"/2019/05/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9D%91Transaction-rolled-back-because-it-has-been-marked-as-rollback-only/"},{"title":"说说MySQL读写分离的原理？主从同步延时咋解决？","text":"1、面试题你们有没有做MySQL读写分离？如何实现mysql的读写分离？MySQL主从复制原理的是啥？如何解决mysql主从同步的延时问题？ 2、面试官心里分析这个，高并发这个阶段，那肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？ 3、面试题剖析（1）如何实现mysql的读写分离？其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。 （2）MySQL主从复制原理的是啥？主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个中继日志中。接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。 这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。 而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。 所以mysql实际上在这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题。 这个所谓半同步复制，semi-sync复制，指的就是主库写入binlog日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成了。 所谓并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 1）主从复制的原理 2）主从延迟问题产生的原因 3）主从复制的数据丢失问题，以及半同步复制的原理 4）并行复制的原理，多库并发重放relay日志，缓解主从延迟问题 （3）mysql主从同步延时问题（精华）线上确实处理过因为主从同步延时问题，导致的线上的bug，小型的生产事故 show status，Seconds_Behind_Master，你可以看到从库复制主库的数据落后了几ms 其实这块东西我们经常会碰到，就比如说用了mysql主从架构之后，可能会发现，刚写入库的数据结果没查到，结果就完蛋了。。。。 所以实际上你要考虑好应该在什么场景下来用这个mysql主从同步，建议是一般在读远远多于写，而且读的时候一般对数据时效性要求没那么高的时候，用mysql主从同步 所以这个时候，我们可以考虑的一个事情就是，你可以用mysql的并行复制，但是问题是那是库级别的并行，所以有时候作用不是很大 所以这个时候。。通常来说，我们会对于那种写了之后立马就要保证可以查到的场景，采用强制读主库的方式，这样就可以保证你肯定的可以读到数据了吧。其实用一些数据库中间件是没问题的。 一般来说，如果主从延迟较为严重 1、分库，将一个主库拆分为4个主库，每个主库的写并发就500/s，此时主从延迟可以忽略不计 2、打开mysql支持的并行复制，多个库并行复制，如果说某个库的写入并发就是特别高，单库写并发达到了2000/s，并行复制还是没意义。28法则，很多时候比如说，就是少数的几个订单表，写入了2000/s，其他几十个表10/s。 3、重写代码，写代码的同学，要慎重，当时我们其实短期是让那个同学重写了一下代码，插入数据之后，直接就更新，不要查询 4、如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置直连主库。不推荐这种方法，你这么搞导致读写分离的意义就丧失了","link":"/2019/01/21/%E8%AF%B4%E8%AF%B4MySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%8E%9F%E7%90%86%EF%BC%9F%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%BB%B6%E6%97%B6%E5%92%8B%E8%A7%A3%E5%86%B3%EF%BC%9F/"},{"title":"面试题 - 使用线程交替打印奇数偶数","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书 分析题目。需要使用两个线程交替打印奇偶数。 使用同步锁解决这个问题 使用信号量来实现交替打印 定义两个信号量，一个奇数信号量，一个偶数信号量，都初始化为1 先用掉偶数的信号量，因为要让奇数先启动，等奇数打印完再释放 信号量实现 具体实现思路： 定义两个信号量，一个奇数信号量，一个偶数信号量，都初始化为1 先用掉偶数的信号量，因为要让奇数先启动，等奇数打印完再释放 具体流程就是 第一次的时候先减掉偶数的信号量 奇数线程打印完成以后用掉奇数的信号量。然后释放偶数的信号量如此循环 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import java.util.concurrent.Semaphore;/** * @ClassName AlternatePrinting * @Author yunlogn * @Date 2019/5/21 * @Description 交替打印奇偶数 */public class AlternatePrinting { static int i = 0; public static void main(String[] args) throws InterruptedException { Semaphore semaphoreOdd = new Semaphore(1); Semaphore semaphoreEven = new Semaphore(1); semaphoreOdd.acquire(); //让奇数先等待启动，所以先减掉偶数的信号量 等奇数线程来释放 SemaphorePrintEven semaphorePrintEven = new SemaphorePrintEven(semaphoreOdd, semaphoreEven); Thread t1 = new Thread(semaphorePrintEven); t1.start(); SemaphorePrintOdd semaphorePrintOdd = new SemaphorePrintOdd(semaphoreOdd, semaphoreEven); Thread t2 = new Thread(semaphorePrintOdd); t2.start(); } /** * 使用信号量实现 */ static class SemaphorePrintOdd implements Runnable { private Semaphore semaphoreOdd; private Semaphore semaphoreEven; public SemaphorePrintOdd(Semaphore semaphoreOdd, Semaphore semaphoreEven) { this.semaphoreOdd = semaphoreOdd; this.semaphoreEven = semaphoreEven; } @Override public void run() { try { semaphoreOdd.acquire();//获取信号量 semaphoreOdd在初始化的时候被获取了信号量所以这里被阻塞了，所以会先执行下面的奇数线程 while (true) { i++; if (i % 2 == 0) { System.out.println(&quot;偶数线程：&quot; + i); semaphoreEven.release();//释放偶数信号量 让奇数线程那边的阻塞解除 //再次申请获取偶数信号量，因为之前已经获取过，如果没有奇数线程去释放，那么就会一直阻塞在这，等待奇数线程释放 semaphoreOdd.acquire(); } } } catch (InterruptedException e) { e.printStackTrace(); } } } static class SemaphorePrintEven implements Runnable { private Semaphore semaphoreOdd; private Semaphore semaphoreEven; public SemaphorePrintEven(Semaphore semaphoreOdd, Semaphore semaphoreEven) { this.semaphoreOdd = semaphoreOdd; this.semaphoreEven = semaphoreEven; } @Override public void run() { try { semaphoreEven.acquire(); while (true) { i++; if (i % 2 == 1) { System.out.println(&quot;奇数线程：&quot; + i); semaphoreOdd.release(); //释放奇数信号量 让偶数线程那边的阻塞解除 //这里阻塞，等待偶数线程释放信号量 //再次申请获取奇数信号量，需要等偶数线程执行完然后释放该信号量，不然阻塞 semaphoreEven.acquire(); } } } catch (Exception ex) {} } }} 需要注意的是，如果某个线程来不及释放就异常中断了，会导致另一个线程一直在等，造成死锁。 虽然这个异常不在这个问题的考虑范围内 但是可以使用finally 来包裹释放锁资源 同步锁打印 让两个线程使用同一把锁。交替执行 。 判断是不是奇数 如果是奇数进入奇数线程执行打印并加一。然后线程释放锁资源。然后让该线程等待 判断是不是偶数，如果是偶数进入偶数线程执行打印并加一。然后线程释放锁资源。然后让该线程等待 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.util.concurrent.atomic.AtomicInteger;/** * @ClassName AlternatePrinting * @Author yunlogn * @Date 2019/5/21 * @Description 交替打印奇偶数 */public class AlternatePrinting { public static AtomicInteger atomicInteger = new AtomicInteger(1); public static void main(String[] args) throws InterruptedException { Thread a=new Thread(new AThread()); Thread b=new Thread(new BThread()); a.start(); b.start(); } public static class AThread implements Runnable { @Override public void run() { while (true) { synchronized (atomicInteger) { if (atomicInteger.intValue() % 2 != 0) { System.out.println(&quot;奇数线程:&quot; + atomicInteger.intValue()); atomicInteger.getAndIncrement(); // 奇数线程释放锁资源 atomicInteger.notify(); try { atomicInteger.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { try { // 奇数线程等待 atomicInteger.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } } } public static class BThread implements Runnable { @Override public void run() { while (true){ synchronized (atomicInteger){ if(atomicInteger.intValue() %2== 0 ){ System.out.println(&quot;偶数线程:&quot;+ atomicInteger.intValue()); atomicInteger.getAndIncrement(); // 偶数线程释放锁资源 atomicInteger.notify(); try { atomicInteger.wait(); } catch (InterruptedException e) { e.printStackTrace(); } }else{ try { // 偶数线程等待 atomicInteger.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } } }} 一种更简单的写法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class TheadTest { public static void main(String[] args) { PrintDigitThread print1 = new PrintDigitThread((i) -&gt; i % 2 == 1, &quot;thread1&quot;); PrintDigitThread print2 = new PrintDigitThread((i) -&gt; i % 2 == 0, &quot;thread2&quot;); print1.start(); print2.start(); }} class ShareData { public static final AtomicInteger atomicInt = new AtomicInteger(0);} class PrintDigitThread extends Thread { private Predicate&lt;Integer&gt; predicate; public PrintDigitThread(Predicate&lt;Integer&gt; predicate, String name) { this.predicate = predicate; this.setName(name); } @Override public void run() { int v = ShareData.atomicInt.get(); while (v &lt; 100) { synchronized (ShareData.atomicInt) { v = ShareData.atomicInt.get(); if (predicate.test(v)) { System.out.println(Thread.currentThread().getName() + &quot;:&quot; + v); ShareData.atomicInt.incrementAndGet(); try { ShareData.atomicInt.notify(); } catch (Exception ex) { } } else { try { ShareData.atomicInt.wait(); } catch (Exception ex) { } } } } }} 欢迎关注 http://yunlongn.github.io","link":"/2019/05/21/%E9%9D%A2%E8%AF%95%E9%A2%98-%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E5%A5%87%E6%95%B0%E5%81%B6%E6%95%B0/"},{"title":"J2EE基础知识","text":"这世上有三样东西是别人抢不走的：一是吃进胃里的食物，二是藏在心中的梦想，三是读进大脑的书本文引用 https://github.com/Snailclimb/JavaGuide自己进行了添加与修改 Servlet总结在Java Web程序中，Servlet主要负责接收用户请求HttpServletRequest,在doGet(),doPost()**中做相应的处理，并将回应HttpServletResponse反馈给用户。Servlet可以设置初始化参数，供Servlet内部使用。一个Servlet类只会有一个实例，在它初始化时调用init()方法，销毁时调用destroy()方法。Servlet需要在web.xml中配置（MyEclipse中创建Servlet会自动配置），一个Servlet可以设置多个URL访问。Servlet不是线程安全**，因此要谨慎使用类变量。 阐述Servlet和CGI的区别?CGI的不足之处:1，需要为每个请求启动一个操作CGI程序的系统进程。如果请求频繁，这将会带来很大的开销。 2，需要为每个请求加载和运行一个CGI程序，这将带来很大的开销 3，需要重复编写处理网络协议的代码以及编码，这些工作都是非常耗时的。 Servlet的优点:1，只需要启动一个操作系统进程以及加载一个JVM，大大降低了系统的开销 2，如果多个请求需要做同样处理的时候，这时候只需要加载一个类，这也大大降低了开销 3，所有动态加载的类可以实现对网络协议以及请求解码的共享，大大降低了工作量。 4，Servlet能直接和Web服务器交互，而普通的CGI程序不能。Servlet还能在各个程序之间共享数据，使数据库连接池之类的功能很容易实现。 补充：Sun Microsystems公司在1996年发布Servlet技术就是为了和CGI进行竞争，Servlet是一个特殊的Java程序，一个基于Java的Web应用通常包含一个或多个Servlet类。Servlet不能够自行创建并执行，它是在Servlet容器中运行的，容器将用户的请求传递给Servlet程序，并将Servlet的响应回传给用户。通常一个Servlet会关联一个或多个JSP页面。以前CGI经常因为性能开销上的问题被诟病，然而Fast CGI早就已经解决了CGI效率上的问题，所以面试的时候大可不必信口开河的诟病CGI，事实上有很多你熟悉的网站都使用了CGI技术。 参考：《javaweb整合开发王者归来》P7 Servlet接口中有哪些方法及Servlet生命周期探秘Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关： void init(ServletConfig config) throws ServletException void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException void destory() java.lang.String getServletInfo() ServletConfig getServletConfig() 生命周期： Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。init方法和destroy方法只会执行一次，service方法客户端每次请求Servlet都会执行。Servlet中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入init方法中，销毁资源的代码放入destroy方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。 参考：《javaweb整合开发王者归来》P81 get和post请求的区别 网上也有文章说：get和post请求实际上是没有区别，大家可以自行查询相关文章（参考文章：https://www.cnblogs.com/logsharing/p/8448446.html，知乎对应的问题链接：get和post区别？）！我下面给出的只是一种常见的答案。 ①get请求用来从服务器上获得资源，而post是用来向服务器提交数据； ②get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?”连接，而各个变量之间使用”&amp;”连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL； ③get传输的数据要受到URL长度限制（最大长度是 2048 个字符）；而post可以传输大量的数据，上传文件通常要使用post方式； ④使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post； ⑤get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。 补充：GET方式提交表单的典型应用是搜索引擎。GET方式就是被设计为查询用的。 还有另外一种回答。推荐大家看一下： https://www.zhihu.com/question/28586791 https://mp.weixin.qq.com/s?__biz=MzI3NzIzMzg3Mw==&amp;mid=100000054&amp;idx=1&amp;sn=71f6c214f3833d9ca20b9f7dcd9d33e4#rd 什么情况下调用doGet()和doPost()Form标签里的method的属性为get时调用doGet()，为post时调用doPost()。 转发(Forward)和重定向(Redirect)的区别转发是服务器行为，重定向是客户端行为。 转发（Forward）通过RequestDispatcher对象的forward（HttpServletRequest request,HttpServletResponse response）方法实现的。RequestDispatcher可以通过HttpServletRequest 的getRequestDispatcher()方法获得。例如下面的代码就是跳转到login_success.jsp页面。 1request.getRequestDispatcher(&quot;login_success.jsp&quot;).forward(request, response); 重定向（Redirect） 是利用服务器返回的状态码来实现的。客户端浏览器请求服务器的时候，服务器会返回一个状态码。服务器通过 HttpServletResponse 的 setStatus(int status) 方法设置状态码。如果服务器返回301或者302，则浏览器会到新的网址重新请求该资源。 从地址栏显示来说 forward是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址.redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 从数据共享来说 forward:转发页面和转发到的页面可以共享request里面的数据.redirect:不能共享数据. 从运用地方来说 forward:一般用于用户登陆的时候,根据角色转发到相应的模块.redirect:一般用于用户注销登陆时返回主页面和跳转到其它的网站等 从效率来说 forward:高.redirect:低. 自动刷新(Refresh)自动刷新不仅可以实现一段时间之后自动跳转到另一个页面，还可以实现一段时间之后自动刷新本页面。Servlet中通过HttpServletResponse对象设置Header属性实现自动刷新例如： 1Response.setHeader(&quot;Refresh&quot;,&quot;5;URL=http://localhost:8080/servlet/example.htm&quot;); 其中5为时间，单位为秒。URL指定就是要跳转的页面（如果设置自己的路径，就会实现每过5秒自动刷新本页面一次） Servlet与线程安全Servlet不是线程安全的，多线程并发的读写会导致数据不同步的问题。 解决的办法是尽量不要定义name属性，而是要把name变量分别定义在doGet()和doPost()方法内。虽然使用synchronized(name){}语句块可以解决问题，但是会造成线程的等待，不是很科学的办法。注意：多线程的并发的读写Servlet类属性会导致数据不同步。但是如果只是并发地读取属性而不写入，则不存在数据不同步的问题。因此Servlet里的只读属性最好定义为final类型的。 参考：《javaweb整合开发王者归来》P92 JSP和Servlet是什么关系其实这个问题在上面已经阐述过了，Servlet是一个特殊的Java程序，它运行于服务器的JVM中，能够依靠服务器的支持向浏览器提供显示内容。JSP本质上是Servlet的一种简易形式，JSP会被服务器处理成一个类似于Servlet的Java程序，可以简化页面内容的生成。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件。有人说，Servlet就是在Java中写HTML，而JSP就是在HTML中写Java代码，当然这个说法是很片面且不够准确的。JSP侧重于视图，Servlet更侧重于控制逻辑，在MVC架构模式中，JSP适合充当视图（view）而Servlet适合充当控制器（controller）。 JSP工作原理JSP是一种Servlet，但是与HttpServlet的工作方式不太一样。HttpServlet是先由源代码编译为class文件后部署到服务器下，为先编译后部署。而JSP则是先部署后编译。JSP会在客户端第一次请求JSP文件时被编译为HttpJspPage类（接口Servlet的一个子类）。该类会被服务器临时存放在服务器工作目录里面。下面通过实例给大家介绍。工程JspLoginDemo下有一个名为login.jsp的Jsp文件，把工程第一次部署到服务器上后访问这个Jsp文件，我们发现这个目录下多了下图这两个东东。.class文件便是JSP对应的Servlet。编译完毕后再运行class文件来响应客户端请求。以后客户端访问login.jsp的时候，Tomcat将不再重新编译JSP文件，而是直接调用class文件来响应客户端请求。由于JSP只会在客户端第一次请求的时候被编译 ，因此第一次请求JSP时会感觉比较慢，之后就会感觉快很多。如果把服务器保存的class文件删除，服务器也会重新编译JSP。 开发Web程序时经常需要修改JSP。Tomcat能够自动检测到JSP程序的改动。如果检测到JSP源代码发生了改动。Tomcat会在下次客户端请求JSP时重新编译JSP，而不需要重启Tomcat。这种自动检测功能是默认开启的，检测改动会消耗少量的时间，在部署Web应用的时候可以在web.xml中将它关掉。 参考：《javaweb整合开发王者归来》P97 JSP有哪些内置对象、作用分别是什么JSP内置对象 - CSDN博客 JSP有9个内置对象： request：封装客户端的请求，其中包含来自GET或POST请求的参数； response：封装服务器对客户端的响应； pageContext：通过该对象可以获取其他对象； session：封装用户会话的对象； application：封装服务器运行环境的对象； out：输出服务器响应的输出流对象； config：Web应用的配置对象； page：JSP页面本身（相当于Java程序中的this）； exception：封装页面抛出异常的对象。 Request对象的主要方法有哪些 setAttribute(String name,Object)：设置名字为name的request 的参数值 getAttribute(String name)：返回由name指定的属性值 getAttributeNames()：返回request 对象所有属性的名字集合，结果是一个枚举的实例 getCookies()：返回客户端的所有 Cookie 对象，结果是一个Cookie 数组 getCharacterEncoding() ：返回请求中的字符编码方式 = getContentLength() ：返回请求的 Body的长度 getHeader(String name) ：获得HTTP协议定义的文件头信息 getHeaders(String name) ：返回指定名字的request Header 的所有值，结果是一个枚举的实例 getHeaderNames() ：返回所以request Header 的名字，结果是一个枚举的实例 getInputStream() ：返回请求的输入流，用于获得请求中的数据 getMethod() ：获得客户端向服务器端传送数据的方法 getParameter(String name) ：获得客户端传送给服务器端的有 name指定的参数值 getParameterNames() ：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例 getParameterValues(String name)：获得有name指定的参数的所有值 getProtocol()：获取客户端向服务器端传送数据所依据的协议名称 getQueryString() ：获得查询字符串 getRequestURI() ：获取发出请求字符串的客户端地址 getRemoteAddr()：获取客户端的 IP 地址 getRemoteHost() ：获取客户端的名字 getSession([Boolean create]) ：返回和请求相关 Session getServerName() ：获取服务器的名字 getServletPath()：获取客户端所请求的脚本文件的路径 getServerPort()：获取服务器的端口号 removeAttribute(String name)：删除请求中的一个属性 request.getAttribute()和 request.getParameter()有何区别从获取方向来看： getParameter()是获取 POST/GET 传递的参数值； getAttribute()是获取对象容器中的数据值； 从用途来看： getParameter用于客户端重定向时，即点击了链接或提交按扭时传值用，即用于在用表单或url重定向传值时接收数据用。 getAttribute用于服务器端重定向时，即在 sevlet 中使用了 forward 函数,或 struts 中使用了mapping.findForward。 getAttribute 只能收到程序用 setAttribute 传过来的值。 另外，可以用 setAttribute,getAttribute 发送接收对象.而 getParameter 显然只能传字符串。setAttribute 是应用服务器把这个对象放在该页面所对应的一块内存中去，当你的页面服务器重定向到另一个页面时，应用服务器会把这块内存拷贝另一个页面所对应的内存中。这样getAttribute就能取得你所设下的值，当然这种方法可以传对象。session也一样，只是对象在内存中的生命周期不一样而已。getParameter只是应用服务器在分析你送上来的 request页面的文本时，取得你设在表单或 url 重定向时的值。 总结： getParameter 返回的是String,用于读取提交的表单中的值;（获取之后会根据实际需要转换为自己需要的相应类型，比如整型，日期类型啊等等） getAttribute 返回的是Object，需进行转换,可用setAttribute 设置成任意对象，使用很灵活，可随时用 include指令include的行为的区别include指令： JSP可以通过include指令来包含其他文件。被包含的文件可以是JSP文件、HTML文件或文本文件。包含的文件就好像是该JSP文件的一部分，会被同时编译执行。 语法格式如下：&lt;%@ include file=”文件相对 url 地址” %&gt; include动作： jsp:include动作元素用来包含静态和动态的文件。该动作把指定文件插入正在生成的页面。语法格式如下：&lt;jsp:include page=”相对 URL 地址” flush=”true” /&gt; JSP九大内置对象，七大动作，三大指令JSP九大内置对象，七大动作，三大指令总结 讲解JSP中的四种作用域JSP中的四种作用域包括page、request、session和application，具体来说： page代表与一个页面相关的对象和属性。 request代表与Web客户机发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个Web组件；需要在页面显示的临时数据可以置于此作用域。 session代表与某个用户与服务器建立的一次会话相关的对象和属性。跟某个用户相关的数据应该放在用户自己的session中。 application代表与整个Web应用程序相关的对象和属性，它实质上是跨越整个Web应用程序，包括多个页面、请求和会话的一个全局作用域。 如何实现JSP或Servlet的单线程模式对于JSP页面，可以通过page指令进行设置。&lt;%@page isThreadSafe=”false”%&gt; 对于Servlet，可以让自定义的Servlet实现SingleThreadModel标识接口。 说明：如果将JSP或Servlet设置成单线程工作模式，会导致每个请求创建一个Servlet实例，这种实践将导致严重的性能问题（服务器的内存压力很大，还会导致频繁的垃圾回收），所以通常情况下并不会这么做。 实现会话跟踪的技术有哪些 使用Cookie 向客户端发送Cookie 123Cookie c =new Cookie(&quot;name&quot;,&quot;value&quot;); //创建Cookie c.setMaxAge(60*60*24); //设置最大时效，此处设置的最大时效为一天response.addCookie(c); //把Cookie放入到HTTP响应中 其实Java的底层实现原理就是 （将设置的cookie 用Set-Cookie的方式返回给浏览器） 从客户端读取Cookie 12345678910111213String name =&quot;name&quot;; Cookie[]cookies =request.getCookies(); if(cookies !=null){ for(int i= 0;i&lt;cookies.length;i++){ Cookie cookie =cookies[i]; if(name.equals(cookis.getName())) //something is here. //you can get the value cookie.getValue(); } } 优点: 数据可以持久保存，不需要服务器资源，简单，基于文本的Key-Value 缺点: 大小受到限制，用户可以禁用Cookie功能，由于保存在本地，有一定的安全风险。 URL 重写 在URL中添加用户会话的信息作为请求的参数，或者将唯一的会话ID添加到URL结尾以标识一个会话。 优点： 在Cookie被禁用的时候依然可以使用 缺点： 必须对网站的URL进行编码，所有页面必须动态生成，不能用预先记录下来的URL进行访问。 3.隐藏的表单域 1&lt;input type=&quot;hidden&quot; name =&quot;session&quot; value=&quot;...&quot;/&gt; 优点： Cookie被禁时可以使用 缺点： 所有页面必须是表单提交之后的结果。 HttpSession 在所有会话跟踪技术中，HttpSession对象是最强大也是功能最多的。当一个用户第一次访问某个网站时会自动创建 HttpSession，每个用户可以访问他自己的HttpSession。可以通过HttpServletRequest对象的getSession方 法获得HttpSession，通过HttpSession的setAttribute方法可以将一个值放在HttpSession中，通过调用 HttpSession对象的getAttribute方法，同时传入属性名就可以获取保存在HttpSession中的对象。与上面三种方式不同的 是，HttpSession放在服务器的内存中，因此不要将过大的对象放在里面，即使目前的Servlet容器可以在内存将满时将HttpSession 中的对象移到其他存储设备中，但是这样势必影响性能。添加到HttpSession中的值可以是任意Java对象，这个对象最好实现了 Serializable接口，这样Servlet容器在必要的时候可以将其序列化到文件中，否则在序列化时就会出现异常。 Cookie和Session的的区别Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 Cookie 一般用来保存用户信息 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。","link":"/2019/05/23/J2EE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"Java源码之List,Set,Map","text":"Java原理之List,Set,Map 1、Java8对Java7的HashMap做了修改，最大的区别就是利用了红黑树。 2、Java7的结构中，查找数据的时候，我们会根据hash值快速定位到数组的具体下标。但是后面是需要通过链表去遍历数据，所以查询的速度就依赖于链表的长度，时间复杂度也自然是O(n) 3、为了减少2中出现的问题，在Java8中，当链表的个数大于8的时候，就会把链表转化为红黑树。那么在红黑树查找数据的时候，时间复杂度就变味了O(logN) 说说List,Set,Map三者的区别？ List(对付顺序的好帮手)： List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。 Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。 Arraylist 与 LinkedList 区别? 1. 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 2. 底层数据结构： Arraylist 底层使用的是Object数组；LinkedList 底层使用的是双向链表数据结构（JDK1.6之前为循环链表，JDK1.7取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！） 3. 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e) 方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element) ）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似 O（1）而数组为近似 O（n）。 4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。 5. 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 补充内容:RandomAccess接口12public interface RandomAccess {} 查看源码我们发现实际上 RandomAccess 接口中什么都没有定义。所以，在我看来 RandomAccess 接口不过是一个标识罢了。标识什么？ 标识实现这个接口的类具有随机访问功能。 在binarySearch（）方法中，它要判断传入的list 是否RamdomAccess的实例，如果是，调用indexedBinarySearch（）方法，如果不是，那么调用iteratorBinarySearch（）方法 1234567public static &lt;T&gt;int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) { if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key);} ArrayList 实现了 RandomAccess 接口， 而 LinkedList 没有实现。为什么呢？我觉得还是和底层数据结构有关！ArrayList 底层是数组，而 LinkedList 底层是链表。数组天然支持随机访问，时间复杂度为 O（1），所以称为快速随机访问。链表需要遍历到特定位置才能访问特定位置的元素，时间复杂度为 O（n），所以不支持快速随机访问。，ArrayList 实现了 RandomAccess 接口，就表明了他具有快速随机访问功能。 RandomAccess 接口只是标识，并不是说 ArrayList 实现 RandomAccess 接口才具有快速随机访问功能的！ 下面再总结一下 list 的遍历方式选择： 实现了RandomAccess接口的list，优先选择普通for循环 ，其次foreach, 未实现RandomAccess接口的ist， 优先选择iterator遍历（foreach遍历底层也是通过iterator实现的），大size的数据，千万不要使用普通for循环 补充内容:双向链表和双向循环链表双向链表： 包含两个指针，一个prev指向前一个节点，一个next指向后一个节点。 双向循环链表： 最后一个节点的 next 指向head，而 head 的prev指向最后一个节点，构成一个环。 ArrayList 与 Vector 区别呢?为什么要用Arraylist取代Vector呢？Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。 说一说 ArrayList 的扩容机制吧详见笔主的这篇文章:通过源码一步一步分析ArrayList 扩容机制 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 HasMap 中带有初始容量的构造函数： 123456789101112131415public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);} public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);} 下面这个方法保证了 HashMap 总是使用2的幂作为哈希表的大小。 123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} HashMap 和 HashSet区别如果你看过 HashSet 源码的话就应该知道：HashSet 底层就是基于 HashMap 实现的。（HashSet 的源码非常非常少，因为除了 clone() 、writeObject()、readObject()是 HashSet 自己不得不实现之外，其他方法都是直接调用 HashMap 中的方法。 HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用 put（）向map中添加元素 调用 add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性， HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。（摘自我的Java启蒙书《Head fist java》第二版） hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ==与equals的区别 ==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同 ==是指对内存地址进行比较 equals()是对字符串的内容进行比较 ==指引用是否相同 equals()指的是值是否相同 HashMap的底层实现JDK1.8之前 推荐一个很不错的源码分析文章 https://www.javadoop.com/post/hashmap JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。 所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。 JDK 1.8 HashMap 的 hash 方法源码: JDK 1.8 的 hash方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。 1234567 static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);} 对比一下 JDK1.7的 HashMap 的 hash 方法源码. 12345678static int hash(int h) { // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);} 相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。 所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 [ JDK1.8之后相比于之前的版本， JDK1.8之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。 [ TreeMap、TreeSet以及JDK1.8之后的HashMap底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。 推荐阅读： 《Java 8系列之重新认识HashMap》 ：https://zhuanlan.zhihu.com/p/21673805 HashMap 的长度为什么是2的幂次方为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648到2147483647，前后加起来大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个40亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ (n - 1) &amp; hash”。（n代表数组长度）。这也就解释了 HashMap 的长度为什么是2的幂次方。 这个算法应该如何设计呢？ 我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。” 并且 采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方。 HashMap 多线程操作导致死循环问题主要原因在于 并发下的Rehash 会造成元素之间会形成一个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。 详情请查看：https://coolshell.cn/articles/9606.html ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 两者的对比图： 图片来源：http://www.cnblogs.com/chengxiao/p/6842045.html HashTable: [ JDK1.7的ConcurrentHashMap： [JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）：[ ConcurrentHashMap线程安全的具体实现方式/底层具体实现JDK1.7（上面有示意图）首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {} 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 JDK1.8 （上面有示意图）ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))） synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 comparable 和 Comparator的区别 comparable接口实际上是出自java.lang包 它有一个 compareTo(Object obj)方法用来排序 comparator接口实际上是出自 java.util 包它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo()方法或compare()方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo()方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 Collections.sort(). Comparator定制排序123456789101112131415161718192021222324252627282930ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();arrayList.add(-1);arrayList.add(3);arrayList.add(3);arrayList.add(-5);arrayList.add(7);arrayList.add(4);arrayList.add(-9);arrayList.add(-7);System.out.println(&quot;原始数组:&quot;);System.out.println(arrayList);// void reverse(List list)：反转Collections.reverse(arrayList);System.out.println(&quot;Collections.reverse(arrayList):&quot;);System.out.println(arrayList);// void sort(List list),按自然排序的升序排序Collections.sort(arrayList);System.out.println(&quot;Collections.sort(arrayList):&quot;);System.out.println(arrayList);// 定制排序的用法Collections.sort(arrayList, new Comparator&lt;Integer&gt;() { @Override public int compare(Integer o1, Integer o2) { return o2.compareTo(o1); }});System.out.println(&quot;定制排序后：&quot;);System.out.println(arrayList); Output: 12345678原始数组:[-1, 3, 3, -5, 7, 4, -9, -7]Collections.reverse(arrayList):[-7, -9, 4, 7, -5, 3, 3, -1]Collections.sort(arrayList):[-9, -7, -5, -1, 3, 3, 4, 7]定制排序后：[7, 4, 3, 3, -1, -5, -7, -9] 重写compareTo方法实现按年龄来排序123456789101112131415161718192021222324252627282930313233343536373839404142434445// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列// 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他// 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了public class Person implements Comparable&lt;Person&gt; { private String name; private int age; public Person(String name, int age) { super(); this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } /** * TODO重写compareTo方法实现按年龄来排序 */ @Override public int compareTo(Person o) { // TODO Auto-generated method stub if (this.age &gt; o.getAge()) { return 1; } else if (this.age &lt; o.getAge()) { return -1; } return age; }} 12345678910111213public static void main(String[] args) { TreeMap&lt;Person, String&gt; pdata = new TreeMap&lt;Person, String&gt;(); pdata.put(new Person(&quot;张三&quot;, 30), &quot;zhangsan&quot;); pdata.put(new Person(&quot;李四&quot;, 20), &quot;lisi&quot;); pdata.put(new Person(&quot;王五&quot;, 10), &quot;wangwu&quot;); pdata.put(new Person(&quot;小红&quot;, 5), &quot;xiaohong&quot;); // 得到key的值的同时得到key所对应的值 Set&lt;Person&gt; keys = pdata.keySet(); for (Person key : keys) { System.out.println(key.getAge() + &quot;-&quot; + key.getName()); }} Output： 12345-小红10-王五20-李四30-张三 集合框架底层数据结构总结Collection1. List Arraylist： Object数组 Vector： Object数组 LinkedList： 双向链表(JDK1.6之前为循环链表，JDK1.7取消了循环) 详细可阅读JDK1.7-LinkedList循环链表优化 2. Set HashSet（无序，唯一）: 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。) Map HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：《LinkedHashMap 源码详细分析（JDK1.8）》 Hashtable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap： 红黑树（自平衡的排序二叉树） 如何选用集合?集合的选用主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用Map接口下的集合，需要排序时选择TreeMap,不需要排序时就选择HashMap,需要保证线程安全就选用ConcurrentHashMap.当我们只需要存放元素值时，就选择实现Collection接口的集合，需要保证元素唯一时选择实现Set接口的集合比如TreeSet或HashSet，不需要就选择实现List接口的比如ArrayList或LinkedList，然后再根据实现这些接口的集合的特点来选用。","link":"/2019/05/24/Java%E6%BA%90%E7%A0%81%E4%B9%8BList-Set-Map/"},{"title":"Netty-使用Netty传输POJO对象","text":"Netty-使用Netty传输POJO对象 使用Netty传输POJO对象，重点在于对象的序列化，序列化后的对象可以通过TCP流进行网络传输，结合Netty提供的对象编解码器，可以做到远程传输对象。 下面我们来看一个例子：模拟订票 首先Java序列化的POJO对象需要实现java.io.Serializable接口。 火车车次和余票量POJO：123456789101112131415161718192021222324252627282930package bookticket; import java.io.Serializable;/** * 火车pojo对象 * @author xwalker */public class Train implements Serializable { private static final long serialVersionUID = 1510326612440404416L; private String number;//火车车次 private int ticketCounts;//余票数量 public Train(String number,int ticketCounts){ this.number=number; this.ticketCounts=ticketCounts; } public String getNumber() { return number; } public void setNumber(String number) { this.number = number; } public int getTicketCounts() { return ticketCounts; } public void setTicketCounts(int ticketCounts) { this.ticketCounts = ticketCounts; } } 车票POJO：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package bookticket; import java.io.Serializable;import java.util.Date;/** * 订票POJO对象 * @author xwalker */public class Ticket implements Serializable { private static final long serialVersionUID = 4228051882802183587L; private String trainNumber;//火车车次 private int carriageNumber;//车厢编号 private String seatNumber;//座位编号 private String number;//车票编号 private User user;//订票用户 private Date bookTime;//订票时间 private Date startTime;//开车时间 public String getNumber() { return number; } public void setNumber(String number) { this.number = number; } public Date getBookTime() { return bookTime; } public void setBookTime(Date bookTime) { this.bookTime = bookTime; } public Date getStartTime() { return startTime; } public void setStartTime(Date startTime) { this.startTime = startTime; } public User getUser() { return user; } public void setUser(User user) { this.user = user; } public String getTrainNumber() { return trainNumber; } public void setTrainNumber(String trainNumber) { this.trainNumber = trainNumber; } public int getCarriageNumber() { return carriageNumber; } public void setCarriageNumber(int carriageNumber) { this.carriageNumber = carriageNumber; } public String getSeatNumber() { return seatNumber; } public void setSeatNumber(String seatNumber) { this.seatNumber = seatNumber; }} 用户POJO:123456789101112131415161718192021222324252627282930313233343536373839package bookticket; import java.io.Serializable;/** * 用户POJO对象 * @author xwalker */public class User implements Serializable { private static final long serialVersionUID = -3845514510571408376L; private String userId;//身份证 private String userName;//姓名 private String phone;//电话 private String email;//邮箱 public String getUserId() { return userId; } public void setUserId(String userId) { this.userId = userId; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public String getPhone() { return phone; } public void setPhone(String phone) { this.phone = phone; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; }} 请求指令集：12345678910111213package bookticket; /** * 指令集 * @author xwalker * */public class Code { public static final int CODE_SEARCH=1;//查询车票余量 public static final int CODE_BOOK=2;//订票 public static final int CODE_NONE=-1;//错误指令 无法处理} 客户端发送的请求信息：123456789101112131415161718192021222324252627282930313233343536373839404142package bookticket; import java.io.Serializable;import java.util.Date;/** * 订票人发送查询余票和订票使用的请求信息 * @author xwalker * */public class BookRequestMsg implements Serializable { private static final long serialVersionUID = -7335293929249462183L; private User user;//发送订票信息用户 private String trainNumber;//火车车次 private int code;//查询命令 private Date startTime;//开车时间 public User getUser() { return user; } public void setUser(User user) { this.user = user; } public String getTrainNumber() { return trainNumber; } public void setTrainNumber(String trainNumber) { this.trainNumber = trainNumber; } public Date getStartTime() { return startTime; } public void setStartTime(Date startTime) { this.startTime = startTime; } public int getCode() { return code; } public void setCode(int code) { this.code = code; } } 服务器接收订票和查票后处理完业务反馈客户端的信息：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package bookticket; import java.io.Serializable;import java.util.Date;/** * 订票成功与否反馈信息 * @author xwalker */public class BookResponseMsg implements Serializable { private static final long serialVersionUID = -4984721370227929766L; private boolean success;//是否操作成功 private User user;//请求用户 private String msg;//反馈信息 private int code;//请求指令 private Train train;//火车车次 private Date startTime;//出发时间 private Ticket ticket;//订票成功后具体出票票据 public boolean getSuccess() { return success; } public void setSuccess(boolean success) { this.success = success; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public Ticket getTicket() { return ticket; } public void setTicket(Ticket ticket) { this.ticket = ticket; } public int getCode() { return code; } public void setCode(int code) { this.code = code; } public Train getTrain() { return train; } public void setTrain(Train train) { this.train = train; } public Date getStartTime() { return startTime; } public void setStartTime(Date startTime) { this.startTime = startTime; } public User getUser() { return user; } public void setUser(User user) { this.user = user; } } 订票服务器：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package bookticket; import java.util.ArrayList;import java.util.List; import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder;import io.netty.handler.logging.LogLevel;import io.netty.handler.logging.LoggingHandler; /** * 订票服务器端 * @author xwalker * */public class BookTicketServer { public static List&lt;Train&gt; trains; /** * 初始化 构造车次和车票余数 */ public BookTicketServer() { trains=new ArrayList&lt;Train&gt;(); trains.add(new Train(&quot;G242&quot;,500)); trains.add(new Train(&quot;G243&quot;,200)); trains.add(new Train(&quot;D1025&quot;,100)); trains.add(new Train(&quot;D1235&quot;,0)); } public void bind(int port) throws Exception{ //配置NIO线程组 EventLoopGroup bossGroup=new NioEventLoopGroup(); EventLoopGroup workerGroup=new NioEventLoopGroup(); try{ //服务器辅助启动类配置 ServerBootstrap b=new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //添加对象解码器 负责对序列化POJO对象进行解码 设置对象序列化最大长度为1M 防止内存溢出 //设置线程安全的WeakReferenceMap对类加载器进行缓存 支持多线程并发访问 防止内存溢出 ch.pipeline().addLast(new ObjectDecoder(1024*1024,ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader()))); //添加对象编码器 在服务器对外发送消息的时候自动将实现序列化的POJO对象编码 ch.pipeline().addLast(new ObjectEncoder()); ch.pipeline().addLast(new BookTicketServerhandler()); } }); //绑定端口 同步等待绑定成功 ChannelFuture f=b.bind(port).sync(); //等到服务端监听端口关闭 f.channel().closeFuture().sync(); }finally{ //优雅释放线程资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port =8000; new BookTicketServer().bind(port); } } 服务器端网络IO处理器，查票订票业务处理和反馈：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package bookticket; import java.util.Date;import java.util.Random; import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;/** * 订票server端处理器 * @author xwalker * */public class BookTicketServerhandler extends ChannelHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { BookRequestMsg requestMsg=(BookRequestMsg) msg; BookResponseMsg responseMsg=null; switch (requestMsg.getCode()) { case Code.CODE_SEARCH://查询余票 for(Train train:BookTicketServer.trains){ //找到车次与请求车次相同的 返回车次余票 if(requestMsg.getTrainNumber().equals(train.getNumber())){ responseMsg=new BookResponseMsg(); responseMsg.setUser(requestMsg.getUser()); responseMsg.setCode(Code.CODE_SEARCH); responseMsg.setSuccess(true); responseMsg.setTrain(train); responseMsg.setStartTime(requestMsg.getStartTime()); responseMsg.setMsg(&quot;火车【&quot;+train.getNumber()+&quot;】余票数量为【&quot;+train.getTicketCounts()+&quot;】&quot;); break; } } if(responseMsg==null){ responseMsg=new BookResponseMsg(); responseMsg.setUser(requestMsg.getUser()); responseMsg.setCode(Code.CODE_SEARCH); responseMsg.setSuccess(false); responseMsg.setMsg(&quot;火车【&quot;+requestMsg.getTrainNumber()+&quot;】的信息不存在！&quot;); } break; case Code.CODE_BOOK://确认订票 for(Train train:BookTicketServer.trains){ //找到车次与请求车次相同的 返回车次余票 if(requestMsg.getTrainNumber().equals(train.getNumber())){ responseMsg=new BookResponseMsg(); responseMsg.setUser(requestMsg.getUser()); responseMsg.setSuccess(true); responseMsg.setCode(Code.CODE_BOOK); responseMsg.setMsg(&quot;恭喜您，订票成功！&quot;); Ticket ticket=new Ticket(); ticket.setBookTime(new Date()); ticket.setUser(requestMsg.getUser()); ticket.setStartTime(requestMsg.getStartTime()); ticket.setNumber(train.getNumber()+System.currentTimeMillis());//生成车票编号 ticket.setCarriageNumber(new Random().nextInt(15));//随机车厢 ticket.setUser(requestMsg.getUser());//设置订票人信息 String[] seat=new String[]{&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;}; Random seatRandom=new Random(); ticket.setSeatNumber(seat[seatRandom.nextInt(5)]+seatRandom.nextInt(100)); ticket.setTrainNumber(train.getNumber()); train.setTicketCounts(train.getTicketCounts()-1);//余票减去一张 responseMsg.setTrain(train); responseMsg.setTicket(ticket); break; } } if(responseMsg==null){ responseMsg=new BookResponseMsg(); responseMsg.setUser(requestMsg.getUser()); responseMsg.setCode(Code.CODE_BOOK); responseMsg.setSuccess(false); responseMsg.setMsg(&quot;火车【&quot;+requestMsg.getTrainNumber()+&quot;】的信息不存在！&quot;); } break; default://无法处理 responseMsg=new BookResponseMsg(); responseMsg.setUser(requestMsg.getUser()); responseMsg.setCode(Code.CODE_NONE); responseMsg.setSuccess(false); responseMsg.setMsg(&quot;指令无法处理！&quot;); break; } ctx.writeAndFlush(responseMsg); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package bookticket; import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder; /** * 订票客户端 * @author xwalker */public class BookTicketClient { public void connect(int port,String host) throws Exception{ //配置客户端线程组 EventLoopGroup group=new NioEventLoopGroup(); try{ //配置客户端启动辅助类 Bootstrap b=new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //添加POJO对象解码器 禁止缓存类加载器 ch.pipeline().addLast(new ObjectDecoder(1024,ClassResolvers.cacheDisabled(this.getClass().getClassLoader()))); //设置发送消息编码器 ch.pipeline().addLast(new ObjectEncoder()); //设置网络IO处理器 ch.pipeline().addLast(new BookTicketClientHandler()); } }); //发起异步服务器连接请求 同步等待成功 ChannelFuture f=b.connect(host,port).sync(); //等到客户端链路关闭 f.channel().closeFuture().sync(); }finally{ //优雅释放线程资源 group.shutdownGracefully(); } } public static void main(String[] args) throws Exception{ new BookTicketClient().connect(8000, &quot;127.0.0.1&quot;); } } 客户端处理网络IO处理器 发送查票和订票请求：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package bookticket; import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext; import java.util.Calendar; /** * 客户端处理器 * * @author xwalker */public class BookTicketClientHandler extends ChannelHandlerAdapter { private User user; public BookTicketClientHandler() { user=new User(); user.setUserName(&quot;xwalker&quot;); user.setPhone(&quot;187667*****&quot;); user.setEmail(&quot;909854136@qq.com&quot;); user.setUserId(&quot;3705231988********&quot;); } /** * 链路链接成功 */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { // 链接成功后发送查询某车次余票的请求 Calendar c = Calendar.getInstance(); c.set(Calendar.YEAR, 2015); c.set(Calendar.MONTH, 1); c.set(Calendar.DATE, 2); c.set(Calendar.HOUR, 11); c.set(Calendar.MINUTE, 30); // G242查询余票 BookRequestMsg requestMsg1 = new BookRequestMsg(); requestMsg1.setCode(Code.CODE_SEARCH); requestMsg1.setStartTime(c.getTime()); requestMsg1.setTrainNumber(&quot;G242&quot;);//设置查询车次 requestMsg1.setUser(user);//设置当前登陆用户 ctx.write(requestMsg1); // D1235查询余票 BookRequestMsg requestMsg2 = new BookRequestMsg(); requestMsg2.setCode(Code.CODE_SEARCH); requestMsg2.setStartTime(c.getTime()); requestMsg2.setTrainNumber(&quot;D1235&quot;);//设置查询车次 requestMsg2.setUser(user); ctx.write(requestMsg2); ctx.flush(); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { BookResponseMsg responseMsg = (BookResponseMsg) msg; switch (responseMsg.getCode()) { case Code.CODE_SEARCH://收到查询结果 System.out.println(&quot;==========火车【&quot;+responseMsg.getTrain().getNumber()+&quot;】余票查询结果:【&quot;+(responseMsg.getSuccess()?&quot;成功&quot;:&quot;失败&quot;)+&quot;】=========&quot;); System.out.println(responseMsg.getMsg()); //查询发现有余票的话 需要发送订票指令 if(responseMsg.getTrain().getTicketCounts()&gt;0){ //构造查询有余票的火车的订票指令 BookRequestMsg requestMsg = new BookRequestMsg(); requestMsg.setCode(Code.CODE_BOOK); requestMsg.setUser(user); requestMsg.setStartTime(responseMsg.getStartTime()); requestMsg.setTrainNumber(responseMsg.getTrain().getNumber()); ctx.writeAndFlush(requestMsg); }else{ System.out.println(&quot;火车【&quot;+responseMsg.getTrain().getNumber()+&quot;】没有余票，不能订票了！&quot;); } break; case Code.CODE_BOOK://收到订票结果 System.out.println(&quot;==========火车【&quot;+responseMsg.getTrain().getNumber()+&quot;】订票结果:【&quot;+(responseMsg.getSuccess()?&quot;成功&quot;:&quot;失败&quot;)+&quot;】=========&quot;); System.out.println(responseMsg.getMsg()); System.out.println(&quot;========车票详情========&quot;); Ticket ticket=responseMsg.getTicket(); System.out.println(&quot;车票票号：【&quot;+ticket.getNumber()+&quot;】&quot;); System.out.println(&quot;火车车次：【&quot;+ticket.getTrainNumber()+&quot;】&quot;); System.out.println(&quot;火车车厢：【&quot;+ticket.getCarriageNumber()+&quot;】&quot;); System.out.println(&quot;车厢座位：【&quot;+ticket.getSeatNumber()+&quot;】&quot;); System.out.println(&quot;预定时间：【&quot;+ticket.getBookTime()+&quot;】&quot;); System.out.println(&quot;出发时间：【&quot;+ticket.getStartTime()+&quot;】&quot;); System.out.println(&quot;乘客信息：【&quot;+ticket.getUser().getUserName()+&quot;】&quot;); break; default: System.out.println(&quot;==========操作错误结果=========&quot;); System.out.println(responseMsg.getMsg()); break; } } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 最后测试结果： 文章来源于： https://blog.csdn.net/albertfly/article/details/51527488","link":"/2019/04/03/Netty-%E4%BD%BF%E7%94%A8Netty%E4%BC%A0%E8%BE%93POJO%E5%AF%B9%E8%B1%A1/"},{"title":"SpringBoot中Shiro缓存使用Redis、Ehcache","text":"在SpringBoot中Shiro缓存使用Redis、Ehcache实现的两种方式实例SpringBoot 中配置redis作为session 缓存器。 让shiro引用 本文是建立在你是使用这shiro基础之上的补充内容 第一种：Redis缓存，将数据存储到redis 并且开启session存入redis中。引入pom12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 配置redisConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport { @Bean public KeyGenerator keyGenerator() { return new KeyGenerator() { @Override public Object generate(Object target, Method method, Object... params) { StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) { sb.append(obj.toString()); } return sb.toString(); } }; } @Bean //在这里配置缓存reids配置 public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) { RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofHours(1)); // 设置缓存有效期一小时 System.out.println(&quot;《========【开启redis】 ======== 》 &quot;); return RedisCacheManager .builder(RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory)) .cacheDefaults(redisCacheConfiguration).build(); } @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) { StringRedisTemplate template = new StringRedisTemplate(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; }} 配置自定义缓存管理器，引入redis缓存管理器 定义自己的CacheManager 123456789101112131415161718192021222324252627282930313233343536373839/** * &lt;p&gt; 自定义cacheManage 扩张shiro里面的缓存 使用reids作缓存 &lt;/p&gt; * &lt;description&gt; * 引入自己定义的CacheManager * 关于CacheManager的配置文件在spring-redis-cache.xml中 * &lt;/description&gt; */@Componentpublic class ShiroSpringCacheManager implements CacheManager ,Destroyable{ /** * 将之上的RedisCacheManager的Bean拿出来 注入于此 */ @Autowired private org.springframework.cache.CacheManager cacheManager; public org.springframework.cache.CacheManager getCacheManager() { return cacheManager; } public void setCacheManager(org.springframework.cache.CacheManager cacheManager) { this.cacheManager = cacheManager; } @Override public void destroy() throws Exception { cacheManager = null; } @Override public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String name) { if (name == null ){ return null; } // 新建一个ShiroSpringCache 将Bean放入并实例化 return new ShiroSpringCache&lt;K,V&gt;(name,getCacheManager()); }} 定义自己实现的Shiro的Cache,实现了Shiro包里的Cache 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * &lt;p&gt; 自定义缓存 将数据存入到redis中 &lt;/p&gt; */@SuppressWarnings(&quot;unchecked&quot;)public class ShiroSpringCache&lt;K,V&gt; implements org.apache.shiro.cache.Cache&lt;K, V&gt;{ private static final Logger log = LoggerFactory.getLogger(ShiroSpringCache.class); private CacheManager cacheManager; private Cache cache; public ShiroSpringCache(String name, CacheManager cacheManager) { if(name==null || cacheManager==null){ throw new IllegalArgumentException(&quot;cacheManager or CacheName cannot be null.&quot;); } this.cacheManager = cacheManager; //这里首先是从父类中获取这个cache,如果没有会创建一个redisCache,初始化这个redisCache的时候 //会设置它的过期时间如果没有配置过这个缓存的，那么默认的缓存时间是为0的，如果配置了，就会把配置的时间赋予给这个RedisCache //如果从缓存的过期时间为0，就表示这个RedisCache不存在了，这个redisCache实现了spring中的cache this.cache= cacheManager.getCache(name); } @Override public V get(K key) throws CacheException { log.info(&quot;从缓存中获取key为{}的缓存信息&quot;,key); if(key == null){ return null; } ValueWrapper valueWrapper = cache.get(key); if(valueWrapper==null){ return null; } return (V) valueWrapper.get(); } @Override public V put(K key, V value) throws CacheException { log.info(&quot;创建新的缓存，信息为：{}={}&quot;,key,value); cache.put(key, value); return get(key); } @Override public V remove(K key) throws CacheException { log.info(&quot;干掉key为{}的缓存&quot;,key); V v = get(key); cache.evict(key);//干掉这个名字为key的缓存 return v; } @Override public void clear() throws CacheException { log.info(&quot;清空所有的缓存&quot;); cache.clear(); } @Override public int size() { return cacheManager.getCacheNames().size(); } /** * 获取缓存中所的key值 */ @Override public Set&lt;K&gt; keys() { return (Set&lt;K&gt;) cacheManager.getCacheNames(); } /** * 获取缓存中所有的values值 */ @Override public Collection&lt;V&gt; values() { return (Collection&lt;V&gt;) cache.get(cacheManager.getCacheNames()).get(); } @Override public String toString() { return &quot;ShiroSpringCache [cache=&quot; + cache + &quot;]&quot;; }} 到此为止，使用redis做缓存，和spring的集成就完成了。 可以使用以下注解将缓存放入redis 1@Cacheable(value = Cache.CONSTANT, key = &quot;'&quot; + CacheKey.DICT_NAME + &quot;'+#name+'_'+#val&quot;) 配置spring session管理器12345@Bean@ConditionalOnProperty(prefix = &quot;xpro&quot;, name = &quot;spring-session-open&quot;, havingValue = &quot;true&quot;)public ServletContainerSessionManager servletContainerSessionManager() { return new ServletContainerSessionManager();} 新建类 spring session设置session过期时间 123456789101112/** * spring session配置 * * @author xingri * @date 2017-07-13 21:05 */@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 900) //session过期时间 如果部署多机环境,需要打开注释@ConditionalOnProperty(prefix = &quot;xpro&quot;, name = &quot;spring-session-open&quot;, havingValue = &quot;true&quot;)public class SpringSessionConfig {} 第一种：Ehcache做缓存，可以将数据存储到磁盘中，也可以存到内存中 新建ehcache.xml 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ehcache updateCheck=&quot;false&quot; dynamicConfig=&quot;false&quot;&gt; &lt;diskStore path=&quot;java.io.tmpdir&quot;/&gt; &lt;!--授权信息缓存--&gt; &lt;cache name=&quot;authorizationCache&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;1800&quot; timeToLiveSeconds=&quot;1800&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt;&lt;!--身份信息缓存--&gt; &lt;cache name=&quot;authenticationCache&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;1800&quot; timeToLiveSeconds=&quot;1800&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt;&lt;!--session缓存--&gt; &lt;cache name=&quot;activeSessionCache&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;1800&quot; timeToLiveSeconds=&quot;1800&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt; &lt;!-- 缓存半小时 --&gt; &lt;cache name=&quot;halfHour&quot; maxElementsInMemory=&quot;10000&quot; maxElementsOnDisk=&quot;100000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;1800&quot; timeToLiveSeconds=&quot;1800&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; /&gt; &lt;!-- 缓存一小时 --&gt; &lt;cache name=&quot;hour&quot; maxElementsInMemory=&quot;10000&quot; maxElementsOnDisk=&quot;100000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;3600&quot; timeToLiveSeconds=&quot;3600&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; /&gt; &lt;!-- 缓存一天 --&gt; &lt;cache name=&quot;oneDay&quot; maxElementsInMemory=&quot;10000&quot; maxElementsOnDisk=&quot;100000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;86400&quot; timeToLiveSeconds=&quot;86400&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; /&gt; &lt;!-- name:缓存名称。 maxElementsInMemory：缓存最大个数。 eternal:对象是否永久有效，一但设置了，timeout将不起作用。 timeToIdleSeconds：设置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。 timeToLiveSeconds：设置对象在失效前允许存活时间（单位：秒）。最大时间介于创建时间和失效时间之间。仅当eternal=false对象不是永久有效时使用，默认是0.，也就是对象存活时间无穷大。 overflowToDisk：当内存中对象数量达到maxElementsInMemory时，Ehcache将会对象写到磁盘中。 diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。 maxElementsOnDisk：硬盘最大缓存个数。 diskPersistent：是否缓存虚拟机重启期数据 Whether the disk store persists between restarts of the Virtual Machine. The default value is false. diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。 clearOnFlush：内存数量最大时是否清除。 --&gt; &lt;defaultCache name=&quot;defaultCache&quot; maxElementsInMemory=&quot;10000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;600&quot; timeToLiveSeconds=&quot;600&quot; overflowToDisk=&quot;false&quot; maxElementsOnDisk=&quot;100000&quot; diskPersistent=&quot;false&quot; diskExpiryThreadIntervalSeconds=&quot;120&quot; memoryStoreEvictionPolicy=&quot;LRU&quot;/&gt;&lt;/ehcache&gt; 配置自定义缓存管理器，引入ehcache缓存管理器1234567891011121314151617181920212223242526272829303132333435363738/** * ehcache配置 * */@Configuration@EnableCachingpublic class EhCacheConfig { /** * EhCache的配置 */ @Bean public EhCacheCacheManager cacheManager(CacheManager cacheManager) { MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer(); ManagementService.registerMBeans(cacheManager, mBeanServer, true, true, true, true); return new EhCacheCacheManager(cacheManager); } /** * EhCache的配置 */ @Bean public EhCacheManagerFactoryBean ehcache() { System.out.println(&quot;《========【开启ehcache】 ======== 》 &quot;); EhCacheManagerFactoryBean ehCacheManagerFactoryBean = new EhCacheManagerFactoryBean(); ehCacheManagerFactoryBean.setConfigLocation(new ClassPathResource(&quot;ehcache.xml&quot;)); return ehCacheManagerFactoryBean; } @Bean public org.apache.shiro.cache.CacheManager getCacheShiroManager(EhCacheManagerFactoryBean ehcache) { EhCacheManager ehCacheManager = new EhCacheManager(); ehCacheManager.setCacheManager(ehcache.getObject()); return ehCacheManager; }} 最后 最重要的是引入shriro 中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155/** * shiro权限管理的配置 * */@Configurationpublic class ShiroConfig { /** * 安全管理器 */ @Bean public DefaultWebSecurityManager securityManager(CookieRememberMeManager rememberMeManager, CacheManager cacheShiroManager, SessionManager sessionManager) { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setAuthenticator(modularRealmAuthenticator()); List&lt;Realm&gt; realms=new ArrayList&lt;&gt;(); securityManager.setRealms(realms); securityManager.setCacheManager(cacheShiroManager); securityManager.setRememberMeManager(rememberMeManager); securityManager.setSessionManager(sessionManager); return securityManager; } /** * spring session管理器（多机环境） */ @Bean public ServletContainerSessionManager servletContainerSessionManager() { return new ServletContainerSessionManager(); } /** * session管理器(单机环境) 使用cookie存储缓存。。如果多级请注释 */ @Bean public DefaultWebSessionManager defaultWebSessionManager(CacheManager cacheShiroManager, XProProperties xProProperties) { DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); sessionManager.setCacheManager(cacheShiroManager); sessionManager.setSessionValidationInterval(xProProperties.getSessionValidationInterval() * 1000); sessionManager.setGlobalSessionTimeout(xProProperties.getSessionInvalidateTime() * 1000); sessionManager.setDeleteInvalidSessions(true); sessionManager.setSessionValidationSchedulerEnabled(true); Cookie cookie = new SimpleCookie(ShiroHttpSession.DEFAULT_SESSION_ID_NAME); cookie.setName(&quot;shiroCookie&quot;); cookie.setHttpOnly(true); sessionManager.setSessionIdCookie(cookie); return sessionManager; } /** * 缓存管理器 使用Ehcache实现 如果使用redis则注释下面内容！！！！ */ @Bean public CacheManager getCacheShiroManager(EhCacheManagerFactoryBean ehcache) { EhCacheManager ehCacheManager = new EhCacheManager(); ehCacheManager.setCacheManager(ehcache.getObject()); return ehCacheManager; } /** * 项目自定义的Realm */ @Bean public ShiroDbRealm shiroDbRealm() { return new ShiroDbRealm(); } @Bean public ShiroTockenRealm shiroTockenRealm( ) { return new ShiroTockenRealm(); } @Bean public ShiroJwtRealm shiroJwtRealm( ) { return new ShiroJwtRealm(); } /** * 系统自带的Realm管理，主要针对多realm * */ @Bean public ModularRealmAuthenticator modularRealmAuthenticator(){ ModularRealmAuthenticator modularRealmAuthenticator=new ModularRealmAuthenticator(); modularRealmAuthenticator.setAuthenticationStrategy(new AtLeastOneSuccessfulStrategy()); return modularRealmAuthenticator; } /** * rememberMe管理器, cipherKey生成见{@code Base64Test.java} */ @Bean public CookieRememberMeManager rememberMeManager(SimpleCookie rememberMeCookie) { CookieRememberMeManager manager = new CookieRememberMeManager(); manager.setCipherKey(Base64.decode(&quot;Z3VucwAAAAAAAAAAAAAAAA==&quot;)); manager.setCookie(rememberMeCookie); return manager; } /** * 记住密码Cookie */ @Bean public SimpleCookie rememberMeCookie() { SimpleCookie simpleCookie = new SimpleCookie(&quot;rememberMe&quot;); simpleCookie.setHttpOnly(true); simpleCookie.setMaxAge(7 * 24 * 60 * 60);//7天 return simpleCookie; } /** * 在方法中 注入 securityManager,进行代理控制 */ @Bean public MethodInvokingFactoryBean methodInvokingFactoryBean(DefaultWebSecurityManager securityManager) { MethodInvokingFactoryBean bean = new MethodInvokingFactoryBean(); bean.setStaticMethod(&quot;org.apache.shiro.SecurityUtils.setSecurityManager&quot;); bean.setArguments(new Object[]{securityManager}); return bean; } /** * 保证实现了Shiro内部lifecycle函数的bean执行 */ @Bean public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() { return new LifecycleBeanPostProcessor(); } /** * 启用shrio授权注解拦截方式，AOP式方法级权限检查 */ @Bean @DependsOn(value = &quot;lifecycleBeanPostProcessor&quot;) //依赖其他bean的初始化 public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() { return new DefaultAdvisorAutoProxyCreator(); } @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(DefaultWebSecurityManager securityManager) { AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; }}","link":"/2019/08/15/SpringBoot%E4%B8%ADShiro%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8Redis%E3%80%81Ehcache/"},{"title":"Spring中重要的注解","text":"现在大部分的Spring项目都会用到注解。使用注解来替换xml，一行简单的注解就可以解决很多事情。但是你真的懂其中的原理吗。 本文翻译于 https://docs.spring.io/spring-framework/docs and https://docs.spring.io/spring-framework/docs 在面试的时候 多少会问道 你了解过Spring注解吗。 先来谈谈@Configuration定义：指示一个类声明一个或者多个@Bean 声明的方法并且由Spring容器统一管理，以便在运行时为这些bean生成bean的定义和服务请求的类。 例如：12345678910@Configurationpublic class AppConfig { @Bean public MyBean myBean(){ return new MyBean(); }} 上述AppConfig 加入@Configuration 注解，表明这就是一个配置类。有一个myBean()的方法，返回一个MyBean()的实例，并用@Bean 进行注释，表明这个方法是需要被Spring进行管理的bean。@Bean 如果不指定名称的话，默认使用myBean名称，也就是小写的名称。 通过注解启动： 通过启动一个AnnotationConfigApplicationContext 来引导这个@Configuration 注解的类，比如： 123AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();ctx.register(AppConfig.class);ctx.refresh(); 在web项目中，也可以使用AnnotationContextWebApplicationContext或者其他变体来启动。 **使用SpringBoot项目的例子如下： ** pom.xml 文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.spring.configuration&lt;/groupId&gt; &lt;artifactId&gt;spring-configuration&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-configuration&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 在config 包下新建一个MyConfiguration环境配置，和上面的示例代码相似，完整的代码如下： 123456789@Configurationpublic class MyConfiguration { @Bean public MyBean myBean(){ System.out.println(&quot;myBean Initialized&quot;); return new MyBean(); }} 说明MyConfiguration 是一个配置类，能够在此类下面声明管理多个Bean，我们声明了一个MyBean的bean，希望它被容器加载和管理。 新建一个 MyBean的类，具体代码如下 1234567891011public class MyBean { public MyBean(){ System.out.println(&quot;generate MyBean Instance&quot;); } public void init(){ System.out.println(&quot;MyBean Resources Initialized&quot;); }} 新建一个SpringConfigurationApplication类，用来测试MyConfiguration类，具体代码如下： 1234567891011121314public class SpringConfigurationApplication { public static void main(String[] args) { // AnnotationConfigApplicationContext context = = new AnnotationConfigApplicationContext(MyConfiguration.class) // 因为我们加载的@Configuration 是基于注解形式的，所以需要创建AnnotationConfigApplicationContext AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); // 注册MyConfiguration 类并刷新bean 容器。 context.register(MyConfiguration.class); context.refresh(); }} 输出：myBean Initialized generate MyBean Instance 从输出的结果可以看到，默认名称为myBean 的bean随着容器的加载而加载，因为myBean方法返回一个myBean的构造方法，所以myBean被初始化了。 通过XML 的方式来启动例子如下 通过XML 的方式来启动 可以通过使用XML方式定义的&lt;context:annotation-config /&gt;开启基于注解的启动，然后再定义一个MyConfiguration的bean，在/resources 目录下新建 application-context.xml 代码如下 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd&quot;&gt; &lt;!-- 相当于基于注解的启动类 AnnotationConfigApplicationContext--&gt; &lt;context:annotation-config /&gt; &lt;bean class=&quot;com.spring.configuration.config.MyConfiguration&quot;/&gt;&lt;/beans&gt; 需要引入applicationContext.xml ，在SpringConfigurationApplication 需要进行引入，修改后的SpringConfigurationApplication如下： 12345678public class SpringConfigurationApplication { public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); }} 输出：myBean Initialized generate MyBean Instance 再谈谈ComponentScan （扫包范围）@Configuration 使用@Component 进行原注解，因此@Configuration 类也可以被组件扫描到（特别是使用XML context:component-scan 元素）。 在这里认识几个注解: @Controller,** @Service**,** @Repository**, @Component @Controller: 表明一个注解的类是一个”Controller”，也就是控制器，可以把它理解为MVC 模式的Controller 这个角色。这个注解是一个特殊的@Component，允许实现类通过类路径的扫描扫描到。它通常与@RequestMapping 注解一起使用。 @Service: 表明这个带注解的类是一个”Service”，也就是服务层，可以把它理解为MVC 模式中的Service层这个角色，这个注解也是一个特殊的@Component，允许实现类通过类路径的扫描扫描到 @Repository: 表明这个注解的类是一个”Repository”,团队实现了JavaEE 模式中像是作为”Data Access Object” 可能作为DAO来使用，当与 PersistenceExceptionTranslationPostProcessor 结合使用时，这样注释的类有资格获得Spring转换的目的。这个注解也是@Component 的一个特殊实现，允许实现类能够被自动扫描到 @Component: 表明这个注释的类是一个组件，当使用基于注释的配置和类路径扫描时，这些类被视为自动检测的候选者。 也就是说，上面四个注解标记的类都能够通过@ComponentScan 扫描到，上面四个注解最大的区别就是使用的场景和语义不一样. 比如你定义一个Service类想要被Spring进行管理，你应该把它定义为@Service 而不是@Controller因为我们从语义上讲，@Service更像是一个服务的类，而不是一个控制器的类，@Component通常被称作组件，它可以标注任何你没有严格予以说明的类，比如说是一个配置类，它不属于MVC模式的任何一层，这个时候你更习惯于把它定义为 @Component。@Controller，@Service，@Repository 的注解上都有@Component，所以这三个注解都可以用@Component进行替换。 来看一下代码进行理解： 定义五个类，类上分别用@Controller, @Service, @Repository, @Component, @Configuration 进行标注，分别如下 123456789101112131415@Componentpublic class UserBean {}@Configurationpublic class UserConfiguration {}@Controllerpublic class UserController {}@Repositorypublic class UserDao {}@Servicepublic class UserService {} 在MyConfiguration上加上@ComponentScan 注解，扫描上面5个类所在的包位置。代码如下： 12345678910@Configuration@ComponentScan(basePackages = &quot;com.spring.configuration.pojo&quot;)public class MyConfiguration { @Bean public MyBean myBean(){ System.out.println(&quot;myBean Initialized&quot;); return new MyBean(); }} 修改 SpringConfigurationApplication 中的代码，如下： 1234567891011121314151617181920public class SpringConfigurationApplication { public static void main(String[] args) {// AnnotationConfigApplicationContext context = = new AnnotationConfigApplicationContext(MyConfiguration.class)// ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(MyConfiguration.class); context.refresh(); // 获取启动过程中的bean 定义的名称 for(String str : context.getBeanDefinitionNames()){ System.out.println(&quot;str = &quot; + str); } context.close(); }} 输出： myBean Initializedgenerate MyBean Instancestr = org.springframework.context.annotation.internalConfigurationAnnotationProcessorstr = org.springframework.context.annotation.internalAutowiredAnnotationProcessorstr = org.springframework.context.annotation.internalRequiredAnnotationProcessorstr = org.springframework.context.annotation.internalCommonAnnotationProcessorstr = org.springframework.context.event.internalEventListenerProcessorstr = org.springframework.context.event.internalEventListenerFactorystr = myConfigurationstr = userBeanstr = userConfigurationstr = userControllerstr = userDaostr = userServicestr = myBean 由输出可以清楚的看到，上述定义的五个类成功被@ComponentScan 扫描到，并在程序启动的时候进行加载。 @Configuration 和 Environment@Configuration 通常和Environment 一起使用，通过@Environment 解析的属性驻留在一个或多个”属性源”对象中，@Configuration类可以使用@PropertySource，像Environment 对象提供属性源 为了便于测试，我们引入junit4和spring-test 的依赖，完整的配置文件如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.spring.configuration&lt;/groupId&gt; &lt;artifactId&gt;spring-configuration&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-configuration&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring.version&gt;5.0.6.RELEASE&lt;/spring.version&gt; &lt;spring.test.version&gt;4.3.13.RELEASE&lt;/spring.test.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.test.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 在config 包下定义一个 EnvironmentConfig 类，注入Environment 属性，完整代码如下： 1234567891011121314151617181920@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = EnvironmentConfig.class)@Configuration@PropertySource(&quot;classpath:beanName.properties&quot;)public class EnvironmentConfig { @Autowired Environment env; @Test public void testReadProperty(){ // 获取bean.name.controller 的属性 System.out.println(env.getProperty(&quot;bean.name.controller&quot;)); // 判断是否包含bean.name.component System.out.println(env.containsProperty(&quot;bean.name.component&quot;)); // 返回与给定键关联的属性值 System.out.println(env.getRequiredProperty(&quot;bean.name.service&quot;)); }} 在/resources 目录下新建beanName.properties 文件，如下： 123456bean.name.configuration=beanNameConfigurationbean.name.controller=beanNameControllerbean.name.service=beanNameServicebean.name.component=beanNameComponentbean.name.repository=beanNameRepository 启动并进行Junit测试，输出如下： beanNameControllertruebeanNameService @Autowired 、 @Inject、@Resource 的区别@Inject: 这是jsr330 的规范，通过AutowiredAnnotationBeanPostProcessor 类实现的依赖注入。位于javax.inject包内，是Java自带的注解。 如下是@Inject的使用，不加@Named注解，需要配置与变量名一致即可。 123@Inject@Named(&quot;mongo&quot;)private Mongo mongo; @Autowired: @Autowired是Spring提供的注解，通过AutowiredAnnotationBeanPostProcessor类实现的依赖注入，与@inject二者具有可互换性。位于org.springframework.beans.factory.annotation 包内，是Spring 中的注解 @Autowired默认是按照byType进行注入的，但是当byType方式找到了多个符合的bean，又是怎么处理的？Autowired默认先按byType，如果发现找到多个bean，则又按照byName方式比对，如果还有多个，则报出异常。 12345678910public class TestServiceImpl {// 下面两种@Autowired只要使用一种即可@Autowiredprivate UserDao userDao; // 用于字段上 @Autowiredpublic void setUserDao(UserDao userDao) { // 用于属性的方法上this.userDao = userDao;}} @Autowired 注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。如下： 12345public class TestServiceImpl {@Autowired@Qualifier(&quot;userDao&quot;)private UserDao userDao;} @Resource: @Resource 是jsr250规范的实现，@Resource通过CommonAnnotationBeanPostProcessor 类实现注入。@Resource 一般会指定一个name属性，如下： @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 12345678910public class TestServiceImpl {// 下面两种@Resource只要使用一种即可@Resource(name=&quot;userDao&quot;)private UserDao userDao; // 用于字段上 @Resource(name=&quot;userDao&quot;)public void setUserDao(UserDao userDao) { // 用于属性的setter方法上this.userDao = userDao;}} 注： @Autowired和@Inject基本是一样的，因为两者都是使用AutowiredAnnotationBeanPostProcessor来处理依赖注入。但是@Resource是个例外，它使用的是CommonAnnotationBeanPostProcessor来处理依赖注入。当然，两者都是BeanPostProcessor。 @Autowired和@Inject默认autowired by type，可以通过@Qualifier显式指定autowired by qualifier name。 @Resource默认autowired by field name，如果autowired by field name失败，会退化为autowired by type，可以通过@Qualifier显式指定autowired by qualifier name，如果autowired by qualifier name失败，会退化为autowired by field name。但是这时候如果autowired by field name失败，就不会再退化为autowired by type。 @Value、@PropertySource 和 @Configuration@Configuration 可以和@Value 和@PropertySource 一起使用读取外部配置文件，具体用法如下： 在config 包下新建一个ReadValueFromPropertySource类，代码如下 12345678910111213@PropertySource(&quot;classpath:beanName.properties&quot;)@Configurationpublic class ReadValueFromPropertySource { @Value(&quot;bean.name.component&quot;) String beanName; @Bean(&quot;myTestBean&quot;) public MyBean myBean(){ return new MyBean(beanName); }} 通过@PropertySource引入的配置文件，使@Value 能够获取到属性值，在给myBean()方法指定了一个名称叫做myTestBean。 修改MyBean类，增加一个name属性和一个构造器，再生成其toString() 方法 1234567891011121314151617181920212223public class MyBean { String name; public MyBean(String name) { this.name = name; } public MyBean(){ System.out.println(&quot;generate MyBean Instance&quot;); } public void init(){ System.out.println(&quot;MyBean Resources Initialized&quot;); } @Override public String toString() { return &quot;MyBean{&quot; + &quot;name='&quot; + name + '\\'' + '}'; }} 通过@PropertySource引入的配置文件，使@Value 能够获取到属性值，在给myBean()方法指定了一个名称叫做myTestBean 修改MyBean类，增加一个name属性和一个构造器，再生成其toString() 方法 1234567891011121314151617181920212223public class MyBean { String name; public MyBean(String name) { this.name = name; } public MyBean(){ System.out.println(&quot;generate MyBean Instance&quot;); } public void init(){ System.out.println(&quot;MyBean Resources Initialized&quot;); } @Override public String toString() { return &quot;MyBean{&quot; + &quot;name='&quot; + name + '\\'' + '}'; }} 在SpringConfigurationApplication中进行测试，如下 12345678910111213141516171819202122232425public class SpringConfigurationApplication { public static void main(String[] args) { // 为了展示配置文件的完整性，之前的代码没有删除。// AnnotationConfigApplicationContext context = = new AnnotationConfigApplicationContext(MyConfiguration.class)// ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);// AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();// context.register(MyConfiguration.class);// context.refresh();//// // 获取启动过程中的bean 定义的名称// for(String str : context.getBeanDefinitionNames()){// System.out.println(&quot;str = &quot; + str);// }// context.close(); ApplicationContext context = new AnnotationConfigApplicationContext(ReadValueFromPropertySource.class); MyBean myBean = (MyBean) context.getBean(&quot;myTestBean&quot;); System.out.println(&quot;myBean = &quot; + myBean); }} 使用Applicatio@InConntext 就能够获取myTestBean 这个bean，再生成myBean的实例。 输出：myBean = MyBean{name=’bean.name.component’} @Import 和 @Configuration@Import的定义(来自于JavaDoc)：表明一个或者多个配置类需要导入，提供与Spring XML中相等的功能，允许导入@Configuration 、@ImportSelector、@ImportBeanDefinitionRegistar的实现，以及常规组件类似于AnnotationConfigApplicationContext。可能用于类级别或者是原注解。如果XML或者其他非@Configuration标记的Bean资源需要被导入的话，使用@ImportResource。下面是一个示例代码： 在pojo 包下新建两个配置类，分别是CustomerBo, SchedualBo 12345678910111213141516171819202122232425@Configurationpublic class CustomerBo { public void printMsg(String msg){ System.out.println(&quot;CustomerBo : &quot; + msg); } @Bean public CustomerBo testCustomerBo(){ return new CustomerBo(); }}@Configurationpublic class SchedulerBo { public void printMsg(String msg){ System.out.println(&quot;SchedulerBo : &quot; + msg); } @Bean public SchedulerBo testSchedulerBo(){ return new SchedulerBo(); }} 在config 包下新建一个AppConfig，导入CustomerBo 和 SchedulerBo 。 123@Configuration@Import(value = {CustomerBo.class,SchedulerBo.class})public class AppConfig {} 在config 包下新建一个ImportWithConfiguration ，用于测试@Import 和 @Configuration 的使用 1234567891011public class ImportWithConfiguration { public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); CustomerBo customerBo = (CustomerBo) context.getBean(&quot;testCustomerBo&quot;); customerBo.printMsg(&quot;System out println('get from customerBo')&quot;); SchedulerBo schedulerBo = (SchedulerBo) context.getBean(&quot;testSchedulerBo&quot;); schedulerBo.printMsg(&quot;System out println('get from schedulerBo')&quot;); }} 输出 : CustomerBo : System out println(‘get from customerBo’) SchedulerBo : System out println(‘get from schedulerBo’) @Profile @Profile: 表示当一个或多个@Value 指定的配置文件处于可用状态时，组件符合注册条件，可以进行注册。 ** 三种设置方式：** 可以通过ConfigurableEnvironment.setActiveProfiles()以编程的方式激活 可以通过AbstractEnvironment.ACTIVE_PROFILES_PROPERTY_NAME (spring.profiles.active )属性设置为JVM属性 作为环境变量，或作为web.xml 应用程序的Servlet 上下文参数。也可以通过@ActiveProfiles 注解在集成测试中以声明方式激活配置文件。 ** 作用域** 作为类级别的注释在任意类或者直接与@Component 进行关联，包括@Configuration 类 作为原注解，可以自定义注解 作为方法的注解作用在任何方法 注意: 如果一个配置类使用了Profile 标签或者@Profile 作用在任何类中都必须进行启用才会生效，如果@Profile({“p1”,”!p2”}) 标识两个属性，那么p1 是启用状态 而p2 是非启用状态的。 @ImportResource 和 @Configuration@ImportResource: 这个注解提供了与@Import 功能相似作用，通常与@Configuration 一起使用，通过AnnotationConfigApplicationContext 进行启动，下面以一个示例来看一下具体用法： 在config下新建TestService 类，声明一个构造函数，类初始化时调用 123456public class TestService { public TestService(){ System.out.println(&quot;test @importResource success&quot;); }} 在/resources 目录下新建 importResources.xml ，为了导入TestService 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd&quot;&gt; &lt;bean id = &quot;testService&quot; class=&quot;com.spring.configuration.config.TestService&quot; /&gt;&lt;/beans&gt; 然后在config 下新建一个ImportResourceWithConfiguration， 用于读取配置文件 123456789101112131415161718@Configuration@ImportResource(&quot;classpath:importResources.xml&quot;)public class ImportResourceWithConfiguration { @Autowired private TestService service; public void getImportResource(){ new TestService(); } public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ImportResourceWithConfiguration.class); context.getBean(&quot;testService&quot;); }} 输出：test @importResource success @Configuration 嵌套 @Configuration注解作用在类上，就和普通类一样能够进行相互嵌套，定义内部类 1234567891011121314151617181920// 来自JavaDoc@Configurationpublic class AppConfig{ @Inject DataSource dataSource; @Bean public MyBean myBean(){ return new MyBean(dataSource); } @Configuration static class DataConfig(){ @Bean DataSource dataSource(){ return new EmbeddedDatabaseBuilder().build() } }} 在上述代码中，只需要在应用程序的上下文中注册 AppConfig 。由于是嵌套的@Configuration 类，DatabaseConfig 将自动注册。当AppConfig 、DatabaseConfig 之间的关系已经隐含清楚时，这就避免了使用@Import 注解的需要。 @Lazy 延迟初始化@Lazy : 表明一个bean 是否延迟加载，可以作用在方法上，表示这个方法被延迟加载；可以作用在@Component (或者由@Component 作为原注解) 注释的类上，表明这个类中所有的bean 都被延迟加载。如果没有@Lazy注释，或者@Lazy 被设置为false，那么该bean 就会急切渴望被加载；除了上面两种作用域，@Lazy 还可以作用在@Autowired和@Inject注释的属性上，在这种情况下，它将为该字段创建一个惰性代理，作为使用ObjectFactory或Provider的默认方法。下面来演示一下： 修改MyConfiguration类，在该类上添加@Lazy 注解，新增一个IfLazyInit()方法，检验是否被初始化。 1234567891011121314151617@Lazy@Configuration@ComponentScan(basePackages = &quot;com.spring.configuration.pojo&quot;)public class MyConfiguration { @Bean public MyBean myBean(){ System.out.println(&quot;myBean Initialized&quot;); return new MyBean(); } @Bean public MyBean IfLazyInit(){ System.out.println(&quot;initialized&quot;); return new MyBean(); }} 修改SpringConfigurationApplication 启动类，放开之前MyConfiguration 的启动类 123456789101112131415161718192021222324public class SpringConfigurationApplication { public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MyConfiguration.class);// ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);// AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();// context.register(MyConfiguration.class);// context.refresh();//// // 获取启动过程中的bean 定义的名称 for(String str : context.getBeanDefinitionNames()){ System.out.println(&quot;str = &quot; + str); }// context.close();// ApplicationContext context =// new AnnotationConfigApplicationContext(ReadValueFromPropertySource.class);// MyBean myBean = (MyBean) context.getBean(&quot;myTestBean&quot;);// System.out.println(&quot;myBean = &quot; + myBean); }} 输出你会发现没有关于bean的定义信息，但是当吧@Lazy 注释拿掉，你会发现输出了关于bean的初始化信息：myBean Initializedgenerate MyBean Instanceinitializedgenerate MyBean Instance @RunWith 和 @ContextConfigurationJunit4 测试类，用于注解在类上表示通过Junit4 进行测试，可以省略编写启动类代码，是ApplicationContext 等启动类的替换。一般用@RunWith 和 @Configuration 进行单元测试，这是软件开发过程中非常必要而且具有专业性的一部分，上面EnvironmentConfig 类证实了这一点： 12345678910111213141516171819202122@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = EnvironmentConfig.class)@Configuration@PropertySource(&quot;classpath:beanName.properties&quot;)public class EnvironmentConfig {// @Autowired// Environment env; @Inject Environment env; @Test public void testReadProperty(){ // 获取bean.name.controller 的属性 System.out.println(env.getProperty(&quot;bean.name.controller&quot;)); // 判断是否包含bean.name.component System.out.println(env.containsProperty(&quot;bean.name.component&quot;)); // 返回与给定键关联的属性值 System.out.println(env.getRequiredProperty(&quot;bean.name.service&quot;)); }} @Enable 启动Spring内置功能 详情查阅 @EnableAsync,@EnableScheduling,@EnableTransactionManagement,@EnableAspectJAutoProxy,@EnableWebMvc官方文档 ** @Configuration 使用约束** 必须以类的方式提供(即不是从工厂方法返回的实例) @Configuration 注解的类必须是非final的 配置类必须是非本地的（即可能不在方法中声明）,native 标注的方法 任何嵌套的@Configuration 都必须是static 的。 @Bean 方法可能不会反过来创建更多配置类","link":"/2019/03/13/Spring%E4%B8%AD%E9%87%8D%E8%A6%81%E7%9A%84%E6%B3%A8%E8%A7%A3/"},{"title":"java防止接口被篡改--接口签名(Signature）","text":"前言 在为第三方系统提供接口的时候，肯定要考虑接口数据的安全问题，比如数据是否被篡改，数据是否已经过时，数据是否可以重复提交等问题。其中我认为最终要的还是数据是否被篡改。在此分享一下我的关于接口签名的实践方案。 签名规则 1、线下分配appid和appsecret，针对不同的调用方分配不同的appid和appsecret 2、加入timestamp（时间戳），10分钟内数据有效 3、加入流水号nonce（防止重复提交），至少为10位。针对查询接口，流水号只用于日志落地，便于后期日志核查。 针对办理类接口需校验流水号在有效期内的唯一性，以避免重复请求。 4、加入signature，所有数据的签名信息。以上红色字段放在请求头中。 签名的生成 signature 字段生成规则如下。 数据部分 Path：按照path中的顺序将所有value进行拼接 Query：按照key字典序排序，将所有key=value进行拼接 Form：按照key字典序排序，将所有key=value进行拼接 Body： Json: 按照key字典序排序，将所有key=value进行拼接（例如{“a”:”a”,”c”:”c”,”b”:{“e”:”e”}} =&gt; a=ab=e=ec=c） String: 整个字符串作为一个拼接 如果存在多种数据形式，则按照path、query、form、body的顺序进行再拼接，得到所有数据的拼接值。 上述拼接的值记作 Y。 请求头部分 X=”appid=xxxnonce=xxxtimestamp=xxx” 生成签名 最终拼接值=XY 最后将最终拼接值按照如下方法进行加密得到签名。 signature=org.apache.commons.codec.digest.HmacUtils.hmacSha256Hex(app secret, 拼接的值); 签名算法实现指定哪些接口或者哪些实体需要进行签名1234567891011121314151617import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.METHOD;import static java.lang.annotation.ElementType.TYPE;import static java.lang.annotation.RetentionPolicy.RUNTIME;@Target({TYPE, METHOD})@Retention(RUNTIME)@Documentedpublic @interface Signature { String ORDER_SORT = &quot;ORDER_SORT&quot;;//按照order值排序 String ALPHA_SORT = &quot;ALPHA_SORT&quot;;//字典序排序 boolean resubmit() default true;//允许重复请求 String sort() default Signature.ALPHA_SORT;} 指定哪些字段需要进行签名1234567891011121314151617181920import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;@Target({FIELD})@Retention(RUNTIME)@Documentedpublic @interface SignatureField { //签名顺序 int order() default 0; //字段name自定义值 String customName() default &quot;&quot;; //字段value自定义值 String customValue() default &quot;&quot;;} 核心算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * 生成所有注有 SignatureField属性 key=value的 拼接 */public static String toSplice(Object object) { if (Objects.isNull(object)) { return StringUtils.EMPTY; } if (isAnnotated(object.getClass(), Signature.class)) { Signature sg = findAnnotation(object.getClass(), Signature.class); switch (sg.sort()) { case Signature.ALPHA_SORT: return alphaSignature(object); case Signature.ORDER_SORT: return orderSignature(object); default: return alphaSignature(object); } } return toString(object);}private static String alphaSignature(Object object) { StringBuilder result = new StringBuilder(); Map&lt;String, String&gt; map = new TreeMap&lt;&gt;(); for (Field field : getAllFields(object.getClass())) { if (field.isAnnotationPresent(SignatureField.class)) { field.setAccessible(true); try { if (isAnnotated(field.getType(), Signature.class)) { if (!Objects.isNull(field.get(object))) { map.put(field.getName(), toSplice(field.get(object))); } } else { SignatureField sgf = field.getAnnotation(SignatureField.class); if (StringUtils.isNotEmpty(sgf.customValue()) || !Objects.isNull(field.get(object))) { map.put(StringUtils.isNotBlank(sgf.customName()) ? sgf.customName() : field.getName() , StringUtils.isNotEmpty(sgf.customValue()) ? sgf.customValue() : toString(field.get(object))); } } } catch (Exception e) { LOGGER.error(&quot;签名拼接(alphaSignature)异常&quot;, e); } } } for (Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = map.entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;String, String&gt; entry = iterator.next(); result.append(entry.getKey()).append(&quot;=&quot;).append(entry.getValue()); if (iterator.hasNext()) { result.append(DELIMETER); } } return result.toString();}/** * 针对array, collection, simple property, map做处理 */private static String toString(Object object) { Class&lt;?&gt; type = object.getClass(); if (BeanUtils.isSimpleProperty(type)) { return object.toString(); } if (type.isArray()) { StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; Array.getLength(object); ++i) { sb.append(toSplice(Array.get(object, i))); } return sb.toString(); } if (ClassUtils.isAssignable(Collection.class, type)) { StringBuilder sb = new StringBuilder(); for (Iterator&lt;?&gt; iterator = ((Collection&lt;?&gt;) object).iterator(); iterator.hasNext(); ) { sb.append(toSplice(iterator.next())); if (iterator.hasNext()) { sb.append(DELIMETER); } } return sb.toString(); } if (ClassUtils.isAssignable(Map.class, type)) { StringBuilder sb = new StringBuilder(); for (Iterator&lt;? extends Map.Entry&lt;String, ?&gt;&gt; iterator = ((Map&lt;String, ?&gt;) object).entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;String, ?&gt; entry = iterator.next(); if (Objects.isNull(entry.getValue())) { continue; } sb.append(entry.getKey()).append(&quot;=&quot;).append(toSplice(entry.getValue())); if (iterator.hasNext()) { sb.append(DELIMETER); } } return sb.toString(); } return NOT_FOUND;} 签名的校验header中的参数如下 签名实体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import com.google.common.base.MoreObjects;import com.google.common.collect.Sets;import org.hibernate.validator.constraints.NotBlank;import java.util.Set;@ConfigurationProperties(prefix = &quot;wmhopenapi.validate&quot;, exceptionIfInvalid = false)@Signaturepublic class SignatureHeaders { public static final String SIGNATURE_HEADERS_PREFIX = &quot;wmhopenapi-validate&quot;; public static final Set&lt;String&gt; HEADER_NAME_SET = Sets.newHashSet(); private static final String HEADER_APPID = SIGNATURE_HEADERS_PREFIX + &quot;-appid&quot;; private static final String HEADER_TIMESTAMP = SIGNATURE_HEADERS_PREFIX + &quot;-timestamp&quot;; private static final String HEADER_NONCE = SIGNATURE_HEADERS_PREFIX + &quot;-nonce&quot;; private static final String HEADER_SIGNATURE = SIGNATURE_HEADERS_PREFIX + &quot;-signature&quot;; static { HEADER_NAME_SET.add(HEADER_APPID); HEADER_NAME_SET.add(HEADER_TIMESTAMP); HEADER_NAME_SET.add(HEADER_NONCE); HEADER_NAME_SET.add(HEADER_SIGNATURE); } /** * 线下分配的值 * 客户端和服务端各自保存appId对应的appSecret */ @NotBlank(message = &quot;Header中缺少&quot; + HEADER_APPID) @SignatureField private String appid; /** * 线下分配的值 * 客户端和服务端各自保存，与appId对应 */ @SignatureField private String appsecret; /** * 时间戳，单位: ms */ @NotBlank(message = &quot;Header中缺少&quot; + HEADER_TIMESTAMP) @SignatureField private String timestamp; /** * 流水号【防止重复提交】; (备注：针对查询接口，流水号只用于日志落地，便于后期日志核查； 针对办理类接口需校验流水号在有效期内的唯一性，以避免重复请求) */ @NotBlank(message = &quot;Header中缺少&quot; + HEADER_NONCE) @SignatureField private String nonce; /** * 签名 */ @NotBlank(message = &quot;Header中缺少&quot; + HEADER_SIGNATURE) private String signature; public String getAppid() { return appid; } public void setAppid(String appid) { this.appid = appid; } public String getAppsecret() { return appsecret; } public void setAppsecret(String appsecret) { this.appsecret = appsecret; } public String getTimestamp() { return timestamp; } public void setTimestamp(String timestamp) { this.timestamp = timestamp; } public String getNonce() { return nonce; } public void setNonce(String nonce) { this.nonce = nonce; } public String getSignature() { return signature; } public void setSignature(String signature) { this.signature = signature; } @Override public String toString() { return MoreObjects.toStringHelper(this) .add(&quot;appid&quot;, appid) .add(&quot;appsecret&quot;, appsecret) .add(&quot;timestamp&quot;, timestamp) .add(&quot;nonce&quot;, nonce) .add(&quot;signature&quot;, signature) .toString(); }} 根据request 中 header值生成SignatureHeaders实体12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private SignatureHeaders generateSignatureHeaders(Signature signature, HttpServletRequest request) throws Exception {//NOSONAR Map&lt;String, Object&gt; headerMap = Collections.list(request.getHeaderNames()) .stream() .filter(headerName -&gt; SignatureHeaders.HEADER_NAME_SET.contains(headerName)) .collect(Collectors.toMap(headerName -&gt; headerName.replaceAll(&quot;-&quot;, &quot;.&quot;), headerName -&gt; request.getHeader(headerName))); PropertySource propertySource = new MapPropertySource(&quot;signatureHeaders&quot;, headerMap); SignatureHeaders signatureHeaders = RelaxedConfigurationBinder.with(SignatureHeaders.class) .setPropertySources(propertySource) .doBind(); Optional&lt;String&gt; result = ValidatorUtils.validateResultProcess(signatureHeaders); if (result.isPresent()) { throw new ServiceException(&quot;WMH5000&quot;, result.get()); } //从配置中拿到appid对应的appsecret String appSecret = limitConstants.getSignatureLimit().get(signatureHeaders.getAppid()); if (StringUtils.isBlank(appSecret)) { LOGGER.error(&quot;未找到appId对应的appSecret, appId=&quot; + signatureHeaders.getAppid()); throw new ServiceException(&quot;WMH5002&quot;); } //其他合法性校验 Long now = System.currentTimeMillis(); Long requestTimestamp = Long.parseLong(signatureHeaders.getTimestamp()); if ((now - requestTimestamp) &gt; EXPIRE_TIME) { String errMsg = &quot;请求时间超过规定范围时间10分钟, signature=&quot; + signatureHeaders.getSignature(); LOGGER.error(errMsg); throw new ServiceException(&quot;WMH5000&quot;, errMsg); } String nonce = signatureHeaders.getNonce(); if (nonce.length() &lt; 10) { String errMsg = &quot;随机串nonce长度最少为10位, nonce=&quot; + nonce; LOGGER.error(errMsg); throw new ServiceException(&quot;WMH5000&quot;, errMsg); } if (!signature.resubmit()) { String existNonce = redisCacheService.getString(nonce); if (StringUtils.isBlank(existNonce)) { redisCacheService.setString(nonce, nonce); redisCacheService.expire(nonce, (int) TimeUnit.MILLISECONDS.toSeconds(RESUBMIT_DURATION)); } else { String errMsg = &quot;不允许重复请求, nonce=&quot; + nonce; LOGGER.error(errMsg); throw new ServiceException(&quot;WMH5000&quot;, errMsg); } } //设置appsecret signatureHeaders.setAppsecret(appSecret); return signatureHeaders;} 生成签名前需要几个步骤，如下。 （1）、appid是否合法 （2）、根据appid从配置中心中拿到appsecret （3）、请求是否已经过时，默认10分钟 （4）、随机串是否合法 （5）、是否允许重复请求 生成header信息参数拼接1String headersToSplice = SignatureUtils.toSplice(signatureHeaders); 生成header中的参数，mehtod中的参数的拼接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private List&lt;String&gt; generateAllSplice(Method method, Object[] args, String headersToSplice) { List&lt;String&gt; pathVariables = Lists.newArrayList(), requestParams = Lists.newArrayList(); String beanParams = StringUtils.EMPTY; for (int i = 0; i &lt; method.getParameterCount(); ++i) { MethodParameter mp = new MethodParameter(method, i); boolean findSignature = false; for (Annotation anno : mp.getParameterAnnotations()) { if (anno instanceof PathVariable) { if (!Objects.isNull(args[i])) { pathVariables.add(args[i].toString()); } findSignature = true; } else if (anno instanceof RequestParam) { RequestParam rp = (RequestParam) anno; String name = mp.getParameterName(); if (StringUtils.isNotBlank(rp.name())) { name = rp.name(); } if (!Objects.isNull(args[i])) { List&lt;String&gt; values = Lists.newArrayList(); if (args[i].getClass().isArray()) { //数组 for (int j = 0; j &lt; Array.getLength(args[i]); ++j) { values.add(Array.get(args[i], j).toString()); } } else if (ClassUtils.isAssignable(Collection.class, args[i].getClass())) { //集合 for (Object o : (Collection&lt;?&gt;) args[i]) { values.add(o.toString()); } } else { //单个值 values.add(args[i].toString()); } values.sort(Comparator.naturalOrder()); requestParams.add(name + &quot;=&quot; + StringUtils.join(values)); } findSignature = true; } else if (anno instanceof RequestBody || anno instanceof ModelAttribute) { beanParams = SignatureUtils.toSplice(args[i]); findSignature = true; } if (findSignature) { break; } } if (!findSignature) { LOGGER.info(String.format(&quot;签名未识别的注解, method=%s, parameter=%s, annotations=%s&quot;, method.getName(), mp.getParameterName(), StringUtils.join(mp.getMethodAnnotations()))); } } List&lt;String&gt; toSplices = Lists.newArrayList(); toSplices.add(headersToSplice); toSplices.addAll(pathVariables); requestParams.sort(Comparator.naturalOrder()); toSplices.addAll(requestParams); toSplices.add(beanParams); return toSplices;} 对最终的拼接结果重新生成签名信息1SignatureUtils.signature(allSplice.toArray(new String[]{}), signatureHeaders.getAppsecret()); 依赖第三方工具包12345678&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;&lt;/dependency&gt; 使用示例生成签名12345678910111213//初始化请求头信息SignatureHeaders signatureHeaders = new SignatureHeaders();signatureHeaders.setAppid(&quot;111&quot;);signatureHeaders.setAppsecret(&quot;222&quot;);signatureHeaders.setNonce(SignatureUtils.generateNonce());signatureHeaders.setTimestamp(String.valueOf(System.currentTimeMillis()));List&lt;String&gt; pathParams = new ArrayList&lt;&gt;();//初始化path中的数据pathParams.add(SignatureUtils.encode(&quot;18237172801&quot;, signatureHeaders.getAppsecret()));//调用签名工具生成签名signatureHeaders.setSignature(SignatureUtils.signature(signatureHeaders, pathParams, null, null));System.out.println(&quot;签名数据: &quot; + signatureHeaders);System.out.println(&quot;请求数据: &quot; + pathParams); 输出结果123拼接结果: appid=111^_^appsecret=222^_^nonce=c9e778ba668c8f6fedf35634eb493af6304d54392d990262d9e7c1960b475b67^_^timestamp=1538207443910^_^w8rAwcXDxcDKwsM=^_^签名数据: SignatureHeaders{appid=111, appsecret=222, timestamp=1538207443910, nonce=c9e778ba668c8f6fedf35634eb493af6304d54392d990262d9e7c1960b475b67, signature=0a7d0b5e802eb5e52ac0cfcd6311b0faba6e2503a9a8d1e2364b38617877574d}请求数据: [w8rAwcXDxcDKwsM=] 此文引自 https://www.cnblogs.com/hujunzheng/p/9725168.html","link":"/2019/05/14/java%E9%98%B2%E6%AD%A2%E6%8E%A5%E5%8F%A3%E8%A2%AB%E7%AF%A1%E6%94%B9-%E6%8E%A5%E5%8F%A3%E7%AD%BE%E5%90%8D-Signature%EF%BC%89/"},{"title":"什么是Servlet(原理，从访问到方法)","text":"Servlet简介Servlet是SUN公司提供的一门用于开发动态WEB资源的技术。SUN公司在其API中提供了一个Servlet接口，用户若想开发一个动态WEB资源(即开发一个Java程序向浏览器输出数据)，需要完成以下2个步骤： 编写一个Java类，实现Servlet接口； 把开发好的Java类部署到WEB服务器中。 那么我们不仅要问，写好的Servlet会在WEB应用中的什么位置上呢？位置如下如所示。 提示：按照一种约定俗成的称呼习惯，通常我们也把实现了Servlet接口的Java程序，称之为Servlet。 Servlet快速入门——使用Servlet向浏览器输出“Hello World”阅读Servlet API文档，文档地址是https://tomcat.apache.org/tomcat-8.5-doc/servletapi/index.html。文档里面有对Servlet接口的详细描述，如下。 借助有道翻译为： 定义了所有Servlet必须实现的方法。Servlet是运行在一个Web服务器里的一个小型Java程序。Servlets通常通过HTTP(超文本传输协议)接收并响&gt; 应来自Web客户端的请求。要实现这个接口，您可以编写一个继承了javax.servlet.GenericServlet的一般的Servlet，或者继承了javax.servlet.http.HttpServlet的HTTP Servlet。这个接口定义了方法来初始化一个Servlet，服务请求，并从服务器删除Servlet。这些被称为生命周期方法&gt; 并且按以下顺序依次调用： Servlet被构造，然后用init方法初始化； 任何来自客户机的请求在service方法中处理； Servlet从服务中移除，调用destroy方法销毁，然后垃圾收集和完成。 除了生命周期方法，该接口提供了getServletConfig方法(Servlet可以使用它来得到任何启动信息)和getServletInfo方法(它允许Servlet返回自身的基本信息，比如作者、版本和版权)。 这里面有一个专业术语——life-cycle methods，解释过来就是与生命周期相关的方法，即生命周期中的某个特定时刻必定会执行的方法。那么什么是对象的生命周期？什么又是与生命周期相关的方法呢？对象从创建到销毁经历的过程，称之为对象的生命周期。在对象生命周期过程中，在特定时刻肯定会执行一些特定的方法，这些方法称之为与生命周期相关的方法。例如，人从出生到死亡经历的过程，为人的一个生命周期，在人生命周期过程中，必定有一些与生命周期息息相关的方法，例如吃饭、上学、结婚等，这些方法在人生命周期过程中某个特定时刻必定会执行，所以这些方法是人生命周期相关的方法。但不是说对象中的所有方法都与生命周期相关，例如人自杀，这个方法不是在生命周期中必定会执行的。阅读完Servlet API，我们需要解决两个问题： 输出Hello Servlet的Java代码应该写在Servlet的哪个方法内？ 如何向浏览器输出数据？ 答案很明显： 输出Hello Servlet的Java代码应该写在Servlet的service方法中； 通过ServletResponse接口的实例中的getOutputStream方法获得输出流，向http响应对象中写入数据，服务器将http响应对象回送给浏览器，浏览器解析数据并显示。 下面我们正式编写一个入门级的Servlet。首先在Tomcat服务器webapps目录下新建一个Web应用，比如myWeb(Web应用所在目录)，在myWeb目录中新建一个WEB-INF目录，接着在WEB-INF目录下新建一个classes目录，在classes目录中新建一个Java应用程序——FirstServlet.java，代码如下： 12345678910111213package cn.liayun;import java.io.*;import javax.servlet.*;public class FirstServlet extends GenericServlet { public void service(ServletRequest req, ServletResponse res) throws ServletException, java.io.IOException { OutputStream out = res.getOutputStream(); out.write(&quot;Hello Servlet!!!&quot;.getBytes()); } } 着编译Java应用程序，如图： 所以，我们需要将Servlet所用Jar包加载到classpath路径下，如下图所示。 再在WEB-INF目录中新建一个web.xml文件，配置Servlet的访问对外路径。 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;FirstServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.liayun.FirstServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;FirstServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/FirstServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 最后启动Tomcat，通过Chrome浏览器进行访问。 Servlet的运行过程Servlet程序是由Web服务器调用的，Web服务器收到客户端的Servlet访问请求后： ①Web服务器首先检查是否已经装载并创建了该Servlet的实例对象。如果是，则直接执行第④步，否则，执行第②步； ②装载并创建该Servlet的一个实例对象； ③调用Servlet实例对象的init()方法； ④创建一个用于封装HTTP请求消息的HttpServletRequest对象和一个代表HTTP响应消息的HttpServletResponse对象，然后调用Servlet的service()方法并将请求和响应对象作为参数传递进去； ⑤Web应用程序被停止或重新启动之前，Servlet引擎将卸载Servlet，并在卸载之前调用Servlet的destroy()方法。 用动图来描述以上调用过程： 如果是用UML时序图来描述以上调用过程，则如下： 注意：上图并没画出destory()方法。destory()方法会在Web容器移除Servlet时执行，客户机第一次访问服务器时，服务器会创建Servlet实例对象，它就永远驻留在内存里面了，等待客户机第二次访问，这时有一个用户访问完Servlet之后，此Servlet对象并不会被摧毁，destory()方法也就不会被执行。 一道面试题：请说出Servlet的生命周期Servlet对象是用户第一次访问时创建，对象创建之后就驻留在内存里面了，响应后续的请求。Servlet对象一旦被创建，init()方法就会被执行，客户端的每次请求导致service()方法被执行，Servlet对象被摧毁时(Web服务器停止后或者Web应用从服务器里删除时)，destory()方法就会被执行。 在Eclipse中开发Servlet在Eclipse中新建一个Dynamic Web Project工程，Eclipse会自动创建下图所示目录结构： Servlet接口实现类对于Servlet接口，SUN公司定义了两个默认实现类，分别为GenericServlet和HttpServlet。HttpServlet指能够处理HTTP请求的Servlet，它在原有Servlet接口上添加了一些与HTTP协议相关的处理方法，它比Servlet接口的功能更为强大。因此开发人员在编写Servlet时，通常应继承这个类，而避免直接去实现Servlet接口。HttpServlet在实现Servlet接口时，覆写了service方法，该方法体内的代码会自动判断用户的请求方式，如为GET请求，则调用HttpServlet的doGet方法，如为Post请求，则调用doPost方法。因此，开发人员在编写Servlet时，通常只需要覆写doGet或doPost方法，而不要去覆写service方法(温馨提示：可阅读HttpServlet API文档)。 借助有道翻译为： 提供了一个抽象类派生子类来创建一个适合于一个网站的HTTP Servlet。HttpServlet的子类必须覆盖至少一个方法，通常是其中一个： doGet，如果Servlet支持HTTP GET请求 doPost，HTTP POST请求 doPut，HTTP PUT请求 doDelete，HTTP DELETE请求 初始化和销毁，管理Sevlet生命中被掌握的资源 getServletInfo，Servlet用来提供关于其自身信息 几乎没有理由覆盖service()方法。service()方法会处理标准HTTP请求，通过派遣他们每个HTTP请求类型的处理程序方法(上述doMethod方法)。同样，几乎没有理由覆盖doOptions和doTrace方法。 通过Eclipse创建和编写Servlet选中cn.liayun包，右键→New→Servlet，在Eclipse中创建和编写Servlet可参考下面一系列步骤： 这样，我们就通过Eclipse帮我们创建好一个名字为ServletSample的Servlet，创建好的ServletSample里面会有如下代码： 123456789101112131415161718192021222324252627282930313233package cn.liayun;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class ServletSample */@WebServlet(&quot;/ServletSample&quot;)public class ServletSample extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.getWriter().append(&quot;Served at: &quot;).append(request.getContextPath()); } /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub doGet(request, response); }} 这些代码都是Eclipse自动生成的，而web.xml文件中也多了&lt;servlet&gt;&lt;/servlet&gt;和&lt;servlet-mapping&gt;&lt;/servlet-mapping&gt;两对标签，这两对标签是配置ServletSample的，应如下所示： 12345678&lt;servlet&gt; &lt;servlet-name&gt;ServletSample&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.liayun.ServletSample&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletSample&lt;/servlet-name&gt; &lt;url-pattern&gt;/ServletSample&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 注意：照理说，web.xml文件中会多&lt;servlet&gt;&lt;/servlet&gt;和&lt;servlet-mapping&gt;&lt;/servlet-mapping&gt;这两对标签，但是我的就没有，而且使用的是注解@WebServlet(“/ServletSample”)，好像因为我使用的是Servlet3.1规范的缘故。最后我们就可以通过浏览器访问ServletSample这个Servlet了，访问的URL地址是http://localhost:8080/day05/ServletSample。 Servlet开发注意细节如果你的Eclipse中有一个动态web项目TomcatTest，当你使用Eclipse导入一个外部项目，恰好这个项目名就是TomcatTest，这时你为了避免重名，需要修改导入的项目名，比如修改为t_ TomcatTest，然后你将其部署到Tomcat服务器中的webapps目录中，该项目映射的虚拟目录名称仍然是TomcatTest，所以你需要修改其虚拟目录。步骤如下： Servlet访问URL映射配置由于客户端是通过URL地址访问Web服务器中的资源，所以Servlet程序若想被外界访问，必须把Servlet程序映射到一个URL地址上，这个工作在web.xml文件中使用&lt;servlet&gt;元素和&lt;servlet-mapping&gt;元素完成。&lt;servlet&gt;元素用于注册Servlet，它包含有两个主要的子元素：&lt;servlet-name&gt;和&lt;servlet-class&gt;，分别用于设置Servlet的注册名称和Servlet的完整类名。一个&lt;servlet-mapping&gt;元素用于映射一个已注册的Servlet的一个对外访问路径，它包含有两个子元素：&lt;servlet-name&gt;和&lt;url-pattern&gt;，分别用于指定Servlet的注册名称和Servlet的对外访问路径。例如： 12345678&lt;servlet&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.itcast.ServletDemo1&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/ServletDemo1&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 同一个Servlet可以被映射到多个URL上，即多个&lt;servlet-mapping&gt;元素的&lt;servlet-name&gt;子元素的设置值可以是同一个Servlet的注册名。例如： 12345678910111213141516&lt;servlet&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.itcast.ServletDemo1&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/ServletDemo1&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/aa&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/1.html&lt;/url-pattern&gt; &lt;!-- 伪静态，明显是一个动态Web资源，但将其映射成静态Web资源的名称 --&gt;&lt;/servlet-mapping&gt; 温馨提示：一个Web应用的web.xml文件内容一经修改，不需要重新发布，服务器会自动监测web.xml的改动，只要web.xml文件的内容修改，服务器就会自动加载。原因是在Tomcat服务器的conf/context.xml文件中，有如下关键代码： 根据Tomcat服务器文档可知，在conf/context.xml文件中，Context元素信息被所有的Web应用加载。即Context元素的配置信息会被所有Web应用程序所共享。所以所有的Web应用会监测web.xml的改动，只要web.xml文件的内容一旦修改，服务器就会自动重新加载。通过上面的配置，当我们想访问名称是ServletDemo1的Servlet时，可以使用如下的几个地址去访问： http://localhost:8080/day05/ServletDemo1； http://localhost:8080/day05/aa； http://localhost:8080/day05/1.html。 ServletDemo1被映射到了多个URL上。 Servlet访问URL使用*通配符映射在Servlet映射到的URL中也可以使用*通配符，但是只能有两种固定的格式：一种格式是“*.扩展名”，另一种格式是以正斜杠（/）开头并以“*”结尾。例如： 12345678910&lt;servlet-mapping&gt; &lt;servlet-name&gt;AnyName&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;AnyName&lt;/servlet-name&gt; &lt;url-pattern&gt;/action/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 对于如下的一些映射关系： Servlet1映射到/abc/*； Servlet2映射到/*； Servlet3映射到/abc； Servlet4映射到*.do。 有如下问题： 当请求URL为“/abc/a.html”，“/abc/*”和“/*”都匹配，哪个Servlet响应？——Servlet引擎将调用Servlet1； 当请求URL为“/abc”时，“/abc/*”、“/*”和“/abc”都匹配，哪个Servlet响应？——Servlet引擎将调用Servlet3； 当请求URL为“/abc/a.do”时，“/abc/*”、“/*”和“*.do”都匹配，哪个Servlet响应？——Servlet引擎将调用Servlet1； 当请求URL为“/a.do”时，“/*”和“*.do”都匹配，哪个Servlet响应？——Servlet引擎将调用Servlet2； 当请求URL为“/xxx/yyy/a.do”时，“/*”和“*.do”都匹配，哪个Servlet响应？——Servlet引擎将调用Servlet2。 *结论：匹配的原则就是”谁长得更像就找谁”，“*.do”——这种在前面的时候优先级最低。** Servlet与普通Java类的区别Servlet是一个供其他Java程序（Servlet引擎）调用的Java类，它不能独立运行，它的运行完全由Servlet引擎来控制和调度。针对客户端的多次Servlet请求，通常情况下，服务器只会创建一个Servlet实例对象，也就是说Servlet实例对象一旦创建，它就会驻留在内存中，为后续的其它请求服务，直至Web容器退出，Servlet实例对象才会销毁。验证如下： 新建一个Servlet——ServletDemo3，并覆盖init()和destroy()方法； 123456789101112131415161718192021222324252627282930313233package cn.liayun;import java.io.IOException;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class ServletDemo3 extends HttpServlet { private static final long serialVersionUID = 1L; @Override public void init(ServletConfig config) throws ServletException { super.init(config); System.out.println(&quot;init&quot;); } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.getOutputStream().write(&quot;haha&quot;.getBytes()); } protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); } @Override public void destroy() { System.out.println(&quot;destroy&quot;); }} 将项目部署到服务器中，启动服务器，发现没有输出init，说明启动服务器时，Servlet实例对象并没有被创建。此时，通过浏览器进行访问，会发现控制台输出init，如下： 此时再打开一个浏览器进行访问，仍然只会输出一个init，说明针对客户端的多次Servlet请求，通常情况下，服务器只会创建一个Servlet实例对象。 当Web服务器停止后或者Web应用从服务器里删除时，destroy()方法就会被执行； 在Web服务器停止前，Servlet实例对象就会被摧毁。 在Servlet的整个生命周期内，Servlet的init方法只被调用一次。而对一个Servlet的每次访问请求都导致Servlet引擎调用一次Servlet的service方法。对于每次访问请求，Servlet引擎都会创建一个新的HttpServletRequest请求对象和一个新的HttpServletResponse响应对象，然后将这两个对象作为参数传递给它调用的Servlet的service()方法，service方法再根据请求方式分别调用doXXX方法。如果在元素中配置了一个元素，那Web应用程序在启动时，就会装载并创建Servlet的实例对象、以及调用Servlet实例对象的init()方法。例如： 12345&lt;servlet&gt; &lt;servlet-name&gt;ServletDemo3&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.itcast.ServletDemo3&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; 此时在启动服务器的过程中，会在控制台看到： 温馨提示：&lt;load-on-startup&gt;元素配置的数必须为正整数，数字越小，Servlet越优先创建。它的用途：可为Web应用写一个InitServlet，这个Servlet配置为启动时装载，为整个Web应用创建必要的数据库表和数据。 缺省Servlet如果某个Servlet的映射路径仅仅为一个正斜杠（/），那么这个Servlet就成为当前Web应用程序的缺省Servlet。凡是在web.xml文件中找不到匹配的&lt;servlet-mapping&gt;元素的URL，它们的访问请求都将交给缺省Servlet处理，也就是说，缺省Servlet用于处理所有其他Servlet都不处理的访问请求。例如： 12345678910&lt;servlet&gt; &lt;servlet-name&gt;ServletDemo3&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.itcast.ServletDemo3&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;!-- 将ServletDemo3配置成缺省Servlet --&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ServletDemo3&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 当访问不存在的Servlet时，就使用配置的默认Servlet进行处理，如下图所示： 在&lt;Tomcat的安装目录&gt;\\conf\\web.xml文件中，注册了一个名称为org.apache.catalina.servlets.DefaultServlet的Servlet，并将这个Servlet设置为了缺省Servlet。 1234567891011121314151617181920&lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.DefaultServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;listings&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;!-- The mapping for the default servlet --&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 当访问Tomcat服务器中的某个静态HTML文件和图片时，实际上是在访问这个缺省Servlet(服务器中的html文件数据的读取由缺省Servlet完成)。 Servlet的线程安全问题当多个客户端并发访问同一个Servlet时，Web服务器会为每一个客户端的访问请求创建一个线程，并在这个线程上调用Servlet的service方法，因此service方法内如果访问了同一个资源的话，就有可能引发线程安全问题。下面我会举例来说明。 当Servlet不存在线程安全问题时下面是不存在线程安全问题的代码。 1234567891011121314151617181920212223242526package cn.liayun;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(&quot;/ServletSample&quot;)public class ServletSample extends HttpServlet { protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { int i = 0; i++; response.getOutputStream().write((i + &quot;&quot;).getBytes()); } protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); }} 当多线程并发访问这个方法里面的代码时，会存在线程安全问题吗？显然不会，i变量被多个线程并发访问，但是没有线程安全问题，因为i是doGet方法里面的局部变量，当有多个线程并发访问doGet方法时，每一个线程里面都有自己的i变量，各个线程操作的都是自己的i变量，所以不存在线程安全问题。多线程并发访问某一个方法的时候，如果在方法内部定义了一些资源(变量，集合等)，那么每一个线程都有这些东西，所以就不存在线程安全问题。 当Servlet存在线程安全问题时下面是存在线程安全问题的代码。 12345678910111213141516171819202122232425262728293031323334package cn.liayun;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(&quot;/ServletSample&quot;)public class ServletSample extends HttpServlet { private int i = 0; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { i++; try { Thread.sleep(1000 * 10); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } response.getOutputStream().write((i + &quot;&quot;).getBytes()); } protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); }} 把i定义成全局变量，当多个线程并发访问变量i时，就会存在线程安全问题了。线程安全问题只存在多个线程并发操作同一个资源的情况下，所以在编写Servlet的时候，如果并发访问某一个资源(变量，集合等)，就会存在线程安全问题，那么该如何解决这个问题呢？可使用同步代码块。 12345678910111213141516171819202122232425262728293031323334353637package cn.liayun;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(&quot;/ServletSample&quot;)public class ServletSample extends HttpServlet { private int i = 0;//共享资源 protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { i++; synchronized (this) { try { Thread.sleep(1000 * 10); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } response.getOutputStream().write((i + &quot;&quot;).getBytes()); } protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); }} 加了synchronized后，并发访问i时就不存在线程安全问题了，为什么加了synchronized后就没有线程安全问题了呢？原因：假如现在有一个线程访问Servlet对象，那么它就先拿到了Servlet对象的那把锁，等到它执行完之后才会把锁还给Servlet对象，由于是它先拿到了Servlet对象的那把锁，所以当有别的线程来访问这个Servlet对象时，由于锁已经被之前的线程拿走了，后面的线程只能排队等候了。以上这种做法是给Servlet对象加了一把锁，保证任何时候都只有一个线程在访问该Servlet对象里面的资源，这样就不存在线程安全问题了。这种做法虽然解决了线程安全问题，但是编写Servlet却万万不能用这种方式处理线程安全问题，假如有9999个人同时访问这个Servlet，那么这9999个人必须按先后顺序排队轮流访问。针对Servlet的线程安全问题，SUN公司是提供有解决方案的：让Servlet去实现一个SingleThreadModel接口，如果某个Servlet实现了SingleThreadModel接口，那么Servlet引擎将以单线程模式来调用其service方法。查看Sevlet的API可以看到，SingleThreadModel接口中没有定义任何方法和常量，在Java中，把没有定义任何方法和常量的接口称之为标记接口，经常看到的一个最典型的标记接口就是”Serializable”，这个接口也是没有定义任何方法和常量的，标记接口在Java中有什么用呢？主要作用就是给某个对象打上一个标志，告诉JVM，这个对象可以做什么，比如实现了”Serializable”接口的类的对象就可以被序列化，还有一个”Cloneable”接口，这个也是一个标记接口，在默认情况下，Java中的对象是不允许被克隆的，就像现实生活中的人一样，不允许克隆，但是只要实现了”Cloneable”接口，那么对象就可以被克隆了。SingleThreadModel接口中没有定义任何方法，只要在Servlet类的定义中增加实现SingleThreadModel接口的声明即可。对于实现了SingleThreadModel接口的Servlet，Servlet引擎仍然支持对该Servlet的多线程并发访问，其采用的方式是产生多个Servlet实例对象，并发的每个线程分别调用一个独立的Servlet实例对象。实现SingleThreadModel接口并不能真正解决Servlet的线程安全问题，因为Servlet引擎会创建多个Servlet实例对象，而真正意义上解决多线程安全问题是指一个Servlet实例对象被多个线程同时调用的问题。事实上，在Servlet API 2.4中，已经将SingleThreadModel标记为Deprecated（过时的）。 以上代码还要注意异常的处理，代码Thread.sleep(1000*4);只能try不能抛，因为子类在覆盖父类的方法时，不能抛出比父类更多的异常；并且catch之后，后台记录异常的同时并给用户一个友好提示，因为用户访问的是一个网页。","link":"/2019/04/17/%E4%BB%80%E4%B9%88%E6%98%AFServlet/"},{"title":"可能是把Java内存区域讲的最清楚的一篇文章","text":"写在前面(常见面试题)基本问题 介绍下 Java 内存区域（运行时数据区） Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么） 对象的访问定位的两种方式（句柄和直接指针两种方式） 拓展问题 String类和常量池 8种基本类型的包装类和常量池 一 概述对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像C/C++程序开发程序员这样为内一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。 二 运行时数据区域Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同，下面会介绍到。 JDK 1.8之前： JDK 1.8 ： 线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存(非运行时数据区的一部分) 2.1 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 从上面的介绍中我们知道程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 2.2 Java 虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。 Java 内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。） 局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。 Java 虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。 扩展：那么方法/函数如何调用？ Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入Java栈，每一个函数调用结束后，都会有一个栈帧被弹出。 Java方法有两种返回方式： return 语句。 抛出异常。 不管哪种返回方式都会导致栈帧被弹出。 2.3 本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。 2.4 堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 上图所示的 eden区、s0区、s1区都属于新生代，tentired 区属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden区-&gt;Survivor 区后对象的初始年龄变为1)，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 2.5 方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 方法区也被称为永久代。很多人都会分不清方法区和永久代的关系，为此我也查阅了文献。 方法区和永久代的关系 《Java虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像Java中接口和类的关系，类实现了接口，而永久代就是HotSpot虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是HotSpot的概念，方法区是Java虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久带这一说法。 常用参数JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小 12-XX:PermSize=N //方法区(永久代)初始大小-XX:MaxPermSize=N //方法区(永久代)最大大小,超过这个值将会抛出OutOfMemoryError异常:java.lang.OutOfMemoryError: PermGen 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。** JDK 1.8 的时候，方法区（HotSpot的永久代）被彻底移除了（JDK1.7就已经开始了），取而代之是元空间，元空间使用的是直接内存。 下面是一些常用参数： 12-XX:MetaspaceSize=N //设置Metaspace的初始（和最小大小）-XX:MaxMetaspaceSize=N //设置Metaspace的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。 为什么要将永久代(PermGen)替换为元空间(MetaSpace)呢?整个永久代有一个 JVM 本身设置固定大小上线，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到java.lang.OutOfMemoryError。你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。 当然这只是其中一个原因，还有很多底层的原因，这里就不提了。 2.6 运行时常量池运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用） 既然运行时常量池时方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 ——图片来源：https://blog.csdn.net/wangbiao007/article/details/78545189 2.7 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 三 HotSpot 虚拟机对象探秘通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。 3.1 对象的创建下图便是 Java 对象的创建过程，我建议最好是能默写出来，并且要掌握每一步在做什么。 ①类加载检查： 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 ②分配内存： 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 内存分配的两种方式：（补充内容，需要掌握） 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的 内存分配并发问题（补充内容，需要掌握） 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在Eden区分配一块儿内存，JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配 ③初始化零值： 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 ④设置对象头： 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 ⑤执行 init 方法： 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 3.2 对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为3块区域：对象头、实例数据和对齐填充。 Hotspot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的自身运行时数据（哈希码、GC分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为Hotspot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 3.3 对象的访问定位建立对象就是为了使用对象，我们的Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式有虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种： 句柄： 如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息； 直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。 这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 四 重点补充内容String 类和常量池1 String 对象的两种创建方式： 12345String str1 = &quot;abcd&quot;;//先检查字符串常量池中有没有&quot;abcd&quot;，如果字符串常量池中没有，则创建一个，然后str1指向字符串常量池中的对象，如果有，则直接将str1指向&quot;abcd&quot;&quot;；String str2 = new String(&quot;abcd&quot;);//堆中创建一个新的对象String str3 = new String(&quot;abcd&quot;);//堆中创建一个新的对象System.out.println(str1==str2);//falseSystem.out.println(str2==str3);//false 这两种不同的创建方法是有差别的。 第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。 记住一点：只要使用new方法，便需要创建新的对象。 再给大家一个图应该更容易理解，图片来源：https://www.journaldev.com/797/what-is-java-string-pool： 2 String 类型的常量池比较特殊。它的主要使用方法有两种： 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用。 123456String s1 = new String(&quot;计算机&quot;);String s2 = s1.intern();String s3 = &quot;计算机&quot;;System.out.println(s2);//计算机System.out.println(s1 == s2);//false，因为一个是堆内存中的String对象一个是常量池中的String对象，System.out.println(s3 == s2);//true，因为两个都是常量池中的String对象 3 String 字符串拼接 123456789String str1 = &quot;str&quot;;String str2 = &quot;ing&quot;;String str3 = &quot;str&quot; + &quot;ing&quot;;//常量池中的对象String str4 = str1 + str2; //在堆上创建的新的对象 String str5 = &quot;string&quot;;//常量池中的对象System.out.println(str3 == str4);//falseSystem.out.println(str3 == str5);//trueSystem.out.println(str4 == str5);//false 尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。 String s1 = new String(“abc”);这句话创建了几个字符串对象？将创建1或2个字符串。如果池中已存在字符串文字“abc”，则池中只会创建一个字符串“s1”。如果池中没有字符串文字“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共2个字符串对象。 验证： 1234String s1 = new String(&quot;abc&quot;);// 堆内存的地址值String s2 = &quot;abc&quot;;System.out.println(s1 == s2);// 输出false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。System.out.println(s1.equals(s2));// 输出true 结果： 12falsetrue 8种基本类型的包装类和常量池 Java 基本类型的包装类的大部分都实现了常量池技术，即Byte,Short,Integer,Long,Character,Boolean；这5种包装类默认创建了数值[-128，127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。 123456789Integer i1 = 33;Integer i2 = 33;System.out.println(i1 == i2);// 输出trueInteger i11 = 333;Integer i22 = 333;System.out.println(i11 == i22);// 输出falseDouble i3 = 1.2;Double i4 = 1.2;System.out.println(i3 == i4);// 输出false Integer 缓存源代码： 123456789/***此方法将始终缓存-128到127（包括端点）范围内的值，并可以缓存此范围之外的其他值。*/ public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 应用场景： Integer i1=40；Java 在编译的时候会直接将代码封装成Integer i1=Integer.valueOf(40);，从而使用常量池中的对象。 Integer i1 = new Integer(40);这种情况下会创建新的对象。 123Integer i1 = 40;Integer i2 = new Integer(40);System.out.println(i1==i2);//输出false Integer比较更丰富的一个例子: 12345678910111213Integer i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println(&quot;i1=i2 &quot; + (i1 == i2));System.out.println(&quot;i1=i2+i3 &quot; + (i1 == i2 + i3));System.out.println(&quot;i1=i4 &quot; + (i1 == i4));System.out.println(&quot;i4=i5 &quot; + (i4 == i5));System.out.println(&quot;i4=i5+i6 &quot; + (i4 == i5 + i6)); System.out.println(&quot;40=i5+i6 &quot; + (40 == i5 + i6)); 结果： 123456i1=i2 truei1=i2+i3 truei1=i4 falsei4=i5 falsei4=i5+i6 true40=i5+i6 true 解释： 语句i4 == i5 + i6，因为+这个操作符不适用于Integer对象，首先i5和i6进行自动拆箱操作，进行数值相加，即i4 == 40。然后Integer对象无法与数值进行直接比较，所以i4自动拆箱转为int值40，最终这条语句转为40 == 40进行数值比较。 参考 《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版》 《实战java虚拟机》 https://docs.oracle.com/javase/specs/index.html http://www.pointsoftware.ch/en/under-the-hood-runtime-data-areas-javas-memory-model/ https://dzone.com/articles/jvm-permgen-%E2%80%93-where-art-thou https://stackoverflow.com/questions/9095748/method-area-and-permgen 文章引用于 Snailclimb","link":"/2019/04/16/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"},{"title":"对象拷贝 - 优雅的解决方案 Mapstruct","text":"MapStruct GitHub 访问地址 : https://github.com/mapstruct/mapstruct/ 使用例子 : https://github.com/mapstruct/mapstruct-examples MapStrcut与其它工具对比以及使用说明! http://www.tuicool.com/articles/uiIRjai 是否一直在使用BeanUtils.copyProperties 用于对象属性拷贝。 出现种种小问题。 会将同名属性拷贝到另外一个对象中，操作方便但是存在一个缺陷 （速度慢） 有些同名字段却无法进行特殊化处理，将会导致不想修改的字段被覆盖。也不能自定义属性映射 在 mvc层 我们经常会DTO对象返回给前端 进行字段渲染。我们不喜欢将所有字段都显示给前端，或者我们需要修改字段返回给前端，例如 数据中存储的上架下架是0，1 但是前端需要的字段是true 和 false。 我们都得进行手动判断处理然后编辑成DTO返回给前端 MapStruct是一种类型安全的bean映射类生成java注释处理器。我们要做的就是定义一个映射器接口，声明任何必需的映射方法。在编译的过程中，MapStruct会生成此接口的实现。该实现使用纯java方法调用的源和目标对象之间的映射，MapStruct节省了时间，通过生成代码完成繁琐和容易出错的代码逻辑。。 MapStruct 拥有的优点： 使用普通方法调用而不是反射来快速执行，他会在编译器生成相应的 Impl 方法调用时直接通过简单的 getter/setter调用而不是反射或类似的方式将值从源复制到目标 编译时类型安全性 : 只能映射彼此的对象和属性，不能将商品实体意外映射到用户 DTO等 在构建时清除错误报告，如 映射不完整 (并非所有目标属性都被映射) 或 映射不正确(无法找到适当的映射方法或类型转换) MapStruct 提供的重要注解 : @Mapper : 标记这个接口作为一个映射接口，并且是编译时 MapStruct 处理器的入口 @Mapping : 解决源对象和目标对象中，属性名字不同的情况 Mappers.getMapper 自动生成的接口的实现可以通过 Mapper 的 class对象获取，从而让客户端可以访问 Mapper接口的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;properties&gt; // ... &lt;org.mapstruct.version&gt;1.2.0.Final&lt;/org.mapstruct.version&gt; &lt;/properties&gt; &lt;dependencies&gt; ... &lt;!-- MapStruct START --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MapStruct END --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;compilerArgs&gt; &lt;compilerArg&gt;-Amapstruct.defaultComponentModel=spring&lt;/compilerArg&gt; &lt;compilerArg&gt;-Amapstruct.suppressGeneratorTimestamp=true&lt;/compilerArg&gt; &lt;compilerArg&gt;-Amapstruct.suppressGeneratorVersionInfoComment=true&lt;/compilerArg&gt; &lt;/compilerArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; BasicObjectMapper包含了4个基本方法，单个和集合以及反转的单个和集合。开发中如需要对象转换操作可直接新建 interface 并继承 BasicObjectMapper，并在新建的接口上加上 @Mapper(componentModel = “spring”)，如果是属性中包含其它类以及该类已经存在 Mapper 则注解中加上 users = {类名.class}。componentModel = “spring” 该配置表示生成的实现类默认加上 spring @Component 注解，使用时可直接通过 @Autowire 进行注入 123456789101112131415161718192021222324252627public interface BasicObjectMapper&lt;SOURCE, TARGET&gt; { @Mappings({}) @InheritConfiguration TARGET to(SOURCE var1); @InheritConfiguration List&lt;TARGET&gt; to(List&lt;SOURCE&gt; var1); @InheritInverseConfiguration SOURCE from(TARGET var1); @InheritInverseConfiguration List&lt;SOURCE&gt; from(List&lt;TARGET&gt; var1); } 直接使用进行对象数据转换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293@Datapublic class ProductCategory { /** 类别编码 */ private String categoryCode; /** 类别名称 */ private String categoryName;} @Datapublic class CategoryVo { private String code; private String name;} import org.mapstruct.Mapper;import org.mapstruct.Mapping;import org.mapstruct.Mappings;import org.mapstruct.factory.Mappers;@Mapperpublic interface CategoryMapper extends BasicObjectMapper&lt;CategoryVo, ProductCategory&gt; { CategoryMapper MAPPER = Mappers.getMapper(CategoryMapper.class); @Mappings({ @Mapping(source = &quot;code&quot;, target = &quot;categoryCode&quot;), @Mapping(source = &quot;name&quot;, target = &quot;categoryName&quot;) }) ProductCategory to(CategoryVo source);}public static void main(String[] args) { CategoryMapper categoryMapper = CategoryMapper.MAPPER; CategoryVo vo = new CategoryVo(); vo.setCode(&quot;0000&quot;); vo.setName(&quot;属性名称&quot;); ProductCategory pc = categoryMapper.to(vo); // 通过 to方法得到 ProductCategory System.out.println(&quot;1&quot; + pc); CategoryVo vo1 = categoryMapper.from(pc); // 通过 from方法得到 CategoryVo，既反转 to方法 System.out.println(&quot;2&quot; + vo1); List&lt;ProductCategory&gt; pcList = categoryMapper.to(Arrays.asList(vo, vo1)); // 通过to方法从集合得到转换后的集合 System.out.println(&quot;3&quot; + pcList); List&lt;CategoryVo&gt; voList = categoryMapper.from(pcList); // 反转集合 System.out.println(&quot;4&quot; + voList);} 自定义方法添加到映射器 : 在某些情况下，需要手动实现 MapStruct 无法生成的从一种类型到另一种类型的特定映射，有如下两种实现方法 : 方法1&gt; 在另一个类上实现此类方法，然后由 MapStruct 生成的映射器使用该方法 方法2&gt; 在Java 8或更高版本时，可以直接在映射器界面中实现自定义方法作为默认方法。如果参数和返回类型匹配，生成的代码将调用默认方法 12345678910111213141516171819@Mapperpublic interface CarMapper { CarMapper MAPPER = Mappers.getMapper(CarMapper.class); @Mappings({...}) CarDto carToCarDto(Car car); default PersonDto personToPersonDto(Person person) { // hand-written mapping logic }} 映射器也可以定义为抽象类的形式而不是接口，并直接在此映射器类中实现自定义方法。在这种情况下，MapStruct将生成抽象类的扩展，并实现所有抽象方法。这种方法优于声明默认方法的优点是可以在映射器类中声明附加字段 1234567891011121314151617@Mapperpublic abstract class CarMapper { @Mappings(...) public abstract CarDto carToCarDto(Car car); public PersonDto personToPersonDto(Person person) { // hand-written mapping logic }} 多源参数映射方法 : MapStruct 支持多个源参数的映射方法，将几个实体组合成一个数据传输对象 123456789101112131415@Mapperpublic interface AddressMapper { @Mappings({ @Mapping(source = &quot;person.description&quot;, target = &quot;description&quot;), @Mapping(source = &quot;address.houseNo&quot;, target = &quot;houseNumber&quot;) }) DeliveryAddressDto personAndAddressToDeliveryAddressDto(Person person, Address address);} 如果多个源对象定义了一个具有相同名称的属性，则必须使用 @Mapping 注释来指定从中检索属性的源参数，如果这种歧义未得到解决，将会引发错误。对于在给定源对象中只存在一次的属性，指定源参数的名称是可选的，因为它可以自动确定 123456789101112131415161718MapStruct 还提供直接引用源参数@Mapperpublic interface AddressMapper { @Mappings({ @Mapping(source = &quot;person.description&quot;, target = &quot;description&quot;), @Mapping(source = &quot;hn&quot;, target = &quot;houseNumber&quot;) }) DeliveryAddressDto personAndAddressToDeliveryAddressDto(Person person, Integer hn);} 直接字段访问映射 : MapStruct 支持 public 没有 getter/setter 的字段的映射，如果 MapStruct 无法为属性找到合适的 getter/setter方法，MapStruct 将使用这些字段作为 读/写访问器。如果它是 public，则字段被认为是读取存取器 public final。如果一个字段 static 不被视为读取存取器只有在字段被认为是写入访问者的情况下 public。如果一个字段 final 和/或 static 它不被认为是写入访问者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class Customer { private Long id; private String name; // getters and setter omitted for brevity} public class CustomerDto { public Long id; public String customerName;} @Mapperpublic interface CustomerMapper { CustomerMapper MAPPER = Mappers.getMapper( CustomerMapper.class ); @Mapping(source = &quot;customerName&quot;, target = &quot;name&quot;) Customer toCustomer(CustomerDto customerDto); @InheritInverseConfiguration CustomerDto fromCustomer(Customer customer);}// 生成的映射器如下public class CustomerMapperImpl implements CustomerMapper { @Override public Customer toCustomer(CustomerDto customerDto) { // ... customer.setId( customerDto.id ); customer.setName( customerDto.customerName ); // ... } @Override public CustomerDto fromCustomer(Customer customer) { // ... customerDto.id = customer.getId(); customerDto.customerName = customer.getName(); // ... }} 检索映射器 : Mapper实例 通过 org.mapstruct.factory.Mappers 的 getMapper() 方法来检索。通常 映射器接口应该定义一个名为的成员 INSTANCE ，它包含一个映射器类型的单个实例 : 123456789101112131415161718192021222324252627282930313233@Mapperpublic interface CarMapper { CarMapper INSTANCE = Mappers.getMapper(CarMapper.class); CarDto carToCarDto(Car car);}这种模式使客户非常容易地使用映射器对象，而无需反复实例化新的实例 :Car car = ...;CarDto dto = CarMapper.INSTANCE.carToCarDto( car ); 使用依赖注入 : 通过 Spring 依赖注入可以获取映射器对象@Mapper(componentModel = &quot;spring&quot;)public interface CarMapper { CarDto carToCarDto(Car car);}@Injectprivate CarMapper mapper; 数据类型转换 : 源对象和目标对象中映射的属性类型可能不同，MapStruct 提供自动处理类型转换，提供如下自动转换 : 1&gt; Java基本数据类型及其相应的包装类型，如 int 和 Integer，boolean 和 Boolean 等生成的代码是 null 转换一个包装型成相应的原始类型时一个感知，即 null 检查将被执行 2&gt; Java基本号码类型和包装类型，例如之间 int 和 long 或 byte 和 Integer (大类类型数据转换成小类可能出现精度损失) 3&gt; 所有Java基本类型之间 (包括其包装) 和 String 之间，例如 int 和 String 或 Boolean 和 String，java.text.DecimalFormat 均可以指定格式字符串 int 到 String的转换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596int 到 String的转换@Mapperpublic interface CarMapper { @Mapping(source = &quot;price&quot;, numberFormat = &quot;$#.00&quot;) CarDto carToCarDto(Car car); @IterableMapping(numberFormat = &quot;$#.00&quot;) List&lt;String&gt; prices(List&lt;Integer&gt; prices);}BigDecimal 转换为 String@Mapperpublic interface CarMapper { @Mapping(source = &quot;power&quot;, numberFormat = &quot;#.##E0&quot;) CarDto carToCarDto(Car car);}从日期到字符串的转换@Mapperpublic interface CarMapper { @Mapping(source = &quot;manufacturingDate&quot;, dateFormat = &quot;dd.MM.yyyy&quot;) CarDto carToCarDto(Car car); @IterableMapping(dateFormat = &quot;dd.MM.yyyy&quot;) List&lt;String&gt; stringListToDateList(List&lt;Date&gt; dates);} 映射对象引用 : 对象中如果包含另一个对象的引用，此时只需为引用的对象类型定义映射方法即可@Mapperpublic interface CarMapper { CarDto carToCarDto(Car car); PersonDto personToPersonDto(Person person);} # 映射器控制嵌套的bean映射@Mapperpublic interface FishTankMapper { @Mappings({ @Mapping(target = &quot;fish.kind&quot;, source = &quot;fish.type&quot;), @Mapping(target = &quot;fish.name&quot;, ignore = true), @Mapping(target = &quot;plant&quot;, ignore = true ), @Mapping(target = &quot;ornament&quot;, ignore = true ), @Mapping(target = &quot;material&quot;, ignore = true), @Mapping(target = &quot;ornament&quot;, source = &quot;interior.ornament&quot;), @Mapping(target = &quot;material.materialType&quot;, source = &quot;material&quot;), @Mapping(target = &quot;quality.report.organisation.name&quot;, source = &quot;quality.report.organisationName&quot;) }) FishTankDto map( FishTank source );} 调用其他映射器 : MapStruct 中可以调用在其他类中定义的映射方法，无论是由MapStruct生成的映射器还是手写映射方法 1234567891011121314151617181920212223242526272829303132333435363738# 手动实现的映射public class DateMapper { public String asString(Date date) { return date != null ? new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).format(date) : null; } public Date asDate(String date) { try { return date != null ? new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).parse(date) : null; } catch (ParseException e) { throw new RuntimeException(e); } }} # 引用另一个映射器类@Mapper(uses = DateMapper.class)public class CarMapper { CarDto carToCarDto(Car car);} 当为该 carToCarDto() 方法的实现生成代码时，MapStruct将查找将 Date 对象映射到String的方法，在 DateMapper 该类上找到它并生成 asString() 用于映射该 manufacturingDate 属性的调用 映射集合 : 集合类型(映射 List，Set 等等) 以相同的方式映射 bean类型，通过定义与在映射器接口所需的源和目标类型的映射方法。生成的代码将包含一个遍历源集合的循环，转换每个元素并将其放入目标集合中。如果在给定的映射器或其使用的映射器中找到了集合元素类型的映射方法，则会调用此方法以执行元素转换。或者，如果存在源和目标元素类型的隐式转换，则将调用此转换例程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Mapperpublic interface CarMapper { Set&lt;String&gt; integerSetToStringSet(Set&lt;Integer&gt; integers); List&lt;CarDto&gt; carsToCarDtos(List&lt;Car&gt; cars); CarDto carToCarDto(Car car);} # 生成的集合映射方法@Overridepublic Set&lt;String&gt; integerSetToStringSet(Set&lt;Integer&gt; integers) { if (integers == null) { return null; } Set&lt;String&gt; set = new HashSet&lt;&gt;(); for (Integer integer : integers) { set.add(String.valueOf(integer)); } return set;} @Overridepublic List&lt;CarDto&gt; carsToCarDtos(List&lt;Car&gt; cars) { if (cars == null) { return null; } List&lt;CarDto&gt; list = new ArrayList&lt;&gt;(); for (Car car : cars) { list.add(carToCarDto(car)); } return list;} 映射Map :public interface SourceTargetMapper { @MapMapping(valueDateFormat = &quot;dd.MM.yyyy&quot;) Map&lt;String, String&gt; longDateMapToStringStringMap(Map&lt;Long, Date&gt; source);} 映射流 :@Mapperpublic interface CarMapper { Set&lt;String&gt; integerStreamToStringSet(Stream&lt;Integer&gt; integers); List&lt;CarDto&gt; carsToCarDtos(Stream&lt;Car&gt; cars); CarDto carToCarDto(Car car);} 映射枚举 : 默认情况下，源枚举中的每个常量映射到目标枚举类型中具有相同名称的常量。如果需要，可以使用 @ValueMapping 注释帮助将source enum中的常量映射为具有其他名称的常量 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Mapperpublic interface OrderMapper { OrderMapper INSTANCE = Mappers.getMapper(OrderMapper.class); @ValueMappings({ @ValueMapping(source = &quot;EXTRA&quot;, target = &quot;SPECIAL&quot;), @ValueMapping(source = &quot;STANDARD&quot;, target = &quot;DEFAULT&quot;), @ValueMapping(source = &quot;NORMAL&quot;, target = &quot;DEFAULT&quot;) }) ExternalOrderType orderTypeToExternalOrderType(OrderType orderType);} 默认值和常量 : @Mapper(uses = StringListMapper.class)public interface SourceTargetMapper { SourceTargetMapper INSTANCE = Mappers.getMapper(SourceTargetMapper.class); @Mappings({ @Mapping(target = &quot;stringProperty&quot;, source = &quot;stringProp&quot;, defaultValue = &quot;undefined&quot;), @Mapping(target = &quot;longProperty&quot;, source = &quot;longProp&quot;, defaultValue = &quot;-1&quot;), @Mapping(target = &quot;stringConstant&quot;, constant = &quot;Constant Value&quot;), @Mapping(target = &quot;integerConstant&quot;, constant = &quot;14&quot;), @Mapping(target = &quot;longWrapperConstant&quot;, constant = &quot;3001&quot;), @Mapping(target = &quot;dateConstant&quot;, dateFormat = &quot;dd-MM-yyyy&quot;, constant = &quot;09-01-2014&quot;), @Mapping(target = &quot;stringListConstants&quot;, constant = &quot;jack-jill-tom&quot;) }) Target sourceToTarget(Source s);} 表达式 :@Mapperpublic interface SourceTargetMapper { SourceTargetMapper INSTANCE = Mappers.getMapper(SourceTargetMapper.class); @Mapping(target = &quot;timeAndFormat&quot;, expression = &quot;java( new org.sample.TimeAndFormat( s.getTime(), s.getFormat() ) )&quot;) Target sourceToTarget(Source s);} 确定结果类型 : 当结果类型具有继承关系时，选择映射方法(@Mapping) 或工厂方法(@BeanMapping) 可能变得不明确。假设一个Apple和一个香蕉，这两个都是 Fruit的专业 123456789101112131415161718192021222324252627@Mapper(uses = FruitFactory.class)public interface FruitMapper { @BeanMapping(resultType = Apple.class) Fruit map(FruitDto source);} public class FruitFactory { public Apple createApple() { return new Apple(&quot;Apple&quot;); } public Banana createBanana() { return new Banana(&quot;Banana&quot;); }} 控制 ‘空’ 参数的映射结果 : 默认情况下 null 会返回，通过指定 nullValueMappingStrategy = NullValueMappingStrategy.RETURN_DEFAULT 上 @BeanMapping，@IterableMapping，@MapMapping，或全局上 @Mapper 或 @MappingConfig，映射结果可以被改变以返回空默认值 1&gt; Bean映射 : 将返回一个 ‘空’ 目标bean，除常量和表达式外，它们将在存在时填充 2&gt; 基元 : 基元的默认值将被返回，例如 false for boolean 或 0 for int 3&gt; Iterables/Arrays : 一个空的迭代器将被返回 4&gt; 地图 : 将返回空白地图 共享配置 : 通过指向中心接口来定义共享配置的可能性 @MapperConfig，要使映射器使用共享配置，需要在 @Mapper#config 属性中定义配置界面。该 @MapperConfig 注释具有相同的属性 @Mapper 注释。任何未通过的属性 @Mapper 都将从共享配置继承。指定 @Mapper 的属性优先于通过引用的配置类指定的属性 123456789@MapperConfig(uses = CustomMapperViaMapperConfig.class, unmappedTargetPolicy = ReportingPolicy.ERROR)public interface CentralConfig {} @Mapper(config = CentralConfig.class, uses = { CustomMapperViaMapper.class } )public interface SourceTargetMapper {}","link":"/2019/05/29/%E5%AF%B9%E8%B1%A1%E6%8B%B7%E8%B4%9D-%E4%BC%98%E9%9B%85%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-Mapstruct/"},{"title":"带你看懂分布式事务","text":"转自Java Geek Tech 4月初在面试一家互联网公司的过程中就被问到了分布式事务问题。我又一次在没有好好整理的问题上吃了亏，记录一下，还是长记性！！！ 背景四月初，去面试了本市的一家之前在做办公室无人货架的公司，虽然他们现在在面临着转型，但是对于我这种想从传统企业往互联网行业走的孩子来说，还是比较有吸引力的。 在面试过程中就提到了分布式事务问题。我又一次在没有好好整理的问题上吃了亏，记录一下，还是长记性 ！！！ 先看面试过程面试官先是在纸上先画了这样一张图： 让我看这张图按照上面的流程走，有没有什么问题？面试官并没有直接说出来这里面会有分布式事务的问题，而是让我来告诉他，这就是面试套路呀。 我回答了这中间可能存在分布式事务的问题，当步骤 2 在调用 B 系统时，可能存在B 系统处理完成后，在响应的时候超时，导致 A 系统误认为 B 处理失败了，从而导致A 系统回滚，跟 B 系统存在数据不一致的情况。 ok ，我回答到这里，应该回答了面试官的第一层意思，至少我有这种意识，他点了点头。 接着，他继续问：“那你有什么好的解决方式吗？” 此时我脑子里面只有两阶段提交的大概流程图的印象，然后巴卡巴拉的跟他说了一番，什么中间来个协调者呀，先预提交什么的，如果有失败，就 rollback，如果 ok，再真正的提交事务，就是网上这些大神们说的这些理论。 然后面试官就继续问：那A 在调用 B 的这条线断了，你们代码具体是怎么处理的呢 ？怎么来做到 rollback 的呢 ？说说你代码怎么写的。 此时，我懵了。 最后结果，大家肯定也能猜到，凉凉。 什么是事务这里我们说的事务一般是指 数据库事务，简称 事务，是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。维基百科中这么说的。 用转账的例子来说，A 账户要给 B 账户转 100块，这中间至少包含了两个操作： A 账户 减 100 块 B 账户 加 100 块 在支持事务的数据库管理系统来说，就是得确保上面两个操作（整个“事务”）都能完成，不能存在，A 的100块扣了，然后B 的账户又没加上去的情况。 数据库事务包含了四个特性，分别是： 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。对于转账来说，A账户扣钱，B 账户加钱，要么同时成功，要么同时失败。 一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。其他账户在转账的时候，不能影响到上面的 A 跟 B 之前的交易。 持久性（Durability）：已被提交的事务对数据库的修改应该永久保存在数据库中。 什么是分布式事务我们知道，上面的转账 我们是在一个数据库中的事务操作。我们可以使用一些框架 比如 Spring 的事务管理器来给我们统一搞定。 但是如果我们系统中出现垮库操作，比如一个操作中，我需要操作多个库，或者说这个操作会垮应用之前的调用，那么Spring 的事务管理机制就对这种场景没有办法了。 就像上面面试题中出现的问题一样，在系统 A 的步骤 2 在远程调用 B 的时候，由于网络超时，导致B 没有正常响应，但是A 这边调用失败，进行了回滚，而 B 又提交了事务。此时就可能会导致数据不一致的情况，参生分布式事务的问题。 分布式事务的存在，就是解决数据不一致的情况。 为什么我们要保证一致性CAP 理论分布式系统中有这么一个广为流传的理论：CAP 定理 这个定理呀，起源于加州大学柏克莱分校（University of California, Berkeley）的计算机科学家埃里克·布鲁尔在 2000年的分布式计算原理研讨会（PODC）上提出的一个猜想。后来在2002年，麻省理工学院（MIT）的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为一个定理。【摘自维基百科】 他说呀，对于一个分布式计算系统来说，不可能同时满足以下三点： 一致性（Consistency） 可用性（Availability） 分区容错性（Partition tolerance） 而一个分布式系统最多只能满足其中的两项。 那么，上面的三点分别是什么玩意儿？为什么又只能同时满足两项呢？ 我们先看这样一个场景，现在我们系统部署了两份（两个节点，web1 和 web2 ）,同样的业务代码，但是维护的是自己这个节点生成的数据。但是用户访问进来，可能会访问到不同的节点。但是不管是访问web1 还是web2 ,在用户参数数据 过后，这个数据都必须得同步到另外的节点，让用户不管访问哪个节点，都是响应他需要的数据。如下图： 分区容错性我们先说 分区容错性：也就是说呀，就算上面这两个节点之间发生了网络故障，无法发生同步的问题，但是用户访问进来，不管到哪个节点，这个节点都得单独提供服务，这一点对于互联网公司来说，是必须要满足的。 当 web1 和 web2 之间的网络发生故障，导致数据无法进行同步。用户在web1 上写了数据，马上又访问进来读取数据，请求到了 web2，但是此时 web2 是没有数据的。那么我们是 给用户返回 null ？还是说给一些提示，说系统不可用，稍后重试呢？ 都不妥吧，兄弟。 一致性如果要保证可用性，那么有数据的节点返回数据，没数据的节点返回 null ,就会出现用户那里看到的是一会儿有数据，一会儿没有数据，此时就存在 一致性 的问题。 可用性如果保证一致性，那么在用户访问的时候，不管 web1 还是web2 ，我们可能会返回一些提示信息，说系统不可用，稍后再试等等，保证每次都是一致的。明明我们有数据在，但是我们系统却响应的是提示信息，此时就是 可用性 的问题。 由于分区容错性（P）是必须保证的，那么我们分布式系统就更多是在一致性（CP） 和可用性（AP）上做平衡了，只能同时满足两个条件。 其实，大家想想，ZK 是不是就是严格实现了 CP ，而 Eureka 则是保证了 AP。 其实分布式事务强调的就是一致性。 几种分布式事务解决方案2PC在说 2PC 之前，我们先了解一下 XA规范 是个什么东西？ XA规范 描述了全局的事务管理器与局部的资源管理器之间的接口。XA规范的目的是允许多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问，这样可以使ACID属性跨越应用程序而保持有效。 XA 使用 两阶段提交（2PC） 来保证所有资源同时提交或回滚任何特定的事务。 大家想一个场景，在做单应用的时候，有的同学连过两个库吧？在一个事务中会同时向两个系统插入数据。但是对于普通事务来讲，是管不了的。 看下图（只是举例这种操作的套路，不局限于下面的业务）： 一个服务里面要去操作两个库，如何保证事务成功呢。 这里我们介绍一个框架 Atomikos ，他就是实现了这种 XA 的套路。看代码： 具体代码移步 Github AtomikosJTATest: https://github.com/heyxyw/learn/blob/master/distributed-transaction/src/main/java/com/zhouq/jta/AtomikosJTATest.java 看到上面的图了哇，Atomikos 自己实现了一个事务管理器。我们获取的连接都从它哪里拿。 第一步先开启事务，然后进行预提交，db1 和 db2 都先进行预先执行，注意：这里没有提交事务。 第二步才是真正的提交事务，由 Atomikos 来发起提交的，如果出现异常则发起回滚操作。 这个过程是不是就有两个角色了，一个 事务管理器，一个资源管理器（我们这里是 数据库，也可以是其他的组件，消息队列什么的）。 整个执行过程是这样：上图是正常情况，下图是一方出现故障的情况。 图片来自：XA 事务处理：https://www.infoq.cn/article/xa-transactions-handle ，具体关于XA 的详细讲解，可以好好看看。整个2PC 的流程： 第一阶段（提交请求阶段）： 协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 **第二阶段 (提交执行阶段)**： 成功，当协调者节点从所有参与者节点获得的相应消息都为”同意”时： 协调者节点向所有参与者节点发出”正式提交”的请求。 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”完成”消息。 协调者节点收到所有参与者节点反馈的”完成”消息后，完成事务。 失败，如果任一参与者节点在第一阶段返回的响应消息为”终止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出”回滚操作”的请求。 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”回滚完成”消息。 协调者节点收到所有参与者节点反馈的”回滚完成”消息后，取消事务。 有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。 可靠消息最终一致性方案基于普通的消息队列中间件上面我们说了两阶段提交的方案，接下来我们讲讲怎么基于可靠消息最终一致性方案来解决分布式事务的问题。 这个方案，就有消息服务中间件角色参与进来了。我们先看一个大提的流程图： 我们以创建订单下单过程和 后面出库 的流程为例来讲述上面的图。 在下单逻辑里面（Producer 端），我们先生成一个订单的数据，比如订单号，数量等关键的信息，先包装成一条消息，并把消息的状态置为 init ,然后发送到 独立消息服务中，并且入库。 接下来继续处理 下单的其他本地的逻辑。 处理完成后，走到确认发送消息这一步，说明我的订单是能够下成功的。那么我们再向消息服务里面发送一条confirm 的消息，消息服务里面就可以把这个订单的消息状态修改为 send 并且，发送到消息队列里面。 接下来，消费者端去消费这条消息。处理自己这边的逻辑，处理完成以后，然后反馈消息处理结果到独立消息服务，独立消息服务把消息状态置为 end 状态 ,表示结束。但是得注意保证接口的幂等性，避免重复消费带来的问题。 这里面可能出现的问题，以及各个步骤怎么解决的： 比如在 prepare 阶段就发生异常，那么这里订单这块都不会下成功。但是我们说，我们这里是基于可靠消息，得保证我们的消息服务是正常的。 在 comfirm 出现异常，此时发送确认失败，但是我们的单已经下成功了。这种情况，我们就可以在独立消息服务中起一个定时任务，定时去查询 消息状态为 init 的数据，去反向查询 订单系统中的单号是否存在，如果存在，那么我们就把消息置为 send 状态，然后发送到 消息队列里面，如果查询到不存在的订单，那么就直接抛弃掉这条消息。所以这里我们的订单系统得提供批量查询订单的接口，还有下游的消费系统得保证幂等。保证重复消费的一致性。 消息队列丢消息或者下游系统一直处理失败，导致没有消息反馈过来，出现一直是 send 状态的消息。此时独立消息我们还需要一个定时任务，就是处理这种 send 状态的消息，我们可以进行重发，直到后面系统消费成功为止。 最后消费者这端，我们在消费的时候，如果出现消费异常，或者是系统bug 导致异常的情况。那么这里我们还可以去记录日志，如果不是系统代码问题，是网络抖动导致的，那么在上面第三种情况，消息系统会重新发送消息，我们再处理就是。如果是一直失败，你就要考虑是不是你的代码真的有问题，有bug 了吧。 最后的保底方案，记录日志，出现问题人肉处理数据。现在我们系统出现错误，以目前的技术手段是没办法做到都靠机器去解决的，都得靠我们人。据我了解，现在很多大厂都会有这样的人，专门处理这种类型的问题，手动去修改数据库的方式。我们之前待的小厂，基本上都是靠我们自己去写 sql 去修改数据的，想想，是不是？ 贴一下关键的独立消息服务核心逻辑代码框架： 定时任务： 基于 RocketMQ实现这种方案，跟上面的独立消息服务一致，这里直接去掉独立服务，只利用消息队列来实现，也就是阿里的 RocketMQ 。 流程图如下： 这里的整个流程跟上面基于消息服务是一致的。这里就不过多阐述，具体代码实现请参考 ：https://www.jianshu.com/p/453c6e7ff81c ，写得非常好。 针对这里的 可靠消息最终一致性方案 来说，我们说的 可靠 是指保证消息一定能发送到消息中间件里面去，保证这里可靠。 对于下游的系统来说，消费不成功，一般来说就是采取失败重试，重试多次不成功，那么就记录日志，后续人工介入来进行处理。所以这里得强调一下，后面的系统，一定要处理 幂等，重试，日志 这几个东西。 如果是对于资金类的业务，后续系统回滚了以后，得想办法去通知前面的系统也进行回滚，或者是发送报警由人工来手工回滚和补偿。 TCC 方案TCC 的全程分为三个阶段，分别是 Try、Confirm、Cancel： Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留 Confirm阶段：这个阶段说的是在各个服务中执行实际的操作 Cancel阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作 还是以转账的例子为例，在跨银行进行转账的时候，需要涉及到两个银行的分布式事务，从A 银行向 B 银行转 1 块，如果用TCC 方案来实现： 大概思路就是这样的： Try 阶段：先把A 银行账户先冻结 1 块，B银行账户中的资金给预加 1 块。 Confirm 阶段：执行实际的转账操作，A银行账户的资金扣减 1块，B 银行账户的资金增加 1 块。 Cancel 阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如A银行账户如果已经扣减了，但是B银行账户资金增加失败了，那么就得把A银行账户资金给加回去。 这种方案就比较复杂了，一步操作要做多个接口来配合完成。 以 ByteTCC 框架的实现例子来大概描述一下上面的流程，示例地址 https://gitee.com/bytesoft/ByteTCC-sample/tree/master/dubbo-sample 最开始 A 银行账户 与 B 银行账户都分别为：amount（数量）=1000，frozen（冻结金额）= 0 从A银行账户发起转账到 B 银行账户 1 块： try 阶段：A 银行账户金额减 1，冻结金额 加 1，B 银行 账户 冻结金额加 1 。 此时： A 银行账户：amount（数量）= 1000 - 1 = 999，frozen（冻结金额）= 0 + 1 = 1 B 银行账户：amount（数量）= 1000，frozen（冻结金额）= 0 + 1 = 1 confirm 阶段 ： A银行账户冻结金额 减 1，B 银行账户金额 加 1，冻结金额 减 1 此时： A 银行账户：amount（数量）= 999，frozen（冻结金额）= 1 - 1 = 0 B 银行账户：amount（数量）= 1000 + 1 = 1001，frozen（冻结金额）= 1 - 1 = 0 cancel 阶段： A 银行账户金额 + 1，冻结金额 -1 ，B 银行 冻结金额 -1 此时： A 银行账户：amount（数量）= 999 + 1 = 1000，frozen（冻结金额）= 1 - 1 = 0 B 银行账户：amount（数量）= 1000，frozen（冻结金额）= 1 - 1 = 0 至此，整个过程就演示完毕，大家记得跑一遍代码。其实还是蛮复杂的，有许多接口一起来配合完成整个业务，试想一下，如果我们项目中大量用到 TCC 来写，你受得了？ 再提一下 BASE理论BASE 理论是 Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。 基本可用（Basically Available）： 指分布式系统在出现不可预知故障的时候，允许损失部分可用性。 软状态（ Soft State）：指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致（ Eventual Consistency）：强调的是所有的数据更新操作，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 其核心思想是： 即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency） 到这里大家再想想， 上面 TCC 方案中的账户设计了一个冻结字段 frozen ，这里是不是就是 BASE理论 中间的 软状态 呢 ？ 最后对存在非常多的微服务的公司来说，服务之间的调用异常的复杂，那么在引入分布式事务的过程中，你需要考虑加入分布式事务后，系统实现起来的复杂性和开发成本，或者说哪些地方根本就不需要搞分布式事务。 其实没必要到处都搞分布式事务，对于大多数的业务来说，其实我们并不需要做分布式事务，直接做日志，做监控就好了。然后出现问题，手工去处理，一个月也不会有那么多的问题的。如果你天天都出现这些问题，你是不是要好好去排查排查你的代码Bug了。 对于资金类的场景，那么基本上会采用分布式事务方案来保证，像其他的服务，会员，积分，商品信息呀这些，可能就不需要这么去搞了。","link":"/2019/04/22/%E5%B8%A6%E4%BD%A0%E7%9C%8B%E6%87%82%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"title":"搞定JVM垃圾回收就是这么简单","text":"写在前面本节常见面试题：问题答案在文中都有提到 如何判断对象是否死亡（两种方法）。 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。 如何判断一个常量是废弃常量 如何判断一个类是无用的类 垃圾收集有哪些算法，各自的特点？ HotSpot为什么要分为新生代和老年代？ 常见的垃圾回收器有那些？ 介绍一下CMS,G1收集器。 Minor Gc和Full GC 有什么不同呢？ 本文导火索 当需要排查各种 内存溢出问题、当垃圾收集成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。 1 揭开JVM内存分配与回收的神秘面纱Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆空间的基本结构： 上图所示的 eden区、s0区、s1区都属于新生代，tentired 区属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden区-&gt;Survivor 区后对象的初始年龄变为1)，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 1.1 对象优先在eden区分配目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC.下面我们来进行实际测试以下。 在测试之前我们先来看看 Minor GC和Full GC 有什么不同呢？ 新生代GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。 老年代GC（Major GC/Full GC）:指发生在老年代的GC，出现了Major GC经常会伴随至少一次的Minor GC（并非绝对），Major GC的速度一般会比Minor GC的慢10倍以上。 测试： 12345678public class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2; allocation1 = new byte[30900*1024]; //allocation2 = new byte[900*1024]; }} 通过以下方式运行： 添加的参数：-XX:+PrintGCDetails 运行结果(红色字体描述有误，应该是对应于JDK1.7的永久代)： 从上图我们可以看出eden区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用2000多k内存）。假如我们再为allocation2分配内存会出现什么情况呢？ 1allocation2 = new byte[900*1024]; 简单解释一下为什么会出现这种情况： 因为给allocation2分配内存的时候eden区内存几乎已经被分配完了，我们刚刚讲了当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC.GC期间虚拟机又发现allocation1无法存入Survivor空间，所以只好通过 分配担保机制 把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。可以执行如下代码验证： 123456789101112public class GCTest { public static void main(String[] args) { byte[] allocation1, allocation2,allocation3,allocation4,allocation5; allocation1 = new byte[32000*1024]; allocation2 = new byte[1000*1024]; allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; }} 1.2 大对象直接进入老年代大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 1.3 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 1.4 动态对象年龄判定为了更好的适应不同程序的内存情况，虚拟机不是永远要求对象年龄必须达到了某个值才能进入老年代，如果 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需达到要求的年龄。 2 对象已经死亡？堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 2.1 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。 123456789101112public class ReferenceCountingGc { Object instance = null; public static void main(String[] args) { ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; }} 2.2 可达性分析算法这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 2.3 再谈引用无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。 JDK1.2之前，Java中引用的定义很传统：如果reference类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2以后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 1．强引用 以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空 间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 2．软引用（SoftReference） 如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 3．弱引用（WeakReference） 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 4．虚引用（PhantomReference） “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 2.4 不可达的对象并非“非死不可”即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。 被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 2.5 如何判断一个常量是废弃常量运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 “abc”，如果当前没有任何String对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。 注意：我们在 可能是把Java内存区域讲的最清楚的一篇文章 也讲了JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 2.6 如何判断一个类是无用的类方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 3 垃圾收集算法 3.1 标记-清除算法算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，效率也很高，但是会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 3.2 复制算法为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 3.3 标记-整理算法根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 3.4 分代收集算法当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 延伸面试问题： HotSpot为什么要分为新生代和老年代？ 根据上面的对分代收集算法的介绍回答。 4 垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为知道现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的HotSpot虚拟机就不会实现那么多不同的垃圾收集器了。 4.1 Serial收集器Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。 虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial收集器对于运行在Client模式下的虚拟机来说是个不错的选择。 4.2 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。 新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。 4.3 Parallel Scavenge收集器Parallel Scavenge 收集器类似于ParNew 收集器。 那么它有什么特别之处呢？ 12345678-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行-XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行 Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用复制算法，老年代采用标记-整理算法。 4.4.Serial Old收集器Serial收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。 4.5 Parallel Old收集器 Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。 4.6 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与root相连的对象，速度很快 ； 并发标记： 同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时GC线程开始对为标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对CPU资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 4.7 G1收集器G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征. 被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备一下特点： 并行与并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。 空间整合：与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内。 G1收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 **G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)**。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 文章引用于 Snailclimb 参考： 《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版》 https://my.oschina.net/hosee/blog/644618","link":"/2019/04/16/%E6%90%9E%E5%AE%9AJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E7%AE%80%E5%8D%95/"},{"title":"小程序的三级联动","text":"项目中经常遇到要选择城市。用到三级联动的方式 微信小程序的 picker 组件 mode=date 是三级联动的，但是无法自定义，这让我们心痛不已，值得我们欣慰的 picker-view 组件是可以自定义添加多个选项，但还是无法联动。既然这样那就自己写一个联动。 做到如下图所示： 分为动态获取地址 引用静态文件获取地址 addressAdd.wxml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;view class=&quot;add-address&quot;&gt; &lt;view class=&quot;add-form&quot;&gt; &lt;view class=&quot;form-item&quot;&gt; &lt;input class=&quot;input&quot; bindinput=&quot;bindinputName&quot; placeholder=&quot;姓名&quot; value=&quot;{{address.name}}&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;form-item&quot;&gt; &lt;input class=&quot;input&quot; bindinput=&quot;bindinputMobile&quot; value=&quot;{{address.mobile}}&quot; placeholder=&quot;手机号码&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;form-item&quot;&gt; &lt;input class=&quot;input&quot; bindinput=&quot;bindinputAddress&quot; value=&quot;{{address.address}}&quot; placeholder=&quot;详细地址&quot; /&gt; &lt;/view&gt; &lt;view class=&quot;form-item&quot; bindtap='select'&gt; &lt;view class=&quot;weui-cell__bd&quot;&gt; {{areaInfo}} &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;form-default&quot;&gt; &lt;text bindtap=&quot;bindIsDefault&quot; class=&quot;default-input {{address.isDefault == 1 ? 'selected' : ''}}&quot;&gt;设为默认地址&lt;/text&gt; &lt;/view&gt; &lt;/view&gt; &lt;view class=&quot;btns&quot;&gt; &lt;button class=&quot;cannel&quot; bindtap=&quot;cancelAddress&quot;&gt;取消&lt;/button&gt; &lt;button class=&quot;save&quot; bindtap=&quot;saveAddress&quot;&gt;保存&lt;/button&gt; &lt;/view&gt;&lt;/view&gt;&lt;view class=&quot;bg-mask&quot; bindtap=&quot;cancelSelectRegion&quot; wx:if=&quot;{{openSelectRegion}}&quot;&gt;&lt;/view&gt;&lt;view class=&quot;picker-view&quot; animation=&quot;{{animationAddressMenu}}&quot; style=&quot;visibility:{{addressMenuIsShow ? 'visible':'hidden'}}&quot;&gt; &lt;!-- 确认取消按钮 --&gt; &lt;view class='btn'&gt; &lt;text catchtap=&quot;cityCancel&quot;&gt;取消&lt;/text&gt; &lt;text style=&quot;float: right&quot; catchtap=&quot;citySure&quot;&gt;确定&lt;/text&gt; &lt;/view&gt; &lt;!-- 选择地址 --&gt; &lt;picker-view class='cont' bindchange=&quot;cityChange&quot; value=&quot;{{value}}&quot; wx:key=&quot;&quot;&gt; &lt;!-- 省 --&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{provinces}}&quot; class=&quot;picker-item&quot; wx:key=&quot;{{index}}&quot;&gt;{{item.area}}&lt;/view&gt; &lt;/picker-view-column&gt; &lt;!-- 市 --&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{citys}}&quot; class=&quot;picker-item&quot; wx:key=&quot;index&quot;&gt;{{item.area}}&lt;/view&gt; &lt;/picker-view-column&gt; &lt;!-- 区 --&gt; &lt;picker-view-column&gt; &lt;view wx:for=&quot;{{areas}}&quot; class=&quot;picker-item&quot; wx:key=&quot;index&quot;&gt;{{item.area}}&lt;/view&gt; &lt;/picker-view-column&gt; &lt;/picker-view&gt;&lt;/view&gt; addressAdd.wxss 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221page{ height: 100%; background: #f4f4f4;}.add-address .add-form{ background: #fff; width: 100%; height: auto; overflow: hidden;}.add-address .form-item{ height: 116rpx; padding-left: 31.25rpx; border-bottom: 1px solid #d9d9d9; display: flex; align-items: center; padding-right: 31.25rpx;}.add-address .input{ flex: 1; height: 44rpx; line-height: 44rpx; overflow: hidden;}.add-address .form-default{ border-bottom: 1px solid #d9d9d9; height: 96rpx; background: #fafafa; padding-top: 28rpx; font-size: 28rpx;}.default-input{ margin: 0 auto; display: block; width: 240rpx; height: 40rpx; padding-left: 50rpx; line-height: 40rpx; background: url(http://yanxuan.nosdn.127.net/hxm/yanxuan-wap/p/20161201/style/img/sprites/checkbox-sed825af9d3-a6b8540d42.png) 1rpx -448rpx no-repeat; background-size: 38rpx 486rpx; font-size: 28rpx;}.default-input.selected{ background: url(http://yanxuan.nosdn.127.net/hxm/yanxuan-wap/p/20161201/style/img/sprites/checkbox-sed825af9d3-a6b8540d42.png) 0 -192rpx no-repeat; background-size: 38rpx 486rpx;}.add-address .btns{ position: fixed; bottom: 0; left: 0; overflow: hidden; display: flex; height: 100rpx; width: 100%;}.add-address .cannel,.add-address .save{ flex: 1; height: 100rpx; text-align: center; line-height: 100rpx; font-size: 28rpx; color: #fff; border:none; border-radius: 0;}.add-address .cannel{ background: #3F3F3F;}.add-address .save{ background: #a78845;}.region-select{ width: 100%; height: 600rpx; background: #fff; position: fixed; z-index: 10; left:0; bottom: 0;}.region-select .hd{ height: 108rpx; width: 100%; border-bottom: 1px solid #f4f4f4; padding: 46rpx 30rpx 0 30rpx;}.region-select .region-selected{ float: left; height: 60rpx; display: flex;}.region-select .region-selected .item{ max-width: 140rpx; margin-right: 30rpx; text-align: left; line-height: 60rpx; height: 100%; color: #333; font-size: 28rpx; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;}.region-select .region-selected .item.disabled{ color: #999;}.region-select .region-selected .item.selected{ color: #a78845;}.region-select .done{ float: right; height: 60rpx; width: 60rpx; border: none; background: #fff; line-height: 60rpx; text-align: center; color: #333; font-size: 28rpx;}.region-select .done.disabled{ color: #999;}.region-select .bd{ height: 492rpx; width: 100%; padding: 0 30rpx;}.region-select .region-list{ height: 492rpx;}.region-select .region-list .item{ width: 100%; height: 104rpx; line-height: 104rpx; text-align: left; color: #333; font-size: 28rpx;}.region-select .region-list .item.selected{ color: #b4282d;}.bg-mask{ height: 100%; width: 100%; background: rgba(0, 0, 0, 0.4); position: fixed; top:0; left:0; z-index: 8;}.picker-view { width: 100%; display: flex; z-index:12; background-color: #fff; /* background: rgba(0, 0, 0, .2); */ flex-direction: column; justify-content: center; align-items: center; position: fixed; bottom: 0; left: 0rpx; height: 40vh;}.btn { width: 100%; height: 90rpx; padding: 0 24rpx; box-sizing: border-box; line-height: 90rpx; text-align: center; display: flex; background: rgba(255,255,255,.8); justify-content: space-between;}.cont { width: 100%; height: 389rpx;}.picker-item { line-height: 70rpx; margin-left: 5rpx; margin-right: 5rpx; text-align: center;}.address { width: 100%; height: 90rpx; line-height: 90rpx; text-align: center; border-bottom: 1rpx solid #f1f1f1;} addressAdd.js (分两个版本一个是动态获取的 就是选择的时候动态向后台获取内容 下方是动态获取的例子：) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363var util = require('../../../utils/util.js');var api = require('../../../config/api.js');var app = getApp();Page({ data: { addressId: 0, openSelectRegion: false, regionType: 1, selectRegionDone: false, szxqList: [], szxq: { id: &quot;&quot;, name: &quot;请选择小区&quot; }, szdsList: [], szds: { id: &quot;&quot;, name: &quot;&quot; }, fanghao: &quot;&quot;, animationAddressMenu: {}, addressMenuIsShow: false, value: [0, 0, 0], provinces: [], citys: [], areas: [], areaInfo: '', areaJson: {} }, bindinputMobile(event) { let address = this.data.address; address.mobile = event.detail.value; this.setData({ address: address }); }, bindinputName(event) { let address = this.data.address; address.name = event.detail.value; this.setData({ address: address }); }, bindinputAddress(event) { let address = this.data.address; address.address = event.detail.value; this.setData({ address: address }); }, bindIsDefault() { let address = this.data.address; address.isDefault = !address.isDefault; this.setData({ address: address }); }, getAddressDetail() { let that = this; // util.request(api.AddressDetail, { // id: that.data.addressId // }).then(function(res) { // if (res.errno === 0) { // if (res.data) { // that.setData({ // address: res.data // }); // } // } // }); }, wxChooseAddress() { let that = this; let address = this.data.address; // 用户已经同意小程序使用地址功能 wx.chooseAddress({ success: function(res) { address.provinceId = 99999; address.cityId = 88888; address.areaId = 77777; address.name = res.userName; address.mobile = res.telNumber; address.provinceName = res.provinceName; address.cityName = res.cityName; address.areaName = res.countyName; address.address = res.provinceName + res.cityName + res.countyName + res.detailInfo; that.setData({ address: address, }); } }); }, wxAddress() { let that = this; // 可以通过 wx.getSetting 先查询一下用户是否授权了 &quot;scope.address&quot; 这个 scope wx.getSetting({ success(res) { if (!res.authSetting['scope.address']) { wx.authorize({ scope: 'scope.address', success() { that.wxChooseAddress(); } }) } else { that.wxChooseAddress(); } } }) }, onLoad: function(options) { let that = this; // 页面初始化 options为页面跳转所带来的参数 console.log(options); if (options.id &amp;&amp; options.id != 0) { this.setData({ addressId: options.id }); this.getAddressDetail(); } else { that.wxAddress(); } }, onReady: function() { }, cancelAddress() { wx.navigateBack(); }, saveAddress() { console.log(this.data.address); let address = this.data.address; if (address.name == '') { util.showErrorToast('请输入姓名'); return false; } if (address.mobile == '') { util.showErrorToast('请输入手机号码'); return false; } if (address.areaId == 0) { util.showErrorToast('请输入省市区'); return false; } if (address.address == '') { util.showErrorToast('请输入详细地址'); return false; } let that = this; }, onShow: function() { // 获取所在栋数 var animation = wx.createAnimation({ duration: 500, timingFunction: 'linear', }) this.animation = animation const that = this // 获取所在地区 console.log() util.getAreaReq().then(provinces =&gt; { util.getAreaReq(provinces[0].code).then(citys =&gt; { util.getAreaReq(citys[0].code).then(areas =&gt; { that.setData({ provinces: provinces, citys: citys, areas: areas, areaJson: { provinces: { id: 40, name: &quot;广东省&quot; }, citys: { id: 4006, name: &quot;河源市&quot; }, areas: { id: 400602, name: &quot;源城区&quot; } } }) var areas = that.data.areaJson.areas.name == null ? &quot;&quot; : that.data.areaJson.areas.name var areaInfo = that.data.areaJson.provinces.name + '·' + that.data.areaJson.citys.name + '·' + areas that.setData({ areaInfo: areaInfo, }) }) }) }) }, // 点击所在地区弹出选择框 select: function(e) { // 如果已经显示，不在执行显示动画 if (this.data.addressMenuIsShow) { return false } else { // 执行显示动画 this.startAddressAnimation(true) } }, // 处理省市县联动逻辑 cityChange: function(e) { // console.log(this.data.provinces) var value = e.detail.value var provinces = this.data.provinces var citys = this.data.citys var areas = this.data.areas var provinceNum = value[0] var cityNum = value[1] var countyNum = value[2] var that = this; // console.log(provinces) // 如果省份选择项和之前不一样，表示滑动了省份，此时市默认是省的第一组数据， if (this.data.value[0] != provinceNum) { var id = provinces[provinceNum].id // console.log(citys[cityNum]) util.getAreaReq(provinces[provinceNum].code).then(citys =&gt; { util.getAreaReq(citys[0].code).then(areas =&gt; { this.setData({ value: [provinceNum, 0, 0], citys: citys, areas: areas, areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: citys[0].code, name: citys[0].area }, areas: { id: areas.length &gt; 0 ? areas[0].code : null, name: areas.length &gt; 0 ? areas[0].area : null, } } }) }) }) } else if (this.data.value[1] != cityNum) { // 滑动选择了第二项数据，即市，此时区显示省市对应的第一组数据 var id = citys[cityNum].id util.getAreaReq(citys[cityNum].code).then(areas =&gt; { this.setData({ value: [provinceNum, cityNum, 0], areas: areas, areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: citys[cityNum].code, name: citys[cityNum].area }, areas: { id: areas.length &gt; 0 ? areas[0].code : null, name: areas.length &gt; 0 ? areas[0].area : null, } } }) }) } else { // 滑动选择了区 this.setData({ value: [provinceNum, cityNum, countyNum], areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: citys[cityNum].code, name: citys[cityNum].area }, areas: { id: areas[countyNum].code, name: areas[countyNum].area } } }) // console.log(that.data.areaJson) } }, // 执行动画 startAddressAnimation: function(isShow) { if (isShow) { // vh是用来表示尺寸的单位，高度全屏是100vh this.animation.translateY(0 + 'vh').step() } else { this.animation.translateY(40 + 'vh').step() } this.setData({ animationAddressMenu: this.animation.export(), addressMenuIsShow: isShow, }) }, // 点击地区选择取消按钮 cityCancel: function(e) { this.startAddressAnimation(false) }, // 点击地区选择确定按钮 citySure: function(e) { var that = this var city = that.data.city var value = that.data.value this.startAddressAnimation(false) // console.log(that.data.areaJson) var areas = that.data.areaJson.areas.name == null ? &quot;&quot; : that.data.areaJson.areas.name // 将选择的城市信息显示到输入框 var areaInfo = that.data.areaJson.provinces.name + '·' + that.data.areaJson.citys.name + '·' + areas that.setData({ areaInfo: areaInfo, }) }, onHide: function() { // 页面隐藏 }, onUnload: function() { // 页面关闭 }}); 需要使用外部js（utils） 自己封装的一个工具 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384var api = require('../config/api.js');var app = getApp();var user = require('./user.js');/** * 封装微信的的request */function request(url, data = {}, method = &quot;GET&quot;) { return new Promise(function(resolve, reject) { user.checkLogin().then(res =&gt; { }).catch(() =&gt; { wx.switchTab({ url: '/pages/ucenter/index/index?show=true' }); }); wx.request({ url: url, data: data, method: method, header: { 'Content-Type': 'application/x-www-form-urlencoded', 'Cookie': &quot;token=&quot; + wx.getStorageSync('token') + &quot;;&quot; + wx.getStorageSync('sessionid'), 'X-Requested-With': &quot;XMLHttpRequest&quot; }, success: function(res) { if (res.statusCode == 400) { user.loginByWeixin().then(res =&gt; { app.globalData.hasLogin = true; }); wx.redirectTo({ url: '/pages/index/index' }); wx.showToast({ title: '已经重新登录', }) } if (res.header[&quot;Set-Cookie&quot;]) { wx.setStorageSync(&quot;sessionid&quot;, res.header[&quot;Set-Cookie&quot;]) } if (res.statusCode == 200) { if (res.data.errno == 501) { } else { resolve(res); } } else { reject(res); } }, fail: function(err) { reject(err) } }) });}function getAreaReq(id) { const that = this; return new Promise(function(resolve, reject) { that.request(&quot;****&quot;, JSON.stringify({ }), &quot;post&quot;).then(response =&gt; { console.log(response.data.rs_data) resolve(response.data.rs_data); }) })}module.exports = { request, getAreaReq }; 使用静态获取的时候。js如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384var util = require('../../../utils/util.js');var api = require('../../../config/api.js');var area = require('../../../config/area.js');var app = getApp();Page({ data: { address: { id: 0, provinceId: 0, cityId: 0, areaId: 0, address: '', name: '', mobile: '', isDefault: 0, provinceName: '', cityName: '', areaName: '' }, addressId: 0, openSelectRegion: false, regionType: 1, selectRegionDone: false, szxqList: [], szxq: { id: &quot;&quot;, name: &quot;请选择小区&quot; }, szdsList: [], szds: { id: &quot;&quot;, name: &quot;&quot; }, fanghao: &quot;&quot;, animationAddressMenu: {}, addressMenuIsShow: false, value: [0, 0, 0], provinces: [], citys: [], areas: [], areaInfo: '', areaJson: {} }, bindinputMobile(event) { let address = this.data.address; address.mobile = event.detail.value; this.setData({ address: address }); }, bindinputName(event) { let address = this.data.address; address.name = event.detail.value; this.setData({ address: address }); }, bindinputAddress(event) { let address = this.data.address; address.address = event.detail.value; this.setData({ address: address }); }, bindIsDefault() { let address = this.data.address; address.isDefault = !address.isDefault; this.setData({ address: address }); }, getAddressDetail() { let that = this; util.request(api.AddressDetail, { id: that.data.addressId }).then(function(res) { if (res.errno === 0) { if (res.data) { that.setData({ address: res.data }); } } }); }, wxChooseAddress() { let that = this; let address = this.data.address; // 用户已经同意小程序使用地址功能 wx.chooseAddress({ success: function(res) { address.provinceId = 99999; address.cityId = 88888; address.areaId = 77777; address.name = res.userName; address.mobile = res.telNumber; address.provinceName = res.provinceName; address.cityName = res.cityName; address.areaName = res.countyName; address.address = res.provinceName + res.cityName + res.countyName + res.detailInfo; that.setData({ address: address, }); } }); }, wxAddress() { let that = this; // 可以通过 wx.getSetting 先查询一下用户是否授权了 &quot;scope.address&quot; 这个 scope wx.getSetting({ success(res) { if (!res.authSetting['scope.address']) { wx.authorize({ scope: 'scope.address', success() { that.wxChooseAddress(); } }) } else { that.wxChooseAddress(); } } }) }, onLoad: function(options) { let that = this; // 页面初始化 options为页面跳转所带来的参数 console.log(options); if (options.id &amp;&amp; options.id != 0) { this.setData({ addressId: options.id }); this.getAddressDetail(); } else { that.wxAddress(); } }, onReady: function() { }, cancelAddress() { wx.navigateBack(); }, saveAddress() { console.log(this.data.address); let address = this.data.address; if (address.name == '') { util.showErrorToast('请输入姓名'); return false; } if (address.mobile == '') { util.showErrorToast('请输入手机号码'); return false; } if (address.areaId == 0) { util.showErrorToast('请输入省市区'); return false; } if (address.address == '') { util.showErrorToast('请输入详细地址'); return false; } if (!check.isValidPhone(address.mobile)) { util.showErrorToast('手机号不正确'); return false; } }, onShow: function() { // 获取所在栋数 var animation = wx.createAnimation({ duration: 500, timingFunction: 'linear', }) this.animation = animation util.request(&quot;https://www.xaibox.com/czbb/interface/dataInfo.php&quot;, JSON.stringify({ &quot;param_key&quot;: { &quot;info_mode&quot;: &quot;getcity_jd&quot; }, &quot;secret_key&quot;: &quot;047709aaa7df22205d818bf4c1707458&quot; }), &quot;post&quot;).then(response =&gt; { console.log(response) that.setData({ szxqList: response.data.rs_data }) that.setData({ szxq: response.data.data[0] }) that.setData({ szds: response.data.data[0]['buildingList']['0'] }) that.setData({ szdsList: response.data.data[0]['buildingList'] }) }) // 获取所在地区 that.setData({ provinces: areajs, citys: areajs[0].children, areas: areajs[0].children ? areajs[0].children[0].children : [], areaJson: { provinces: { id: 40, name: &quot;广东省&quot; }, citys: { id: 4006, name: &quot;河源市&quot; }, areas: { id: 400602, name: &quot;源城区&quot; } } }) var areas = that.data.areaJson.areas.name == null ? &quot;&quot; : that.data.areaJson.areas.name var areaInfo = that.data.areaJson.provinces.name + '·' + that.data.areaJson.citys.name + '·' + areas that.setData({ areaInfo: areaInfo, }) }, // 点击所在地区弹出选择框 select: function(e) { // 如果已经显示，不在执行显示动画 if (this.data.addressMenuIsShow) { return false } else { // 执行显示动画 this.startAddressAnimation(true) } }, // 处理省市县联动逻辑 cityChange: function(e) { // console.log(this.data.provinces) var value = e.detail.value var provinces = this.data.provinces var citys = this.data.citys var areas = this.data.areas var provinceNum = value[0] var cityNum = value[1] var countyNum = value[2] var that = this; // console.log(provinces) // 如果省份选择项和之前不一样，表示滑动了省份，此时市默认是省的第一组数据， if (this.data.value[0] != provinceNum) { var id = provinces[provinceNum].id // console.log(citys[cityNum]) this.setData({ value: [provinceNum, 0, 0], citys: provinces[provinceNum].children, areas: provinces[provinceNum].children ? provinces[provinceNum].children[0].children : [], areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: provinces[provinceNum].children[0].code, name: provinces[provinceNum].children[0].area }, areas: { id: citys[cityNum].children.length &gt; 0 ? citys[cityNum].children[0].code : null, name: citys[cityNum].children.length &gt; 0 ? citys[cityNum].children[0].area : null } } }) } else if (this.data.value[1] != cityNum) { // 滑动选择了第二项数据，即市，此时区显示省市对应的第一组数据 var id = citys[cityNum].id this.setData({ value: [provinceNum, cityNum, 0], areas: citys[cityNum].children, areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: citys[cityNum].code, name: citys[cityNum].area }, areas: { id: citys[cityNum].children.length &gt; 0 ? citys[cityNum].children[0].code : null, name: citys[cityNum].children.length &gt; 0 ? citys[cityNum].children[0].area : null } } }) } else { // 滑动选择了区 this.setData({ value: [provinceNum, cityNum, countyNum], areaJson: { provinces: { id: provinces[provinceNum].code, name: provinces[provinceNum].area }, citys: { id: citys[cityNum].code, name: citys[cityNum].area }, areas: { id: areas[countyNum].code, name: areas[countyNum].area } } }) // console.log(that.data.areaJson) } }, // 执行动画 startAddressAnimation: function(isShow) { if (isShow) { // vh是用来表示尺寸的单位，高度全屏是100vh this.animation.translateY(0 + 'vh').step() } else { this.animation.translateY(40 + 'vh').step() } this.setData({ animationAddressMenu: this.animation.export(), addressMenuIsShow: isShow, }) }, // 点击地区选择取消按钮 cityCancel: function(e) { this.startAddressAnimation(false) }, // 点击地区选择确定按钮 citySure: function(e) { var that = this var city = that.data.city var value = that.data.value this.startAddressAnimation(false) // console.log(that.data.areaJson) var areas = that.data.areaJson.areas.name == null ? &quot;&quot; : that.data.areaJson.areas.name // 将选择的城市信息显示到输入框 var areaInfo = that.data.areaJson.provinces.name + '·' + that.data.areaJson.citys.name + '·' + areas that.setData({ areaInfo: areaInfo, }) }, onHide: function() { // 页面隐藏 }, onUnload: function() { // 页面关闭 }}); 静态获取三级联动 的话则需要文件area.js点击下载","link":"/2019/04/23/%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%B8%89%E7%BA%A7%E8%81%94%E5%8A%A8/"},{"title":"Java基础知识","text":"1. 面向对象和面向过程的区别面向过程优点： 性能比面向对象高。因为类调用时需要实例化，开销比较大，比较消耗资源，所以当性能是最重要的考量因素的时候，比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发 缺点： 没有面向对象易维护、易复用、易扩展 面向对象优点： 易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护 缺点： 性能比面向过程低 2. Java 语言有哪些特点? 简单易学； 面向对象（封装，继承，多态）； 平台无关性（ Java 虚拟机实现平台无关性）； 可靠性； 安全性； 支持多线程（ C++ 语言没有内置的多线程机制，因此必须调用操作系统的多线程功能来进行多线程程序设计，而 Java 语言却提供了多线程支持）； 支持网络编程并且很方便（ Java 语言诞生本身就是为简化网络编程设计的，因此 Java 语言不仅支持网络编程而且很方便）； 编译与解释并存； 3. 关于 JVM JDK 和 JRE 最详细通俗的解答JVMJava虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。 什么是字节码?采用字节码的好处是什么? 在 Java 中，JVM可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java程序无须重新编译便可在多种不同操作系统的计算机上运行。 Java 程序从源代码到运行一般有下面3步： 我们需要格外注意的是 .class-&gt;机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT 编译器，而JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。 HotSpot采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是JIT所需要编译的部分。JVM会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9引入了一种新的编译模式AOT(Ahead of Time Compilation)，它是直接将字节码编译成机器码，这样就避免了JIT预热等各方面的开销。JDK支持分层编译和AOT协作使用。但是 ，AOT 编译器的编译质量是肯定比不上 JIT 编译器的。 总结：Java虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。 JDK 和 JREJDK是Java Development Kit，它是功能齐全的Java SDK。它拥有JRE所拥有的一切，还有编译器（javac）和工具（如javadoc和jdb）。它能够创建和编译程序。 JRE 是 Java运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java虚拟机（JVM），Java类库，java命令和其他的一些基础构件。但是，它不能用于创建新程序。 如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装JDK了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何Java开发，仍然需要安装JDK。例如，如果要使用JSP部署Web应用程序，那么从技术上讲，您只是在应用程序服务器中运行Java程序。那你为什么需要JDK呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。 4. Oracle JDK 和 OpenJDK 的对比可能在看这个问题之前很多人和我一样并没有接触和使用过 OpenJDK 。那么Oracle和OpenJDK之间是否存在重大差异？下面我通过收集到的一些资料，为你解答这个被很多人忽视的问题。 对于Java 7，没什么关键的地方。OpenJDK项目主要基于Sun捐赠的HotSpot源代码。此外，OpenJDK被选为Java 7的参考实现，由Oracle工程师维护。关于JVM，JDK，JRE和OpenJDK之间的区别，Oracle博客帖子在2012年有一个更详细的答案： 问：OpenJDK存储库中的源代码与用于构建Oracle JDK的代码之间有什么区别？ 答：非常接近 - 我们的Oracle JDK版本构建过程基于OpenJDK 7构建，只添加了几个部分，例如部署代码，其中包括Oracle的Java插件和Java WebStart的实现，以及一些封闭的源代码派对组件，如图形光栅化器，一些开源的第三方组件，如Rhino，以及一些零碎的东西，如附加文档或第三方字体。展望未来，我们的目的是开源Oracle JDK的所有部分，除了我们考虑商业功能的部分。 总结： Oracle JDK版本将每三年发布一次，而OpenJDK版本每三个月发布一次； OpenJDK 是一个参考模型并且是完全开源的，而Oracle JDK是OpenJDK的一个实现，并不是完全开源的； Oracle JDK 比 OpenJDK 更稳定。OpenJDK和Oracle JDK的代码几乎相同，但Oracle JDK有更多的类和一些错误修复。因此，如果您想开发企业/商业软件，我建议您选择Oracle JDK，因为它经过了彻底的测试和稳定。某些情况下，有些人提到在使用OpenJDK 可能会遇到了许多应用程序崩溃的问题，但是，只需切换到Oracle JDK就可以解决问题； 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能； Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本； Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 5. Java和C++的区别?我知道很多人没学过 C++，但是面试官就是没事喜欢拿咱们 Java 和 C++ 比呀！没办法！！！就算没学过C++，也要记下来！ 都是面向对象的语言，都支持封装、继承和多态 Java 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理机制，不需要程序员手动释放无用内存 6. 什么是 Java 程序的主类 应用程序和小程序的主类有何不同?一个程序中可以有多个类，但只能有一个类是主类。在 Java 应用程序中，这个主类是指包含 main（）方法的类。而在 Java 小程序中，这个主类是一个继承自系统类 JApplet 或 Applet 的子类。应用程序的主类不一定要求是 public 类，但小程序的主类要求必须是 public 类。主类是 Java 程序执行的入口点。 7. Java 应用程序与小程序之间有那些差别?简单说应用程序是从主线程启动(也就是 main() 方法)。applet 小程序没有main方法，主要是嵌在浏览器页面上运行(调用init()线程或者run()来启动)，嵌入浏览器这点跟 flash 的小游戏类似。 8. 字符型常量和字符串常量的区别? 形式上: 字符常量是单引号引起的一个字符; 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整型值( ASCII 值),可以参加表达式运算; 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占2个字节; 字符串常量占若干个字节(至少一个字符结束标志) (注意： char在Java中占两个字节) java编程思想第四版：2.2.2节 9. 构造器 Constructor 是否可被 override?在讲继承的时候我们就知道父类的私有属性和构造方法并不能被继承，所以 Constructor 也就不能被 override（重写）,但是可以 overload（重载）,所以你可以看到一个类中有多个构造函数的情况。 10. 重载和重写的区别重载： 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写： 发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为 private 则子类就不能重写该方法。 11. Java 面向对象编程三大特性: 封装 继承 多态封装封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 关于继承如下 3 点请记住： 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。（以后介绍）。 多态所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 12. String StringBuffer 和 StringBuilder 的区别是什么? String 为什么是不可变的?可变性 简单的来说：String 类中使用 final 关键字修饰字符数组来保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 StringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的，大家可以自行查阅源码。 AbstractStringBuilder.java 12345678abstract class AbstractStringBuilder implements Appendable, CharSequence { char[] value; int count; AbstractStringBuilder() { } AbstractStringBuilder(int capacity) { value = new char[capacity]; } 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结： 操作少量的数据: 适用String 单线程操作字符串缓冲区下操作大量数据: 适用StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用StringBuffer 13. 自动装箱与拆箱装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； 14. 在一个静态方法内调用一个非静态成员为什么是非法的?由于静态方法可以不通过对象进行调用，因此在静态方法里，不能调用其他非静态变量，也不可以访问非静态变量成员。 15. 在 Java 中定义一个不做事且没有参数的构造方法的作用Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super() 来调用父类中特定的构造方法，则编译时将发生错误，因为 Java 程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。 16. import java和javax有什么区别？刚开始的时候 JavaAPI 所必需的包是 java 开头的包，javax 当时只是扩展 API 包来使用。然而随着时间的推移，javax 逐渐地扩展成为 Java API 的组成部分。但是，将扩展从 javax 包移动到 java 包确实太麻烦了，最终会破坏一堆现有的代码。因此，最终决定 javax 包将成为标准API的一部分。 所以，实际上java和javax没有区别。这都是一个名字。 17. 接口和抽象类的区别是什么？ 接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。 接口中除了static、final变量，不能有其他变量，而抽象类中则不一定。 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过extends关键字扩展多个接口。 接口方法默认修饰符是public，抽象方法可以有public、protected和default这些修饰符（抽象方法就是为了被重写所以不能使用private关键字修饰！）。 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。 备注：在JDK8中，接口也可以定义静态方法，可以直接用接口名调用。实现类和实现是不可以调用的。如果同时实现两个接口，接口中定义了一样的默认方法，则必须重写，不然会报错。(详见issue:https://github.com/Snailclimb/JavaGuide/issues/146) 18. 成员变量与局部变量的区别有那些？ 从语法形式上看:成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰。 从变量在内存中的存储方式来看:如果成员变量是使用static修饰的，那么这个成员变量是属于类的，如果没有使用static修饰，这个成员变量是属于实例的。而对象存在于堆内存，局部变量则存在于栈内存。 从变量在内存中的生存时间上看:成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。 成员变量如果没有被赋初值:则会自动以类型的默认值而赋值（一种情况例外被 final 修饰的成员变量也必须显示地赋值），而局部变量则不会自动赋值。 19. 创建一个对象用什么运算符?对象实体与对象引用有何不同?new运算符，new创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。一个对象引用可以指向0个或1个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有n个引用指向它（可以用n条绳子系住一个气球）。 20. 什么是方法的返回值?返回值在类的方法里的作用是什么?方法的返回值是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用:接收出结果，使得它可以用于其他的操作！ 21. 一个类的构造方法的作用是什么? 若一个类没有声明构造方法，该程序能正确执行吗? 为什么?主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。 22. 构造方法有哪些特性？ 名字与类名相同。 没有返回值，但不能用void声明构造函数。 生成类的对象时自动执行，无需调用。 23. 静态方法和实例方法有何不同 在外部调用静态方法时，可以使用”类名.方法名”的方式，也可以使用”对象名.方法名”的方式。而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象。 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），而不允许访问实例成员变量和实例方法；实例方法则无此限制。 24. 对象的相等与指向他们的引用相等,两者有什么不同?对象的相等，比的是内存中存放的内容是否相等。而引用相等，比较的是他们指向的内存地址是否相等。 25. 在调用子类构造方法之前会先调用父类没有参数的构造方法,其目的是?帮助子类做初始化工作。 26. == 与 equals(重要)== : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象(基本数据类型==比较的是值，引用数据类型==比较的是内存地址)。 equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个例子： 1234567891011121314151617public class test1 { public static void main(String[] args) { String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) { // true System.out.println(&quot;true&quot;); } }} 说明： String 中的 equals 方法是被重写过的，因为 object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。 当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。 27. hashCode 与 equals (重要)面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？” hashCode（）介绍hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有 hashCode我们先以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head first java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 通过我们可以看出：hashCode() 的作用就是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。**hashCode() 在散列表中才有用，在其它情况下没用。**在散列表中hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。 hashCode（）与equals（）的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 推荐阅读：Java hashCode() 和 equals()的若干问题解答 28. 为什么Java中只有值传递？ 为什么Java中只有值传递？ 29. 简述线程、程序、进程的基本概念。以及他们之间关系是什么?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。 30. 线程有哪些基本状态?Java 线程在运行的生命周期中的指定时刻只可能处于下面6种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4节）。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4节）： 由上图可以看出： 线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 RUNNING（运行） 状态。 操作系统隐藏 Java虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。 当线程执行 wait()方法之后，线程进入 WAITING（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。 31 关于 final 关键字的一些总结final关键字主要用在三个地方：变量、方法、类。 对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 当用final修饰一个类时，表明这个类不能被继承。final类中的所有成员方法都会被隐式地指定为final方法。 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现在的Java版本已经不需要使用final方法进行这些优化了）。类中所有的private方法都隐式地指定为final。 32 Java 中的异常处理Java异常类层次结构图 在 Java 中，所有的异常都有一个共同的祖先java.lang包中的 Throwable类。Throwable： 有两个重要的子类：Exception（异常） 和 Error（错误） ，二者都是 Java 异常处理的重要子类，各自都包含大量子类。 Error（错误）:是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。 这些错误表示故障发生于虚拟机自身、或者发生在虚拟机试图执行应用时，如Java虚拟机运行错误（Virtual MachineError）、类定义错误（NoClassDefFoundError）等。这些错误是不可查的，因为它们在应用程序的控制和处理能力之 外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在 Java中，错误通过Error的子类描述。 Exception（异常）:是程序本身可以处理的异常。Exception 类有一个重要的子类 RuntimeException。RuntimeException 异常由Java虚拟机抛出。NullPointerException（要访问的变量没有引用任何对象时，抛出该异常）、ArithmeticException（算术运算异常，一个整数除以0时，抛出该异常）和 ArrayIndexOutOfBoundsException （下标越界异常）。 注意：异常和错误的区别：异常能被程序本身可以处理，错误是无法处理。 Throwable类常用方法 public string getMessage():返回异常发生时的详细信息 public string toString():返回异常发生时的简要描述 public string getLocalizedMessage():返回异常对象的本地化信息。使用Throwable的子类覆盖这个方法，可以声称本地化信息。如果子类没有覆盖该方法，则该方法返回的信息与getMessage（）返回的结果相同 public void printStackTrace():在控制台上打印Throwable对象封装的异常信息 异常处理总结 try 块：用于捕获异常。其后可接零个或多个catch块，如果没有catch块，则必须跟一个finally块。 catch 块：用于处理try捕获到的异常。 finally 块：无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。 在以下4种特殊情况下，finally块不会被执行： 在finally语句块第一行发生了异常。 因为在其他行，finally块还是会得到执行 在前面的代码中用了System.exit(int)已退出程序。 exit是带参函数 ；若该语句在异常语句之后，finally会执行 程序所在的线程死亡。 关闭CPU。 下面这部分内容来自issue:https://github.com/Snailclimb/JavaGuide/issues/190。 关于返回值： 如果try语句里有return，返回的是try语句块中变量值。详细执行过程如下： 如果有返回值，就把返回值保存到局部变量中； 执行jsr指令跳到finally语句里执行； 执行完finally语句后，返回之前保存在局部变量表里的值。 如果try，finally语句里均有return，忽略try的return，而使用finally的return. 33 Java序列化中如果有些字段不想进行序列化，怎么办？对于不想进行序列化的变量，使用transient关键字修饰。 transient关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。 34 获取用键盘输入常用的的两种方法方法1：通过 Scanner 123Scanner input = new Scanner(System.in);String s = input.nextLine();input.close(); 方法2：通过 BufferedReader 12BufferedReader input = new BufferedReader(new InputStreamReader(System.in)); String s = input.readLine(); 35 Java 中 IO 流分为几种?BIO,NIO,AIO 有什么区别?java 中 IO 流分为几种? 按照流的流向分，可以分为输入流和输出流； 按照操作单元划分，可以划分为字节流和字符流； 按照流的角色划分为节点流和处理流。 Java Io流共涉及40多个类，这些类看上去很杂乱，但实际上很有规则，而且彼此之间存在非常紧密的联系， Java I0流的40多个类都是从如下4个抽象类基类中派生出来的。 InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 按操作方式分类结构图： 按操作对象分类结构图 BIO,NIO,AIO 有什么区别? BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (New I/O): NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发 AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。 36. 常见关键字总结:static,final,this,super详见笔主的这篇文章: https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Basis/final、static、this、super.md 37. Collections 工具类和 Arrays 工具类常见方法总结详见笔主的这篇文章: https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Basis/Arrays,CollectionsCommonMethods.md 参考 https://stackoverflow.com/questions/1906445/what-is-the-difference-between-jdk-and-jre https://www.educba.com/oracle-vs-openjdk/ https://stackoverflow.com/questions/22358071/differences-between-oracle-jdk-and-openjdk?answertab=active#tab-top","link":"/2019/05/22/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"最全最全的Nginx解读文章","text":"Nginx 概述Nginx 是开源、高性能、高可靠的 Web 和反向代理服务器，而且支持热部署，几乎可以做到 7 * 24 小时不间断运行，即使运行几个月也不需要重新启动，还能在不间断服务的情况下对软件版本进行热更新。性能是 Nginx 最重要的考量，其占用内存少、并发能力强、能支持高达 5w 个并发连接数，最重要的是， Nginx 是免费的并可以商业化，配置使用也比较简单。 Nginx 特点 高并发、高性能； 模块化架构使得它的扩展性非常好； 异步非阻塞的事件驱动模型这点和 Node.js 相似； 相对于其它服务器来说它可以连续几个月甚至更长而不需要重启服务器使得它具有高可靠性； 热部署、平滑升级； 完全开源，生态繁荣； Nginx 作用Nginx 的最重要的几个使用场景： 静态资源服务，通过本地文件系统提供服务； 反向代理服务，延伸出包括缓存、负载均衡等； API 服务， OpenResty ； 对于前端来说 Node.js 并不陌生， Nginx 和 Node.js 的很多理念类似， HTTP 服务器、事件驱动、异步非阻塞等，且 Nginx 的大部分功能使用 Node.js 也可以实现，但 Nginx 和 Node.js 并不冲突，都有自己擅长的领域。 Nginx 擅长于底层服务器端资源的处理（静态资源处理转发、反向代理，负载均衡等）， Node.js 更擅长上层具体业务逻辑的处理，两者可以完美组合。 用一张图表示： Nginx 安装本文演示的是 Linux centOS 7.x 的操作系统上安装 Nginx ，至于在其它操作系统上进行安装可以网上自行搜索，都非常简单的。 使用 yum 安装 Nginx ： 12yum install nginx -y 安装完成后，通过 rpm -ql nginx 命令查看 Nginx 的安装信息： 123456789101112131415161718192021222324252627# Nginx配置文件/etc/nginx/nginx.conf # nginx 主配置文件/etc/nginx/nginx.conf.default# 可执行程序文件/usr/bin/nginx-upgrade/usr/sbin/nginx# nginx库文件/usr/lib/systemd/system/nginx.service # 用于配置系统守护进程/usr/lib64/nginx/modules # Nginx模块目录# 帮助文档/usr/share/doc/nginx-1.16.1/usr/share/doc/nginx-1.16.1/CHANGES/usr/share/doc/nginx-1.16.1/README/usr/share/doc/nginx-1.16.1/README.dynamic/usr/share/doc/nginx-1.16.1/UPGRADE-NOTES-1.6-to-1.10# 静态资源目录/usr/share/nginx/html/404.html/usr/share/nginx/html/50x.html/usr/share/nginx/html/index.html# 存放Nginx日志文件/var/log/nginx 主要关注的文件夹有两个： /etc/nginx/conf.d/ 是子配置项存放处， /etc/nginx/nginx.conf 主配置文件会默认把这个文件夹中所有子配置项都引入； /usr/share/nginx/html/ 静态文件都放在这个文件夹，也可以根据你自己的习惯放在其他地方； Nginx 常用命令systemctl 系统命令： 12345678910111213141516171819202122232425# 开机配置systemctl enable nginx # 开机自动启动systemctl disable nginx # 关闭开机自动启动# 启动Nginxsystemctl start nginx # 启动Nginx成功后，可以直接访问主机IP，此时会展示Nginx默认页面# 停止Nginxsystemctl stop nginx# 重启Nginxsystemctl restart nginx# 重新加载Nginxsystemctl reload nginx# 查看 Nginx 运行状态systemctl status nginx# 查看Nginx进程ps -ef | grep nginx# 杀死Nginx进程kill -9 pid # 根据上面查看到的Nginx进程号，杀死Nginx进程，-9 表示强制结束进程 Nginx 应用程序命令： 1234567nginx -s reload # 向主进程发送信号，重新加载配置文件，热重启nginx -s reopen # 重启 Nginxnginx -s stop # 快速关闭nginx -s quit # 等待工作进程处理完成后关闭nginx -T # 查看当前 Nginx 最终的配置nginx -t # 检查配置是否有问题 Nginx 核心配置配置文件结构 main 全局配置，对全局生效； events 配置影响 Nginx 服务器与用户的网络连接； http 配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置； server 配置虚拟主机的相关参数，一个 http 块中可以有多个 server 块； location 用于配置匹配的 uri ； upstream 配置后端服务器具体地址，负载均衡配置不可或缺的部分； 用一张图清晰的展示它的层级结构： 配置文件 main 段核心参数user指定运行 Nginx 的 woker 子进程的属主和属组，其中组可以不指定。 1234user USERNAME [GROUP]user nginx lion; # 用户是nginx;组是lion pid指定运行 Nginx master 主进程的 pid 文件存放路径。 12pid /opt/nginx/logs/nginx.pid # master主进程的的pid存放在nginx.pid的文件 worker_rlimit_nofile_number指定 worker 子进程可以打开的最大文件句柄数。 12worker_rlimit_nofile 20480; # 可以理解成每个worker子进程的最大连接数量。 worker_rlimit_core指定 worker 子进程异常终止后的 core 文件，用于记录分析问题。 123worker_rlimit_core 50M; # 存放大小限制working_directory /opt/nginx/tmp; # 存放目录 worker_processes_number指定 Nginx 启动的 worker 子进程数量。 123worker_processes 4; # 指定具体子进程数量worker_processes auto; # 与当前cpu物理核心数一致 worker_cpu_affinity将每个 worker 子进程与我们的 cpu 物理核心绑定。 1worker_cpu_affinity 0001 0010 0100 1000; # 4个物理核心，4个worker子进程 将每个 worker 子进程与特定 CPU 物理核心绑定，优势在于，避免同一个 worker 子进程在不同的 CPU 核心上切换，缓存失效，降低性能。但其并不能真正的避免进程切换。 worker_priority指定 worker 子进程的 nice 值，以调整运行 Nginx 的优先级，通常设定为负值，以优先调用 Nginx 。 12worker_priority -10; # 120-10=110，110就是最终的优先级 Linux 默认进程的优先级值是120，值越小越优先； nice 定范围为 -20 到 +19 。 [备注] 应用的默认优先级值是120加上 nice 值等于它最终的值，这个值越小，优先级越高。 worker_shutdown_timeout指定 worker 子进程优雅退出时的超时时间。 12worker_shutdown_timeout 5s; timer_resolutionworker 子进程内部使用的计时器精度，调整时间间隔越大，系统调用越少，有利于性能提升；反之，系统调用越多，性能下降。 12timer_resolution 100ms; 在 Linux 系统中，用户需要获取计时器时需要向操作系统内核发送请求，有请求就必然会有开销，因此这个间隔越大开销就越小。 daemon指定 Nginx 的运行方式，前台还是后台，前台用于调试，后台用于生产。 12daemon off; # 默认是on，后台运行模式 配置文件 events 段核心参数useNginx 使用何种事件驱动模型。 1234use method; # 不推荐配置它，让nginx自己选择method 可选值为：select、poll、kqueue、epoll、/dev/poll、eventport worker_connectionsworker 子进程能够处理的最大并发连接数。 12worker_connections 1024 # 每个子进程的最大连接数为1024 accept_mutex是否打开负载均衡互斥锁。 12accept_mutex on # 默认是off关闭的，这里推荐打开 server_name 指令指定虚拟主机域名。 12345server_name name1 name2 name3# 示例：server_name www.nginx.com; 域名匹配的四种写法： 精确匹配： server_name www.nginx.com ; 左侧通配： server_name *.nginx.com ; 右侧统配： server_name www.nginx.* ; 正则匹配： server_name ~^www\\.nginx\\.*$ ; 匹配优先级：精确匹配 &gt; 左侧通配符匹配 &gt; 右侧通配符匹配 &gt; 正则表达式匹配 server_name 配置实例： 1、配置本地 DNS 解析 vim /etc/hosts （ macOS 系统） 12345678# 添加如下内容，其中 121.42.11.34 是阿里云服务器IP地址121.42.11.34 www.nginx-test.com121.42.11.34 mail.nginx-test.com121.42.11.34 www.nginx-test.org121.42.11.34 doc.nginx-test.com121.42.11.34 www.nginx-test.cn121.42.11.34 fe.nginx-test.club [注意] 这里使用的是虚拟域名进行测试，因此需要配置本地 DNS 解析，如果使用阿里云上购买的域名，则需要在阿里云上设置好域名解析。 2、配置阿里云 Nginx ，vim /etc/nginx/nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839404142# 这里只列举了http端中的sever端配置# 左匹配server { listen 80; server_name *.nginx-test.com; root /usr/share/nginx/html/nginx-test/left-match/; location / { index index.html; }}# 正则匹配server { listen 80; server_name ~^.*\\.nginx-test\\..*$; root /usr/share/nginx/html/nginx-test/reg-match/; location / { index index.html; }}# 右匹配server { listen 80; server_name www.nginx-test.*; root /usr/share/nginx/html/nginx-test/right-match/; location / { index index.html; }}# 完全匹配server { listen 80; server_name www.nginx-test.com; root /usr/share/nginx/html/nginx-test/all-match/; location / { index index.html; }} 3、访问分析 当访问 www.nginx-test.com 时，都可以被匹配上，因此选择优先级最高的“完全匹配”； 当访问 mail.nginx-test.com 时，会进行“左匹配”； 当访问 www.nginx-test.org 时，会进行“右匹配”； 当访问 doc.nginx-test.com 时，会进行“左匹配”； 当访问 www.nginx-test.cn 时，会进行“右匹配”； 当访问 fe.nginx-test.club 时，会进行“正则匹配”； root指定静态资源目录位置，它可以写在 http 、 server 、 location 等配置中。 123456789root path例如：location /image { root /opt/nginx/static;}当用户访问 www.test.com/image/1.png 时，实际在服务器找的路径是 /opt/nginx/static/image/1.png [注意] root 会将定义路径与 URI 叠加， alias 则只取定义路径。 alias它也是指定静态资源目录位置，它只能写在 location 中。 123456location /image { alias /opt/nginx/static/image/;}当用户访问 www.test.com/image/1.png 时，实际在服务器找的路径是 /opt/nginx/static/image/1.png [注意] 使用 alias 末尾一定要添加 / ，并且它只能位于 location 中。 location配置路径。 1234location [ = | ~ | ~* | ^~ ] uri { ...} 匹配规则： = 精确匹配； ~ 正则匹配，区分大小写； ~* 正则匹配，不区分大小写； ^~ 匹配到即停止搜索； 匹配优先级： = &gt; ^~ &gt; ~ &gt; ~* &gt; 不带任何字符。 实例： 12345678910111213141516171819202122server { listen 80; server_name www.nginx-test.com; # 只有当访问 www.nginx-test.com/match_all/ 时才会匹配到/usr/share/nginx/html/match_all/index.html location = /match_all/ { root /usr/share/nginx/html index index.html } # 当访问 www.nginx-test.com/1.jpg 等路径时会去 /usr/share/nginx/images/1.jpg 找对应的资源 location ~ \\.(jpeg|jpg|png|svg)$ { root /usr/share/nginx/images; } # 当访问 www.nginx-test.com/bbs/ 时会匹配上 /usr/share/nginx/html/bbs/index.html location ^~ /bbs/ { root /usr/share/nginx/html; index index.html index.htm; }} location 中的反斜线12345678location /test { ...}location /test/ { ...} 不带 / 当访问 www.nginx-test.com/test 时， Nginx 先找是否有 test 目录，如果有则找 test 目录下的 index.html ；如果没有 test 目录， nginx 则会找是否有 test 文件。 带 / 当访问 www.nginx-test.com/test 时， Nginx 先找是否有 test 目录，如果有则找 test 目录下的 index.html ，如果没有它也不会去找是否存在 test 文件。 return停止处理请求，直接返回响应码或重定向到其他 URL ；执行 return 指令后， location 中后续指令将不会被执行。 123456789101112131415161718192021return code [text];return code URL;return URL;例如：location / { return 404; # 直接返回状态码}location / { return 404 &quot;pages not found&quot;; # 返回状态码 + 一段文本}location / { return 302 /bbs ; # 返回状态码 + 重定向地址}location / { return https://www.baidu.com ; # 返回重定向地址} rewrite根据指定正则表达式匹配规则，重写 URL 。 123456语法：rewrite 正则表达式 要替换的内容 [flag];上下文：server、location、if示例：rewirte /images/(.*\\.jpg)$ /pic/$1; # $1是前面括号(.*\\.jpg)的反向引用 flag 可选值的含义： last 重写后的 URL 发起新请求，再次进入 server 段，重试 location 的中的匹配； break 直接使用重写后的 URL ，不再匹配其它 location 中语句； redirect 返回302临时重定向； permanent 返回301永久重定向； 123456789101112131415161718192021server{ listen 80; server_name fe.lion.club; # 要在本地hosts文件进行配置 root html; location /search { rewrite ^/(.*) https://www.baidu.com redirect; } location /images { rewrite /images/(.*) /pics/$1; } location /pics { rewrite /pics/(.*) /photos/$1; } location /photos { }} 按照这个配置我们来分析： 当访问 fe.lion.club/search 时，会自动帮我们重定向到 https://www.baidu.com。 当访问 fe.lion.club/images/1.jpg 时，第一步重写 URL 为 fe.lion.club/pics/1.jpg ，找到 pics 的 location ，继续重写 URL 为 fe.lion.club/photos/1.jpg ，找到 /photos 的 location 后，去 html/photos 目录下寻找 1.jpg 静态资源。 if 指令123456789语法：if (condition) {...}上下文：server、location示例：if($http_user_agent ~ Chrome){ rewrite /(.*)/browser/$1 break;} condition 判断条件： $variable 仅为变量时，值为空或以0开头字符串都会被当做 false 处理； = 或 != 相等或不等； ~ 正则匹配； ! ~ 非正则匹配； ~* 正则匹配，不区分大小写； -f 或 ! -f 检测文件存在或不存在； -d 或 ! -d 检测目录存在或不存在； -e 或 ! -e 检测文件、目录、符号链接等存在或不存在； -x 或 ! -x 检测文件可以执行或不可执行； 实例： 123456789101112server { listen 8080; server_name localhost; root html; location / { if ( $uri = &quot;/images/&quot; ){ rewrite (.*) /pics/ break; } }} 当访问 localhost:8080/images/ 时，会进入 if 判断里面执行 rewrite 命令。 autoindex用户请求以 / 结尾时，列出目录结构，可以用于快速搭建静态资源下载网站。 autoindex.conf 配置信息： 1234567891011121314server { listen 80; server_name fe.lion-test.club; location /download/ { root /opt/source; autoindex on; # 打开 autoindex，，可选参数有 on | off autoindex_exact_size on; # 修改为off，以KB、MB、GB显示文件大小，默认为on，以bytes显示出⽂件的确切⼤⼩ autoindex_format html; # 以html的方式进行格式化，可选参数有 html | json | xml autoindex_localtime off; # 显示的⽂件时间为⽂件的服务器时间。默认为off，显示的⽂件时间为GMT时间 }} 当访问 fe.lion.com/download/ 时，会把服务器 /opt/source/download/ 路径下的文件展示出来，如下图所示： 变量Nginx 提供给使用者的变量非常多，但是终究是一个完整的请求过程所产生数据， Nginx 将这些数据以变量的形式提供给使用者。 下面列举些项目中常用的变量： 变量名 含义 remote_addr 客户端 IP 地址 remote_port 客户端端口 server_addr 服务端 IP 地址 server_port 服务端端口 server_protocol 服务端协议 binary_remote_addr 二进制格式的客户端 IP 地址 connection TCP 连接的序号，递增 connection_request TCP 连接当前的请求数量 uri 请求的URL，不包含参数 request_uri 请求的URL，包含参数 scheme 协议名， http 或 https request_method 请求方法 request_length 全部请求的长度，包含请求行、请求头、请求体 args 全部参数字符串 arg_参数名 获取特定参数值 is_args URL 中是否有参数，有的话返回 ? ，否则返回空 query_string 与 args 相同 host 请求信息中的 Host ，如果请求中没有 Host 行，则在请求头中找，最后使用 nginx 中设置的 server_name 。 http_user_agent 用户浏览器 http_referer 从哪些链接过来的请求 http_via 每经过一层代理服务器，都会添加相应的信息 http_cookie 获取用户 cookie request_time 处理请求已消耗的时间 https 是否开启了 https ，是则返回 on ，否则返回空 request_filename 磁盘文件系统待访问文件的完整路径 document_root 由 URI 和 root/alias 规则生成的文件夹路径 limit_rate 返回响应时的速度上限值 实例演示 var.conf ： 12345678910111213141516171819202122232425262728293031323334server{ listen 8081; server_name var.lion-test.club; root /usr/share/nginx/html; location / { return 200 &quot;remote_addr: $remote_addrremote_port: $remote_portserver_addr: $server_addrserver_port: $server_portserver_protocol: $server_protocolbinary_remote_addr: $binary_remote_addrconnection: $connectionuri: $urirequest_uri: $request_urischeme: $schemerequest_method: $request_methodrequest_length: $request_lengthargs: $argsarg_pid: $arg_pidis_args: $is_argsquery_string: $query_stringhost: $hosthttp_user_agent: $http_user_agenthttp_referer: $http_refererhttp_via: $http_viarequest_time: $request_timehttps: $httpsrequest_filename: $request_filenamedocument_root: $document_root&quot;; }} 当我们访问 http://var.lion-test.club:8081/test?pid=121414&amp;cid=sadasd 时，由于 Nginx 中写了 return 方法，因此 chrome 浏览器会默认为我们下载一个文件，下面展示的就是下载的文件内容： 12345678910111213141516171819202122232425remote_addr: 27.16.220.84remote_port: 56838server_addr: 172.17.0.2server_port: 8081server_protocol: HTTP/1.1binary_remote_addr: \u001b\u0010茉connection: 126uri: /test/request_uri: /test/?pid=121414&amp;cid=sadasdscheme: httprequest_method: GETrequest_length: 518args: pid=121414&amp;cid=sadasdarg_pid: 121414is_args: ?query_string: pid=121414&amp;cid=sadasdhost: var.lion-test.clubhttp_user_agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36http_referer: http_via: request_time: 0.000https: request_filename: /usr/share/nginx/html/test/document_root: /usr/share/nginx/html Nginx 的配置还有非常多，以上只是罗列了一些常用的配置，在实际项目中还是要学会查阅文档。 Nginx 应用核心概念代理是在服务器和客户端之间假设的一层服务器，代理将接收客户端的请求并将它转发给服务器，然后将服务端的响应转发给客户端。 不管是正向代理还是反向代理，实现的都是上面的功能。 正向代理 正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。 正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。 正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。 反向代理 反向代理*（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。 反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。 反向代理的优势： 隐藏真实服务器； 负载均衡便于横向扩充后端动态服务； 动静分离，提升系统健壮性； 那么“动静分离”是什么？负载均衡又是什么？ 动静分离动静分离是指在 web 服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提示整个服务的访问性和可维护性。 一般来说，都需要将动态资源和静态资源分开，由于 Nginx 的高并发和静态资源缓存等特性，经常将静态资源部署在 Nginx 上。如果请求的是静态资源，直接到静态资源目录获取资源，如果是动态资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。 使用前后端分离后，可以很大程度提升静态资源的访问速度，即使动态服务不可用，静态资源的访问也不会受到影响。 负载均衡一般情况下，客户端发送多个请求到服务器，服务器处理请求，其中一部分可能要操作一些资源比如数据库、静态资源等，服务器处理完毕后，再将结果返回给客户端。 这种模式对于早期的系统来说，功能要求不复杂，且并发请求相对较少的情况下还能胜任，成本也低。随着信息数量不断增长，访问量和数据量飞速增长，以及系统业务复杂度持续增加，这种做法已无法满足要求，并发量特别大时，服务器容易崩。 很明显这是由于服务器性能的瓶颈造成的问题，除了堆机器之外，最重要的做法就是负载均衡。 请求爆发式增长的情况下，单个机器性能再强劲也无法满足要求了，这个时候集群的概念产生了，单个服务器解决不了的问题，可以使用多个服务器，然后将请求分发到各个服务器上，将负载分发到不同的服务器，这就是负载均衡，核心是「分摊压力」。 Nginx 实现负载均衡，一般来说指的是将请求转发给服务器集群。 举个具体的例子，晚高峰乘坐地铁的时候，入站口经常会有地铁工作人员大喇叭“请走 B 口， B 口人少车空….”，这个工作人员的作用就是负载均衡。 Nginx 实现负载均衡的策略： 轮询策略：默认情况下采用的策略，将所有客户端请求轮询分配给服务端。这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 最小连接数策略：将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求。 最快响应时间策略：优先分配给响应时间最短的服务器。 客户端 ip 绑定策略：来自同一个 ip 的请求永远只分配一台服务器，有效解决了动态网页存在的 session 共享问题。 Nginx 实战配置在配置反向代理和负载均衡等等功能之前，有两个核心模块是我们必须要掌握的，这两个模块应该说是 Nginx 应用配置中的核心，它们分别是： upstream 、proxy_pass 。 upstream用于定义上游服务器（指的就是后台提供的应用服务器）的相关信息。 1234567891011语法：upstream name { ...}上下文：http示例：upstream back_end_server{ server 192.168.100.33:8081} 在 upstream 内可使用的指令： server 定义上游服务器地址； zone 定义共享内存，用于跨 worker 子进程； keepalive 对上游服务启用长连接； keepalive_requests 一个长连接最多请求 HTTP 的个数； keepalive_timeout 空闲情形下，一个长连接的超时时长； hash 哈希负载均衡算法； ip_hash 依据 IP 进行哈希计算的负载均衡算法； least_conn 最少连接数负载均衡算法； least_time 最短响应时间负载均衡算法； random 随机负载均衡算法； server定义上游服务器地址。 1234语法：server address [parameters]上下文：upstream parameters 可选值： weight=number 权重值，默认为1； max_conns=number 上游服务器的最大并发连接数； fail_timeout=time 服务器不可用的判定时间； max_fails=numer 服务器不可用的检查次数； backup 备份服务器，仅当其他服务器都不可用时才会启用； down 标记服务器长期不可用，离线维护； keepalive限制每个 worker 子进程与上游服务器空闲长连接的最大数量。 123456keepalive connections;上下文：upstream示例：keepalive 16; keepalive_requests单个长连接可以处理的最多 HTTP 请求个数。 123456语法：keepalive_requests number;默认值：keepalive_requests 100;上下文：upstream keepalive_timeout空闲长连接的最长保持时间。 123456语法：keepalive_timeout time;默认值：keepalive_timeout 60s;上下文：upstream 配置实例1234567upstream back_end{ server 127.0.0.1:8081 weight=3 max_conns=1000 fail_timeout=10s max_fails=2; keepalive 32; keepalive_requests 50; keepalive_timeout 30s;} proxy_pass用于配置代理服务器。 12345678语法：proxy_pass URL;上下文：location、if、limit_except示例：proxy_pass http://127.0.0.1:8081proxy_pass http://127.0.0.1:8081/proxy URL 参数原则 URL 必须以 http 或 https 开头； URL 中可以携带变量； URL 中是否带 URI ，会直接影响发往上游请求的 URL ； 接下来让我们来看看两种常见的 URL 用法： proxy_pass http://192.168.100.33:8081 proxy_pass http://192.168.100.33:8081/ 这两种用法的区别就是带 / 和不带 / ，在配置代理时它们的区别可大了： 不带 / 意味着 Nginx 不会修改用户 URL ，而是直接透传给上游的应用服务器； 带 / 意味着 Nginx 会修改用户 URL ，修改方法是将 location 后的 URL 从用户 URL 中删除； 不带 / 的用法： 1234location /bbs/{ proxy_pass http://127.0.0.1:8080;} 分析： 用户请求 URL ： /bbs/abc/test.html 请求到达 Nginx 的 URL ： /bbs/abc/test.html 请求到达上游应用服务器的 URL ： /bbs/abc/test.html 带 / 的用法： 1234location /bbs/{ proxy_pass http://127.0.0.1:8080/;} 分析： 用户请求 URL ： /bbs/abc/test.html 请求到达 Nginx 的 URL ： /bbs/abc/test.html 请求到达上游应用服务器的 URL ： /abc/test.html 并没有拼接上 /bbs ，这点和 root 与 alias 之间的区别是保持一致的。 配置反向代理这里为了演示更加接近实际，作者准备了两台云服务器，它们的公网 IP 分别是： 121.42.11.34 与 121.5.180.193 。 我们把 121.42.11.34 服务器作为上游服务器，做如下配置： 1234567891011121314# /etc/nginx/conf.d/proxy.confserver{ listen 8080; server_name localhost; location /proxy/ { root /usr/share/nginx/html/proxy; index index.html; }}# /usr/share/nginx/html/proxy/index.html&lt;h1&gt; 121.42.11.34 proxy html &lt;/h1&gt; 配置完成后重启 Nginx 服务器 nginx -s reload 。 把 121.5.180.193 服务器作为代理服务器，做如下配置： 123456789101112131415# /etc/nginx/conf.d/proxy.confupstream back_end { server 121.42.11.34:8080 weight=2 max_conns=1000 fail_timeout=10s max_fails=3; keepalive 32; keepalive_requests 80; keepalive_timeout 20s;}server { listen 80; server_name proxy.lion.club; location /proxy { proxy_pass http://back_end/proxy; }} 本地机器要访问 proxy.lion.club 域名，因此需要配置本地 hosts ，通过命令：vim /etc/hosts 进入配置文件，添加如下内容： 1121.5.180.193 proxy.lion.club 分析： 当访问 proxy.lion.club/proxy 时通过 upstream 的配置找到 121.42.11.34:8080 ； 因此访问地址变为 http://121.42.11.34:8080/proxy ； 连接到 121.42.11.34 服务器，找到 8080 端口提供的 server ； 通过 server 找到 /usr/share/nginx/html/proxy/index.html 资源，最终展示出来。 配置负载均衡配置负载均衡主要是要使用 upstream 指令。 我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ /etc/nginx/conf.d/balance.conf ）： 123456789101112131415161718192021server{ listen 8020; location / { return 200 'return 8020 \\n'; }}server{ listen 8030; location / { return 200 'return 8030 \\n'; }}server{ listen 8040; location / { return 200 'return 8040 \\n'; }} 配置完成后： nginx -t 检测配置是否正确； nginx -s reload 重启 Nginx 服务器； 执行 ss -nlt 命令查看端口是否被占用，从而判断 Nginx 服务是否正确启动。 把 121.5.180.193 服务器作为代理服务器，做如下配置（ /etc/nginx/conf.d/balance.conf ）： 123456789101112131415upstream demo_server { server 121.42.11.34:8020; server 121.42.11.34:8030; server 121.42.11.34:8040;}server { listen 80; server_name balance.lion.club; location /balance/ { proxy_pass http://demo_server; }} 配置完成后重启 Nginx 服务器。并且在需要访问的客户端配置好 ip 和域名的映射关系。 1234# /etc/hosts121.5.180.193 balance.lion.club 在客户端机器执行 curl http://balance.lion.club/balance/ 命令： 不难看出，负载均衡的配置已经生效了，每次给我们分发的上游服务器都不一样。就是通过简单的轮询策略进行上游服务器分发。 接下来，我们再来了解下 Nginx 的其它分发策略。 hash 算法通过制定关键字作为 hash key ，基于 hash 算法映射到特定的上游服务器中。关键字可以包含有变量、字符串。 12345678910111213141516upstream demo_server { hash $request_uri; server 121.42.11.34:8020; server 121.42.11.34:8030; server 121.42.11.34:8040;}server { listen 80; server_name balance.lion.club; location /balance/ { proxy_pass http://demo_server; }} hash $request_uri 表示使用 request_uri 变量作为 hash 的 key 值，只要访问的 URI 保持不变，就会一直分发给同一台服务器。 ip_hash根据客户端的请求 ip 进行判断，只要 ip 地址不变就永远分配到同一台主机。它可以有效解决后台服务器 session 保持的问题。 12345678910111213141516upstream demo_server { ip_hash; server 121.42.11.34:8020; server 121.42.11.34:8030; server 121.42.11.34:8040;}server { listen 80; server_name balance.lion.club; location /balance/ { proxy_pass http://demo_server; }} 最少连接数算法各个 worker 子进程通过读取共享内存的数据，来获取后端服务器的信息。来挑选一台当前已建立连接数最少的服务器进行分配请求。 1234语法：least_conn;上下文：upstream; 示例： 1234567891011121314151617upstream demo_server { zone test 10M; # zone可以设置共享内存空间的名字和大小 least_conn; server 121.42.11.34:8020; server 121.42.11.34:8030; server 121.42.11.34:8040;}server { listen 80; server_name balance.lion.club; location /balance/ { proxy_pass http://demo_server; }} 最后你会发现，负载均衡的配置其实一点都不复杂。 配置缓存缓存可以非常有效的提升性能，因此不论是客户端（浏览器），还是代理服务器（ Nginx ），乃至上游服务器都多少会涉及到缓存。可见缓存在每个环节都是非常重要的。下面让我们来学习 Nginx 中如何设置缓存策略。 proxy_cache存储一些之前被访问过、而且可能将要被再次访问的资源，使用户可以直接从代理服务器获得，从而减少上游服务器的压力，加快整个访问速度。 123456语法：proxy_cache zone | off ; # zone 是共享内存的名称默认值：proxy_cache off;上下文：http、server、location proxy_cache_path设置缓存文件的存放路径。 123456语法：proxy_cache_path path [level=levels] ...可选参数省略，下面会详细列举默认值：proxy_cache_path off上下文：http 参数含义： path 缓存文件的存放路径； level path 的目录层级； keys_zone 设置共享内存； inactive 在指定时间内没有被访问，缓存会被清理，默认10分钟； proxy_cache_key设置缓存文件的 key 。 123456语法：proxy_cache_key默认值：proxy_cache_key $scheme$proxy_host$request_uri;上下文：http、server、location proxy_cache_valid配置什么状态码可以被缓存，以及缓存时长。 123456语法：proxy_cache_valid [code...] time;上下文：http、server、location配置示例：proxy_cache_valid 200 304 2m;; # 说明对于状态为200和304的缓存文件的缓存时间是2分钟 proxy_no_cache定义相应保存到缓存的条件，如果字符串参数的至少一个值不为空且不等于“ 0”，则将不保存该响应到缓存。 123456语法：proxy_no_cache string;上下文：http、server、location示例：proxy_no_cache $http_pragma $http_authorization; proxy_cache_bypass定义条件，在该条件下将不会从缓存中获取响应。 123456语法：proxy_cache_bypass string;上下文：http、server、location示例：proxy_cache_bypass $http_pragma $http_authorization; upstream_cache_status 变量它存储了缓存是否命中的信息，会设置在响应头信息中，在调试中非常有用。 12345678MISS: 未命中缓存HIT： 命中缓存EXPIRED: 缓存过期STALE: 命中了陈旧缓存REVALIDDATED: Nginx验证陈旧缓存依然有效UPDATING: 内容陈旧，但正在更新BYPASS: X响应从原始服务器获取 配置实例我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ /etc/nginx/conf.d/cache.conf ）： 12345678910111213141516server { listen 1010; root /usr/share/nginx/html/1010; location / { index index.html; }}server { listen 1020; root /usr/share/nginx/html/1020; location / { index index.html; }} 把 121.5.180.193 服务器作为代理服务器，做如下配置（ /etc/nginx/conf.d/cache.conf ）： 12345678910111213141516171819proxy_cache_path /etc/nginx/cache_temp levels=2:2 keys_zone=cache_zone:30m max_size=2g inactive=60m use_temp_path=off;upstream cache_server{ server 121.42.11.34:1010; server 121.42.11.34:1020;}server { listen 80; server_name cache.lion.club; location / { proxy_cache cache_zone; # 设置缓存内存，上面配置中已经定义好的 proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟 proxy_cache_key $request_uri; # 缓存文件的key为请求的URI add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端 proxy_pass http://cache_server; # 代理转发 }} 缓存就是这样配置，我们可以在 /etc/nginx/cache_temp 路径下找到相应的缓存文件。 对于一些实时性要求非常高的页面或数据来说，就不应该去设置缓存，下面来看看如何配置不缓存的内容。 1234567891011121314151617181920...server { listen 80; server_name cache.lion.club; # URI 中后缀为 .txt 或 .text 的设置变量值为 &quot;no cache&quot; if ($request_uri ~ \\.(txt|text)$) { set $cache_name &quot;no cache&quot; } location / { proxy_no_cache $cache_name; # 判断该变量是否有值，如果有值则不进行缓存，如果没有值则进行缓存 proxy_cache cache_zone; # 设置缓存内存 proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟 proxy_cache_key $request_uri; # 缓存文件的key为请求的URI add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端 proxy_pass http://cache_server; # 代理转发 }} HTTPS在学习如何配置 HTTPS 之前，我们先来简单回顾下 HTTPS 的工作流程是怎么样的？它是如何进行加密保证安全的？ HTTPS 工作流程 客户端（浏览器）访问 https://www.baidu.com 百度网站； 百度服务器返回 HTTPS 使用的 CA 证书； 浏览器验证 CA 证书是否为合法证书； 验证通过，证书合法，生成一串随机数并使用公钥（证书中提供的）进行加密； 发送公钥加密后的随机数给百度服务器； 百度服务器拿到密文，通过私钥进行解密，获取到随机数（公钥加密，私钥解密，反之也可以）； 百度服务器把要发送给浏览器的内容，使用随机数进行加密后传输给浏览器； 此时浏览器可以使用随机数进行解密，获取到服务器的真实传输内容； 这就是 HTTPS 的基本运作原理，使用对称加密和非对称机密配合使用，保证传输内容的安全性。 关于HTTPS更多知识，可以查看作者的另外一篇文章《学习 HTTP 协议》。 配置证书下载证书的压缩文件，里面有个 Nginx 文件夹，把 xxx.crt 和 xxx.key 文件拷贝到服务器目录，再进行如下配置： 1234567891011121314server { listen 443 ssl http2 default_server; # SSL 访问端口号为 443 server_name lion.club; # 填写绑定证书的域名(我这里是随便写的) ssl_certificate /etc/nginx/https/lion.club_bundle.crt; # 证书地址 ssl_certificate_key /etc/nginx/https/lion.club.key; # 私钥地址 ssl_session_timeout 10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 支持ssl协议版本，默认为后三个，主流版本是[TLSv1.2] location / { root /usr/share/nginx/html; index index.html index.htm; }} 如此配置后就能正常访问 HTTPS 版的网站了。 配置跨域 CORS先简单回顾下跨域究竟是怎么回事。 跨域的定义同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。通常不允许不同源间的读操作。 同源的定义如果两个页面的协议，端口（如果有指定）和域名都相同，则两个页面具有相同的源。 下面给出了与 URL http://store.company.com/dir/page.html 的源进行对比的示例: 12345http://store.company.com/dir2/other.html 同源https://store.company.com/secure.html 不同源，协议不同http://store.company.com:81/dir/etc.html 不同源，端口不同http://news.company.com/dir/other.html 不同源，主机不同 不同源会有如下限制： Web 数据层面，同源策略限制了不同源的站点读取当前站点的 Cookie 、 IndexDB 、 LocalStorage 等数据。 DOM 层面，同源策略限制了来自不同源的 JavaScript 脚本对当前 DOM 对象读和写的操作。 网络层面，同源策略限制了通过 XMLHttpRequest 等方式将站点的数据发送给不同源的站点。 Nginx 解决跨域的原理例如： 前端 server 的域名为： fe.server.com 后端服务的域名为： dev.server.com 现在我在 fe.server.com 对 dev.server.com 发起请求一定会出现跨域。 现在我们只需要启动一个 Nginx 服务器，将 server_name 设置为 fe.server.com 然后设置相应的 location 以拦截前端需要跨域的请求，最后将请求代理回 dev.server.com 。如下面的配置： 12345678server { listen 80; server_name fe.server.com; location / { proxy_pass dev.server.com; }} 这样可以完美绕过浏览器的同源策略： fe.server.com 访问 Nginx 的 fe.server.com 属于同源访问，而 Nginx 对服务端转发的请求不会触发浏览器的同源策略。 配置开启 gzip 压缩GZIP 是规定的三种标准 HTTP 压缩格式之一。目前绝大多数的网站都在使用 GZIP 传输 HTML 、CSS 、 JavaScript 等资源文件。 对于文本文件， GZiP 的效果非常明显，开启后传输所需流量大约会降至 1/4~1/3 。 并不是每个浏览器都支持 gzip 的，如何知道客户端是否支持 gzip 呢，请求头中的 Accept-Encoding 来标识对压缩的支持。启用 gzip 同时需要客户端和服务端的支持，如果客户端支持 gzip 的解析，那么只要服务端能够返回 gzip 的文件就可以启用 gzip 了,我们可以通过 Nginx 的配置来让服务端支持 gzip 。下面的 respone 中 content-encoding:gzip ，指服务端开启了 gzip 的压缩方式。在 /etc/nginx/conf.d/ 文件夹中新建配置文件 gzip.conf ： 12345678910111213141516171819202122232425262728# # 默认off，是否开启gzipgzip on; # 要采用 gzip 压缩的 MIME 文件类型，其中 text/html 被系统强制启用；gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;# ---- 以上两个参数开启就可以支持Gzip压缩了 ---- ## 默认 off，该模块启用后，Nginx 首先检查是否存在请求静态文件的 gz 结尾的文件，如果有则直接返回该 .gz 文件内容；gzip_static on;# 默认 off，nginx做为反向代理时启用，用于设置启用或禁用从代理服务器上收到相应内容 gzip 压缩；gzip_proxied any;# 用于在响应消息头中添加 Vary：Accept-Encoding，使代理服务器根据请求头中的 Accept-Encoding 识别是否启用 gzip 压缩；gzip_vary on;# gzip 压缩比，压缩级别是 1-9，1 压缩级别最低，9 最高，级别越高压缩率越大，压缩时间越长，建议 4-6；gzip_comp_level 6;# 获取多少内存用于缓存压缩结果，16 8k 表示以 8k*16 为单位获得；gzip_buffers 16 8k;# 允许压缩的页面最小字节数，页面字节数从header头中的 Content-Length 中进行获取。默认值是 0，不管页面多大都压缩。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大；# gzip_min_length 1k;# 默认 1.1，启用 gzip 所需的 HTTP 最低版本；gzip_http_version 1.1; 其实也可以通过前端构建工具例如 webpack 、rollup 等在打生产包时就做好 Gzip 压缩，然后放到 Nginx 服务器中，这样可以减少服务器的开销，加快访问速度。 关于 Nginx 的实际应用就学习到这里，相信通过掌握了 Nginx 核心配置以及实战配置，之后再遇到什么需求，我们也能轻松应对。接下来，让我们再深入一点学习下 Nginx 的架构。 Nginx 架构进程结构多进程结构 Nginx 的进程模型图： 多进程中的 Nginx 进程架构如下图所示，会有一个父进程（ Master Process ），它会有很多子进程（ Child Processes ）。 Master Process 用来管理子进程的，其本身并不真正处理用户请求。 某个子进程 down 掉的话，它会向 Master 进程发送一条消息，表明自己不可用了，此时 Master 进程会去新起一个子进程。 某个配置文件被修改了 Master 进程会去通知 work 进程获取新的配置信息，这也就是我们所说的热部署。 子进程间是通过共享内存的方式进行通信的。 配置文件重载原理reload 重载配置文件的流程： 向 master 进程发送 HUP 信号（ reload 命令）； master 进程检查配置语法是否正确； master 进程打开监听端口； master 进程使用新的配置文件启动新的 worker 子进程； master 进程向老的 worker 子进程发送 QUIT 信号； 老的 worker 进程关闭监听句柄，处理完当前连接后关闭进程； 整个过程 Nginx 始终处于平稳运行中，实现了平滑升级，用户无感知； Nginx 模块化管理机制Nginx 的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。Nginx 的模块是互相独立的,低耦合高内聚。 总结相信通过本文的学习，你应该会对 Nginx 有一个更加全面的认识。","link":"/2021/03/24/%E6%9C%80%E5%85%A8%E6%9C%80%E5%85%A8%E7%9A%84Nginx%E8%A7%A3%E8%AF%BB%E6%96%87%E7%AB%A0/"},{"title":"给你的SpringBoot做埋点监控--JVM应用度量框架Micrometer","text":"JVM应用度量框架Micrometer实战前提spring-actuator做度量统计收集，使用Prometheus（普罗米修斯）进行数据收集，Grafana（增强ui）进行数据展示，用于监控生成环境机器的性能指标和业务数据指标。一般，我们叫这样的操作为”埋点”。SpringBoot中的依赖spring-actuator中集成的度量统计API使用的框架是Micrometer，官网是Micrometer.io。在实践中发现了业务开发者滥用了Micrometer的度量类型Counter，导致无论什么情况下都只使用计数统计的功能。这篇文章就是基于Micrometer分析其他的度量类型API的作用和适用场景。 Micrometer提供的度量类库Meter是指一组用于收集应用中的度量数据的接口，Meter单词可以翻译为”米”或者”千分尺”，但是显然听起来都不是很合理，因此下文直接叫Meter，理解它为度量接口即可。Meter是由MeterRegistry创建和保存的，可以理解MeterRegistry是Meter的工厂和缓存中心，一般而言每个JVM应用在使用Micrometer的时候必须创建一个MeterRegistry的具体实现。Micrometer中，Meter的具体类型包括：Timer，Counter，Gauge，DistributionSummary，LongTaskTimer，FunctionCounter，FunctionTimer和TimeGauge。下面分节详细介绍这些类型的使用方法和实战使用场景。而一个Meter具体类型需要通过名字和Tag(这里指的是Micrometer提供的Tag接口)作为它的唯一标识，这样做的好处是可以使用名字进行标记，通过不同的Tag去区分多种维度进行数据统计。 MeterRegistryMeterRegistry在Micrometer是一个抽象类，主要实现包括： 1、SimpleMeterRegistry：每个Meter的最新数据可以收集到SimpleMeterRegistry实例中，但是这些数据不会发布到其他系统，也就是数据是位于应用的内存中的。 2、CompositeMeterRegistry：多个MeterRegistry聚合，内部维护了一个MeterRegistry的列表。 3、全局的MeterRegistry：工厂类io.micrometer.core.instrument.Metrics中持有一个静态final的CompositeMeterRegistry实例globalRegistry。 当然，使用者也可以自行继承MeterRegistry去实现自定义的MeterRegistry。SimpleMeterRegistry适合做调试的时候使用，它的简单使用方式如下： 123MeterRegistry registry = new SimpleMeterRegistry(); Counter counter = registry.counter(&quot;counter&quot;);counter.increment(); CompositeMeterRegistry实例初始化的时候，内部持有的MeterRegistry列表是空的，如果此时用它新增一个Meter实例，Meter实例的操作是无效的 12345678910CompositeMeterRegistry composite = new CompositeMeterRegistry();Counter compositeCounter = composite.counter(&quot;counter&quot;);compositeCounter.increment(); // &lt;- 实际上这一步操作是无效的,但是不会报错SimpleMeterRegistry simple = new SimpleMeterRegistry();composite.add(simple); // &lt;- 向CompositeMeterRegistry实例中添加SimpleMeterRegistry实例compositeCounter.increment(); // &lt;-计数成功 全局的MeterRegistry的使用方式更加简单便捷，因为一切只需要操作工厂类Metrics的静态方法： 123Metrics.addRegistry(new SimpleMeterRegistry());Counter counter = Metrics.counter(&quot;counter&quot;, &quot;tag-1&quot;, &quot;tag-2&quot;);counter.increment(); Tag与Meter的命名Micrometer中，Meter的命名约定使用英文逗号(dot，也就是”.”)分隔单词。但是对于不同的监控系统，对命名的规约可能并不相同，如果命名规约不一致，在做监控系统迁移或者切换的时候，可能会对新的系统造成破坏。Micrometer中使用英文逗号分隔单词的命名规则，再通过底层的命名转换接口NamingConvention进行转换，最终可以适配不同的监控系统，同时可以消除监控系统不允许的特殊字符的名称和标记等。开发者也可以覆盖NamingConvention实现自定义的命名转换规则：registry.config().namingConvention(myCustomNamingConvention);。在Micrometer中，对一些主流的监控系统或者存储系统的命名规则提供了默认的转换方式，例如当我们使用下面的命名时候： 12MeterRegistry registry = ...registry.timer(&quot;http.server.requests&quot;); 对于不同的监控系统或者存储系统，命名会自动转换如下： 1、Prometheus - http_server_requests_duration_seconds。 2、Atlas - httpServerRequests。 3、Graphite - http.server.requests。 4、InfluxDB - http_server_requests。 其实NamingConvention已经提供了5种默认的转换规则：dot、snakeCase、camelCase、upperCamelCase和slashes。 另外，Tag(标签)是Micrometer的一个重要的功能，严格来说，一个度量框架只有实现了标签的功能，才能真正地多维度进行度量数据收集。Tag的命名一般需要是有意义的，所谓有意义就是可以根据Tag的命名可以推断出它指向的数据到底代表什么维度或者什么类型的度量指标。假设我们需要监控数据库的调用和Http请求调用统计，一般推荐的做法是： 123MeterRegistry registry = ...registry.counter(&quot;database.calls&quot;, &quot;db&quot;, &quot;users&quot;)registry.counter(&quot;http.requests&quot;, &quot;uri&quot;, &quot;/api/users&quot;) 这样，当我们选择命名为”database.calls”的计数器，我们可以进一步选择分组”db”或者”users”分别统计不同分组对总调用数的贡献或者组成。一个反例如下： 12345678MeterRegistry registry = ...registry.counter(&quot;calls&quot;, &quot;class&quot;, &quot;database&quot;, &quot;db&quot;, &quot;users&quot;);registry.counter(&quot;calls&quot;, &quot;class&quot;, &quot;http&quot;, &quot;uri&quot;, &quot;/api/users&quot;); 通过命名”calls”得到的计数器，由于标签混乱，数据是基本无法分组统计分析，这个时候可以认为得到的时间序列的统计数据是没有意义的。可以定义全局的Tag，也就是全局的Tag定义之后，会附加到所有的使用到的Meter上(只要是使用同一MeterRegistry)，全局的Tag可以这样定义： 1234567891011121314MeterRegistry registry = ...registry.counter(&quot;calls&quot;, &quot;class&quot;, &quot;database&quot;, &quot;db&quot;, &quot;users&quot;);registry.counter(&quot;calls&quot;, &quot;class&quot;, &quot;http&quot;, &quot;uri&quot;, &quot;/api/users&quot;); MeterRegistry registry = ...registry.config().commonTags(&quot;stack&quot;, &quot;prod&quot;, &quot;region&quot;, &quot;us-east-1&quot;);// 和上面的意义是一样的registry.config().commonTags(Arrays.asList(Tag.of(&quot;stack&quot;, &quot;prod&quot;), Tag.of(&quot;region&quot;, &quot;us-east-1&quot;))); 像上面这样子使用，就能通过主机，实例，区域，堆栈等操作环境进行多维度深入分析。 还有两点点需要注意： 1、Tag的值必须不为null。 2、Micrometer中，Tag必须成对出现，也就是Tag必须设置为偶数个，实际上它们以Key=Value的形式存在，具体可以看io.micrometer.core.instrument.Tag接口： 12345678910111213public interface Tag extends Comparable&lt;Tag&gt; { String getKey(); String getValue(); static Tag of(String key, String value) { return new ImmutableTag(key, value); } default int compareTo(Tag o) { return this.getKey().compareTo(o.getKey()); }} 当然，有些时候，我们需要过滤一些必要的标签或者名称进行统计，或者为Meter的名称添加白名单，这个时候可以使用MeterFilter。MeterFilter本身提供一些列的静态方法，多个MeterFilter可以叠加或者组成链实现用户最终的过滤策略。例如： 1234MeterRegistry registry = ...registry.config() .meterFilter(MeterFilter.ignoreTags(&quot;http&quot;)) .meterFilter(MeterFilter.denyNameStartsWith(&quot;jvm&quot;)); 表示忽略”http”标签，拒绝名称以”jvm”字符串开头的Meter。更多用法可以参详一下MeterFilter这个类。 Meter的命名和Meter的Tag相互结合，以命名为轴心，以Tag为多维度要素，可以使度量数据的维度更加丰富，便于统计和分析。 Meters前面提到Meter主要包括：Timer，Counter，Gauge，DistributionSummary，LongTaskTimer，FunctionCounter，FunctionTimer和TimeGauge。下面逐一分析它们的作用和个人理解的实际使用场景(应该说是生产环境)。 CounterCounter是一种比较简单的Meter，它是一种单值的度量类型，或者说是一个单值计数器。Counter接口允许使用者使用一个固定值(必须为正数)进行计数。准确来说：Counter就是一个增量为正数的单值计数器。这个举个很简单的使用例子： 1234MeterRegistry meterRegistry = new SimpleMeterRegistry();Counter counter = meterRegistry.counter(&quot;http.request&quot;, &quot;createOrder&quot;, &quot;/order/create&quot;);counter.increment();System.out.println(counter.measure()); // [Measurement{statistic='COUNT', value=1.0}] 使用场景： Counter的作用是记录XXX的总量或者计数值，适用于一些增长类型的统计，例如下单、支付次数、Http请求总量记录等等，通过Tag可以区分不同的场景，对于下单，可以使用不同的Tag标记不同的业务来源或者是按日期划分，对于Http请求总量记录，可以使用Tag区分不同的URL。用下单业务举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//实体@Datapublic class Order { private String orderId; private Integer amount; private String channel; private LocalDateTime createTime;}public class CounterMain { private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); static { Metrics.addRegistry(new SimpleMeterRegistry()); } public static void main(String[] args) throws Exception { Order order1 = new Order(); order1.setOrderId(&quot;ORDER_ID_1&quot;); order1.setAmount(100); order1.setChannel(&quot;CHANNEL_A&quot;); order1.setCreateTime(LocalDateTime.now()); createOrder(order1); Order order2 = new Order(); order2.setOrderId(&quot;ORDER_ID_2&quot;); order2.setAmount(200); order2.setChannel(&quot;CHANNEL_B&quot;); order2.setCreateTime(LocalDateTime.now()); createOrder(order2); Search.in(Metrics.globalRegistry).meters().forEach(each -&gt; { StringBuilder builder = new StringBuilder(); builder.append(&quot;name:&quot;) .append(each.getId().getName()) .append(&quot;,tags:&quot;) .append(each.getId().getTags()) .append(&quot;,type:&quot;).append(each.getId().getType()) .append(&quot;,value:&quot;).append(each.measure()); System.out.println(builder.toString()); }); } private static void createOrder(Order order) { //忽略订单入库等操作 Metrics.counter(&quot;order.create&quot;, &quot;channel&quot;, order.getChannel(), &quot;createTime&quot;, FORMATTER.format(order.getCreateTime())).increment(); }} 控制台输出 12name:order.create,tags:[tag(channel=CHANNEL_A), tag(createTime=2018-11-10)],type:COUNTER,value:[Measurement{statistic='COUNT', value=1.0}]name:order.create,tags:[tag(channel=CHANNEL_B), tag(createTime=2018-11-10)],type:COUNTER,value:[Measurement{statistic='COUNT', value=1.0}] 上面的例子是使用全局静态方法工厂类Metrics去构造Counter实例，实际上，io.micrometer.core.instrument.Counter接口提供了一个内部建造器类Counter.Builder去实例化Counter，Counter.Builder的使用方式如下： 1234567891011public class CounterBuilderMain { public static void main(String[] args) throws Exception{ Counter counter = Counter.builder(&quot;name&quot;) //名称 .baseUnit(&quot;unit&quot;) //基础单位 .description(&quot;desc&quot;) //描述 .tag(&quot;tagKey&quot;, &quot;tagValue&quot;) //标签 .register(new SimpleMeterRegistry());//绑定的MeterRegistry counter.increment(); }} FunctionCounterFunctionCounter是Counter的特化类型，它把计数器数值增加的动作抽象成接口类型ToDoubleFunction，这个接口JDK1.8中对于Function的特化类型接口。FunctionCounter的使用场景和Counter是一致的，这里介绍一下它的用法： 12345678910111213141516171819202122public class FunctionCounterMain { public static void main(String[] args) throws Exception { MeterRegistry registry = new SimpleMeterRegistry(); AtomicInteger n = new AtomicInteger(0); //这里ToDoubleFunction匿名实现其实可以使用Lambda表达式简化为AtomicInteger::get FunctionCounter.builder(&quot;functionCounter&quot;, n, new ToDoubleFunction&lt;AtomicInteger&gt;() { @Override public double applyAsDouble(AtomicInteger value) { return value.get(); } }).baseUnit(&quot;function&quot;) .description(&quot;functionCounter&quot;) .tag(&quot;createOrder&quot;, &quot;CHANNEL-A&quot;) .register(registry); //下面模拟三次计数 n.incrementAndGet(); n.incrementAndGet(); n.incrementAndGet(); }} FunctionCounter使用的一个明显的好处是，我们不需要感知FunctionCounter实例的存在，实际上我们只需要操作作为FunctionCounter实例构建元素之一的AtomicInteger实例即可，这种接口的设计方式在很多框架里面都可以看到。 TimerTimer(计时器)适用于记录耗时比较短的事件的执行时间，通过时间分布展示事件的序列和发生频率。所有的Timer的实现至少记录了发生的事件的数量和这些事件的总耗时，从而生成一个时间序列。Timer的基本单位基于服务端的指标而定，但是实际上我们不需要过于关注Timer的基本单位，因为Micrometer在存储生成的时间序列的时候会自动选择适当的基本单位。Timer接口提供的常用方法如下： 1234567891011121314151617181920212223242526272829303132333435363738public interface Timer extends Meter { ... void record(long var1, TimeUnit var3); default void record(Duration duration) { this.record(duration.toNanos(), TimeUnit.NANOSECONDS); } &lt;T&gt; T record(Supplier&lt;T&gt; var1); &lt;T&gt; T recordCallable(Callable&lt;T&gt; var1) throws Exception; void record(Runnable var1); default Runnable wrap(Runnable f) { return () -&gt; { this.record(f); }; } default &lt;T&gt; Callable&lt;T&gt; wrap(Callable&lt;T&gt; f) { return () -&gt; { return this.recordCallable(f); }; } long count(); double totalTime(TimeUnit var1); default double mean(TimeUnit unit) { return this.count() == 0L ? 0.0D : this.totalTime(unit) / (double)this.count(); } double max(TimeUnit var1); ...} 实际上，比较常用和方便的方法是几个函数式接口入参的方法： 123456Timer timer = ...timer.record(() -&gt; dontCareAboutReturnValue());timer.recordCallable(() -&gt; returnValue());Runnable r = timer.wrap(() -&gt; dontCareAboutReturnValue());Callable c = timer.wrap(() -&gt; returnValue()); 使用场景： 根据个人经验和实践，总结如下： 1、记录指定方法的执行时间用于展示。 2、记录一些任务的执行时间，从而确定某些数据来源的速率，例如消息队列消息的消费速率等。 这里举个实际的例子，要对系统做一个功能，记录指定方法的执行时间，还是用下单方法做例子： 123456789101112131415161718192021222324252627public class TimerMain { private static final Random R = new Random(); static { Metrics.addRegistry(new SimpleMeterRegistry()); } public static void main(String[] args) throws Exception { Order order1 = new Order(); order1.setOrderId(&quot;ORDER_ID_1&quot;); order1.setAmount(100); order1.setChannel(&quot;CHANNEL_A&quot;); order1.setCreateTime(LocalDateTime.now()); Timer timer = Metrics.timer(&quot;timer&quot;, &quot;createOrder&quot;, &quot;cost&quot;); timer.record(() -&gt; createOrder(order1)); } private static void createOrder(Order order) { try { TimeUnit.SECONDS.sleep(R.nextInt(5)); //模拟方法耗时 } catch (InterruptedException e) { //no-op } }} 在实际生产环境中，可以通过spring-aop把记录方法耗时的逻辑抽象到一个切面中，这样就能减少不必要的冗余的模板代码。上面的例子是通过Mertics构造Timer实例，实际上也可以使用Builder构造： 123456MeterRegistry registry = ...Timer timer = Timer .builder(&quot;my.timer&quot;) .description(&quot;a description of what this timer does&quot;) // 可选 .tags(&quot;region&quot;, &quot;test&quot;) // 可选 .register(registry); 另外，Timer的使用还可以基于它的内部类Timer.Sample，通过start和stop两个方法记录两者之间的逻辑的执行耗时。例如： 123456Timer.Sample sample = Timer.start(registry);// 这里做业务逻辑Response response = ...sample.stop(registry.timer(&quot;my.timer&quot;, &quot;response&quot;, response.status())); FunctionTimerFunctionTimer是Timer的特化类型，它主要提供两个单调递增的函数(其实并不是单调递增，只是在使用中一般需要随着时间最少保持不变或者说不减少)：一个用于计数的函数和一个用于记录总调用耗时的函数，它的建造器的入参如下： 12345678public interface FunctionTimer extends Meter { static &lt;T&gt; Builder&lt;T&gt; builder(String name, T obj, ToLongFunction&lt;T&gt; countFunction, ToDoubleFunction&lt;T&gt; totalTimeFunction, TimeUnit totalTimeFunctionUnit) { return new Builder&lt;&gt;(name, obj, countFunction, totalTimeFunction, totalTimeFunctionUnit); } ...} 官方文档中的例子如下： 123456IMap&lt;?, ?&gt; cache = ...; // 假设使用了Hazelcast缓存registry.more().timer(&quot;cache.gets.latency&quot;, Tags.of(&quot;name&quot;, cache.getName()), cache, c -&gt; c.getLocalMapStats().getGetOperationCount(), //实际上就是cache的一个方法，记录缓存生命周期初始化的增量(个数) c -&gt; c.getLocalMapStats().getTotalGetLatency(), // Get操作的延迟时间总量，可以理解为耗时 TimeUnit.NANOSECONDS); 按照个人理解，ToDoubleFunction用于统计事件个数，ToDoubleFunction用于记录执行总时间，实际上两个函数都只是Function函数的变体，还有一个比较重要的是总时间的单位totalTimeFunctionUnit。简单的使用方式如下： 1234567891011121314public class FunctionTimerMain { public static void main(String[] args) throws Exception { //这个是为了满足参数,暂时不需要理会 Object holder = new Object(); AtomicLong totalTimeNanos = new AtomicLong(0); AtomicLong totalCount = new AtomicLong(0); FunctionTimer.builder(&quot;functionTimer&quot;, holder, p -&gt; totalCount.get(), p -&gt; totalTimeNanos.get(), TimeUnit.NANOSECONDS) .register(new SimpleMeterRegistry()); totalTimeNanos.addAndGet(10000000); totalCount.incrementAndGet(); }} LongTaskTimerLongTaskTimer也是一种Timer的特化类型，主要用于记录长时间执行的任务的持续时间，在任务完成之前，被监测的事件或者任务仍然处于运行状态，任务完成的时候，任务执行的总耗时才会被记录下来。LongTaskTimer适合用于长时间持续运行的事件耗时的记录，例如相对耗时的定时任务。在Spring应用中，可以简单地使用@Scheduled和@Timed注解，基于spring-aop完成定时调度任务的总耗时记录： 12345@Timed(value = &quot;aws.scrape&quot;, longTask = true)@Scheduled(fixedDelay = 360000)void scrapeResources() { //这里做相对耗时的业务逻辑} 当然，在非spring体系中也能方便地使用LongTaskTimer： 123456789101112131415public class LongTaskTimerMain { public static void main(String[] args) throws Exception{ MeterRegistry meterRegistry = new SimpleMeterRegistry(); LongTaskTimer longTaskTimer = meterRegistry.more().longTaskTimer(&quot;longTaskTimer&quot;); longTaskTimer.record(() -&gt; { //这里编写Task的逻辑 }); //或者这样 Metrics.more().longTaskTimer(&quot;longTaskTimer&quot;).record(()-&gt; { //这里编写Task的逻辑 }); }} GaugeGauge(仪表)是获取当前度量记录值的句柄，也就是它表示一个可以任意上下浮动的单数值度量Meter。Gauge通常用于变动的测量值，测量值用ToDoubleFunction参数的返回值设置，如当前的内存使用情况，同时也可以测量上下移动的”计数”，比如队列中的消息数量。官网文档中提到Gauge的典型使用场景是用于测量集合或映射的大小或运行状态中的线程数。Gauge一般用于监测有自然上界的事件或者任务，而Counter一般使用于无自然上界的事件或者任务的监测，所以像Http请求总量计数应该使用Counter而非Gauge。MeterRegistry中提供了一些便于构建用于观察数值、函数、集合和映射的Gauge相关的方法： 1234List&lt;String&gt; list = registry.gauge(&quot;listGauge&quot;, Collections.emptyList(), new ArrayList&lt;&gt;(), List::size); List&lt;String&gt; list2 = registry.gaugeCollectionSize(&quot;listSize2&quot;, Tags.empty(), new ArrayList&lt;&gt;()); Map&lt;String, Integer&gt; map = registry.gaugeMapSize(&quot;mapGauge&quot;, Tags.empty(), new HashMap&lt;&gt;()); 上面的三个方法通过MeterRegistry构建Gauge并且返回了集合或者映射实例，使用这些集合或者映射实例就能在其size变化过程中记录这个变更值。更重要的优点是，我们不需要感知Gauge接口的存在，只需要像平时一样使用集合或者映射实例就可以了。此外，Gauge还支持java.lang.Number的子类，java.util.concurrent.atomic包中的AtomicInteger和AtomicLong，还有Guava提供的AtomicDouble： 123AtomicInteger n = registry.gauge(&quot;numberGauge&quot;, new AtomicInteger(0));n.set(1);n.set(2); 除了使用MeterRegistry创建Gauge之外，还可以使用建造器流式创建： 1234567//一般我们不需要操作Gauge实例Gauge gauge = Gauge .builder(&quot;gauge&quot;, myObj, myObj::gaugeValue) .description(&quot;a description of what this gauge does&quot;) // 可选 .tags(&quot;region&quot;, &quot;test&quot;) // 可选 .register(registry); 使用场景： 根据个人经验和实践，总结如下： 1、有自然(物理)上界的浮动值的监测，例如物理内存、集合、映射、数值等。 2、有逻辑上界的浮动值的监测，例如积压的消息、(线程池中)积压的任务等，其实本质也是集合或者映射的监测。 举个相对实际的例子，假设我们需要对登录后的用户发送一条短信或者推送，做法是消息先投放到一个阻塞队列，再由一个线程消费消息进行其他操作： 123456789101112131415161718192021222324252627282930313233public class GaugeMain { private static final MeterRegistry MR = new SimpleMeterRegistry(); private static final BlockingQueue&lt;Message&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(500); private static BlockingQueue&lt;Message&gt; REAL_QUEUE; static { REAL_QUEUE = MR.gauge(&quot;messageGauge&quot;, QUEUE, Collection::size); } public static void main(String[] args) throws Exception { consume(); Message message = new Message(); message.setUserId(1L); message.setContent(&quot;content&quot;); REAL_QUEUE.put(message); } private static void consume() throws Exception { new Thread(() -&gt; { while (true) { try { Message message = REAL_QUEUE.take(); //handle message System.out.println(message); } catch (InterruptedException e) { //no-op } } }).start(); }} 上面的例子代码写得比较糟糕，只为了演示相关使用方式，切勿用于生产环境。 TimeGaugeTimeGauge是Gauge的特化类型，相比Gauge，它的构建器中多了一个TimeUnit类型的参数，用于指定ToDoubleFunction入参的基础时间单位。这里简单举个使用例子： 123456789101112131415161718192021222324252627282930313233public class TimeGaugeMain { private static final SimpleMeterRegistry R = new SimpleMeterRegistry(); public static void main(String[] args) throws Exception{ AtomicInteger count = new AtomicInteger(); TimeGauge.Builder&lt;AtomicInteger&gt; timeGauge = TimeGauge.builder(&quot;timeGauge&quot;, count, TimeUnit.SECONDS, AtomicInteger::get); timeGauge.register(R); count.addAndGet(10086); print(); count.set(1); print(); } private static void print()throws Exception{ Search.in(R).meters().forEach(each -&gt; { StringBuilder builder = new StringBuilder(); builder.append(&quot;name:&quot;) .append(each.getId().getName()) .append(&quot;,tags:&quot;) .append(each.getId().getTags()) .append(&quot;,type:&quot;).append(each.getId().getType()) .append(&quot;,value:&quot;).append(each.measure()); System.out.println(builder.toString()); }); } }//输出name:timeGauge,tags:[],type:GAUGE,value:[Measurement{statistic='VALUE', value=10086.0}]name:timeGauge,tags:[],type:GAUGE,value:[Measurement{statistic='VALUE', value=1.0}] DistributionSummarySummary(摘要)主要用于跟踪事件的分布，在Micrometer中，对应的类是DistributionSummary(分发摘要)。它的使用方式和Timer十分相似，但是它的记录值并不依赖于时间单位。常见的使用场景：使用DistributionSummary测量命中服务器的请求的有效负载大小。使用MeterRegistry创建DistributionSummary实例如下： 1DistributionSummary summary = registry.summary(&quot;response.size&quot;); 通过建造器流式创建如下： 12345678DistributionSummary summary = DistributionSummary .builder(&quot;response.size&quot;) .description(&quot;a description of what this summary does&quot;) // 可选 .baseUnit(&quot;bytes&quot;) // 可选 .tags(&quot;region&quot;, &quot;test&quot;) // 可选 .scale(100) // 可选 .register(registry); DistributionSummary中有很多构建参数跟缩放和直方图的表示相关，见下一节。 使用场景： 根据个人经验和实践，总结如下： 1、不依赖于时间单位的记录值的测量，例如服务器有效负载值，缓存的命中率等。 举个相对具体的例子： 1234567891011121314151617181920212223242526272829public class DistributionSummaryMain { private static final DistributionSummary DS = DistributionSummary.builder(&quot;cacheHitPercent&quot;) .register(new SimpleMeterRegistry()); private static final LoadingCache&lt;String, String&gt; CACHE = CacheBuilder.newBuilder() .maximumSize(1000) .recordStats() .expireAfterWrite(60, TimeUnit.SECONDS) .build(new CacheLoader&lt;String, String&gt;() { @Override public String load(String s) throws Exception { return selectFromDatabase(); } }); public static void main(String[] args) throws Exception{ String key = &quot;doge&quot;; String value = CACHE.get(key); record(); } private static void record()throws Exception{ CacheStats stats = CACHE.stats(); BigDecimal hitCount = new BigDecimal(stats.hitCount()); BigDecimal requestCount = new BigDecimal(stats.requestCount()); DS.record(hitCount.divide(requestCount,2,BigDecimal.ROUND_HALF_DOWN).doubleValue()); }} 直方图和百分数配置直方图和百分数配置适用于Summary和Timer，这部分相对复杂，等研究透了再补充。 基于SpirngBoot、Prometheus、Grafana集成集成了Micrometer框架的JVM应用使用到Micrometer的API收集的度量数据位于内存之中，因此，需要额外的存储系统去存储这些度量数据，需要有监控系统负责统一收集和处理这些数据，还需要有一些UI工具去展示数据，一般大佬只喜欢看炫酷的图表或者动画。常见的存储系统就是时序数据库，主流的有Influx、Datadog等。比较主流的监控系统(主要是用于数据收集和处理)就是Prometheus(一般叫普罗米修斯，下面就这样叫吧)。而展示的UI目前相对用得比较多的就是Grafana。另外，Prometheus已经内置了一个时序数据库的实现，因此，在做一套相对完善的度量数据监控的系统只需要依赖目标JVM应用，Prometheus组件和Grafana组件即可。下面花一点时间从零开始搭建一个这样的系统，之前写的一篇文章基于Windows系统，操作可能跟生产环境不够接近，这次使用CentOS7。 SpirngBoot中使用MicrometerSpringBoot中的spring-boot-starter-actuator依赖已经集成了对Micrometer的支持，其中的metrics端点的很多功能就是通过Micrometer实现的，prometheus端点默认也是开启支持的，实际上actuator依赖的spring-boot-actuator-autoconfigure中集成了对很多框架的开箱即用的API，其中prometheus包中集成了对Prometheus的支持，使得使用了actuator可以轻易地让项目暴露出prometheus端点，作为Prometheus收集数据的客户端，Prometheus(服务端软件)可以通过此端点收集应用中Micrometer的度量数据。 我们先引入spring-boot-starter-actuator和spring-boot-starter-web，实现一个Counter和Timer作为示例。依赖： 1234567891011121314151617181920212223242526272829303132333435&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 接着编写一个下单接口和一个消息发送模块，模拟用户下单之后向用户发送消息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130//实体@Datapublic class Message { private String orderId; private Long userId; private String content; } @Data public class Order { private String orderId; private Long userId; private Integer amount; private LocalDateTime createTime; } //控制器和服务类 @RestController public class OrderController { @Autowired private OrderService orderService; @PostMapping(value = &quot;/order&quot;) public ResponseEntity&lt;Boolean&gt; createOrder(@RequestBody Order order){ return ResponseEntity.ok(orderService.createOrder(order)); } } @Slf4j @Service public class OrderService { private static final Random R = new Random(); @Autowired private MessageService messageService; public Boolean createOrder(Order order) { //模拟下单 try { int ms = R.nextInt(50) + 50; TimeUnit.MILLISECONDS.sleep(ms); log.info(&quot;保存订单模拟耗时{}毫秒...&quot;, ms); } catch (Exception e) { //no-op } //记录下单总数 Metrics.counter(&quot;order.count&quot;, &quot;order.channel&quot;, order.getChannel()).increment(); //发送消息 Message message = new Message(); message.setContent(&quot;模拟短信...&quot;); message.setOrderId(order.getOrderId()); message.setUserId(order.getUserId()); messageService.sendMessage(message); return true; } } @Slf4j @Service public class MessageService implements InitializingBean { private static final BlockingQueue&lt;Message&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(500); private static BlockingQueue&lt;Message&gt; REAL_QUEUE; private static final Executor EXECUTOR = Executors.newSingleThreadExecutor(); private static final Random R = new Random(); static { REAL_QUEUE = Metrics.gauge(&quot;message.gauge&quot;, Tags.of(&quot;message.gauge&quot;, &quot;message.queue.size&quot;), QUEUE, Collection::size); } public void sendMessage(Message message) { try { REAL_QUEUE.put(message); } catch (InterruptedException e) { //no-op } } @Override public void afterPropertiesSet() throws Exception { EXECUTOR.execute(() -&gt; { while (true) { try { Message message = REAL_QUEUE.take(); log.info(&quot;模拟发送短信,orderId:{},userId:{},内容:{},耗时:{}毫秒&quot;, message.getOrderId(), message.getUserId(), message.getContent(), R.nextInt(50)); } catch (Exception e) { throw new IllegalStateException(e); } } }); } } //切面类 @Component @Aspect public class TimerAspect { @Around(value = &quot;execution(* club.throwable.smp.service.*Service.*(..))&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable { Signature signature = joinPoint.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method method = methodSignature.getMethod(); Timer timer = Metrics.timer(&quot;method.cost.time&quot;, &quot;method.name&quot;, method.getName()); ThrowableHolder holder = new ThrowableHolder(); Object result = timer.recordCallable(() -&gt; { try { return joinPoint.proceed(); } catch (Throwable e) { holder.throwable = e; } return null; }); if (null != holder.throwable) { throw holder.throwable; } return result; } private class ThrowableHolder { Throwable throwable; }} yaml的配置如下： 12345678910server: port: 9091management: server: port: 10091 endpoints: web: exposure: include: '*' base-path: /management 注意多看spring官方文档关于Actuator的详细描述，在SpringBoot-2.x之后，配置Web端点暴露的权限控制和1.x有很大的不同。总结一下就是：除了shutdown端点之外，其他端点默认都是开启支持的这里仅仅是开启支持，并不是暴露为Web端点，端点必须暴露为Web端点才能被访问，禁用或者开启端点支持的配置方式如下： 1management.endpoint.${端点ID}.enabled=true/false可以查 可以查看actuator-api文档查看所有支持的端点的特性，这个是2.1.0.RELEASE版本的官方文档，不知道日后链接会不会挂掉。端点只开启支持，但是不暴露为Web端点，是无法通过http://{host}:{management.port}/{management.endpoints.web.base-path}/{endpointId}访问的。暴露监控端点为Web端点的配置是： 12management.endpoints.web.exposure.include=info,healthmanagement.endpoints.web.exposure.exclude=prometheus management.endpoints.web.exposure.exclude用于指定不暴露为Web端点的监控端点，指定多个的时候用英文逗号分隔management.endpoints.web.exposure.include默认指定的只有info和health两个端点，我们可以直接指定暴露所有的端点：management.endpoints.web.exposure.include=*，如果采用YAML配置，记得*要加单引号’*‘。暴露所有Web监控端点是一件比较危险的事情，如果需要在生产环境这样做，请务必先确认http://{host}:{management.port}不能通过公网访问(也就是监控端点访问的端口只能通过内网访问，这样可以方便后面说到的Prometheus服务端通过此端口收集数据)。 Prometheus的安装和配置Prometheus目前的最新版本是2.5，鉴于笔者没深入玩过Docker，这里还是直接下载它的压缩包解压安装。 123wget https://github.com/prometheus/prometheus/releases/download/v2.5.0/prometheus-2.5.0.linux-amd64.tar.gztar xvfz prometheus-*.tar.gzcd prometheus-* 先编辑解压出来的目录下的prometheus配置文件prometheus.yml，主要修改scrape_configs节点的属性： 1234567891011scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. # 这里配置需要拉取度量信息的URL路径，这里选择应用程序的prometheus端点 metrics_path: /management/prometheus static_configs: # 这里配置host和port - targets: ['localhost:10091'] 配置拉取度量数据的路径为localhost:10091/management/metrics，此前记得把前一节提到的应用在虚拟机中启动。接着启动Prometheus应用： 12# 参数 --storage.tsdb.path=存储数据的路径，默认路径为./data./prometheus --config.file=prometheus.yml Prometheus引用的默认启动端口是9090，启动成功后，日志如下： 此时，访问ttp://${虚拟机host}:9090/targets就能看到当前Prometheus中执行的Job 访问ttp://${虚拟机host}:9090/graph以查找到我们定义的度量Meter和spring-boot-starter-actuator中已经定义好的一些关于JVM或者Tomcat的度量Meter。我们先对应用的/order接口进行调用，然后查看一下监控前面在应用中定义的rder_count_total``ethod_cost_time_seconds_sum 可以看到，Meter的信息已经被收集和展示，但是显然不够详细和炫酷，这个时候就需要使用Grafana的UI做一下点缀。 Grafana的安装和使用Grafana的安装过程如下： 12wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.3.4-1.x86_64.rpm sudo yum localinstall grafana-5.3.4-1.x86_64.rpm 安装完成后，通过命令service grafana-server start启动即可，默认的启动端口为3000，通过ttp://${host}:3000即可。初始的账号密码都为admin，权限是管理员权限。接着需要在Home面板添加一个数据源，目的是对接Prometheus服务端从而可以拉取它里面的度量数据。数据源添加面板如下： 其实就是指向Prometheus服务端的端口就可以了。接下来可以天马行空地添加需要的面板，就下单数量统计的指标，可以添加一个Graph的面板 配置面板的时候，需要在基础(General)中指定Title： 接着比较重要的是Metrics的配置，需要指定数据源和Prometheus的查询语句： 最好参考一下Prometheus的官方文档，稍微学习一下它的查询语言PromQL的使用方式，一个面板可以支持多个PromQL查询。前面提到的两项是基本配置，其他配置项一般是图表展示的辅助或者预警等辅助功能，这里先不展开，可以取Grafana的官网挖掘一下使用方式。然后我们再调用一下下单接口，过一段时间，图表的数据就会自动更新和展示： 接着添加一下项目中使用的Timer的Meter，便于监控方法的执行时间，完成之后大致如下： 文章作者:throwable 文章链接:http://www.throwable.club/2018/11/17/jvm-micrometer-prometheus/ 版权声明:本博客所有文章除特别声明外，均采用CC BY-NC-SA 4.0许可协议。转载请注明来自Throwable！","link":"/2019/08/13/%E7%BB%99%E4%BD%A0%E7%9A%84SpringBoot%E5%81%9A%E5%9F%8B%E7%82%B9%E7%9B%91%E6%8E%A7-JVM%E5%BA%94%E7%94%A8%E5%BA%A6%E9%87%8F%E6%A1%86%E6%9E%B6Micrometer/"},{"title":"Java 设计模式","text":"设计模式是对大家实际工作中写的各种代码进行高层次抽象的总结 设计模式分为 23 种经典的模式，根据用途我们又可以分为三大类。分别是创建型模式、结构型模式和行为型模式 列举几种设计原则，这几种设计原则将贯通全文： 面向接口编程，而不是面向实现。这个尤为重要，也是优雅的、可扩展的代码的第一步，这就不需要多说了吧 职责单一原则。每个类都应该只有一个单一的功能，并且该功能应该由这个类完全封装起来 对修改关闭，对扩展开放。对修改关闭是说，我们辛辛苦苦加班写出来的代码，该实现的功能和该修复的 bug 都完成了，别人可不能说改就改；对扩展开放就比较好理解了，也就是说在我们写好的代码基础上，很容易实现扩展。 创建型模式 创建型模式的作用就是创建对象，new 一个对象，然后 set 相关属性。但是，在很多场景下，我们需要给客户端提供更加友好的创建对象的方式，尤其是那种我们定义了类，但是需要提供给其他开发者用的时候。 简单工厂模式 和名字一样简单，非常简单，直接上代码吧： 12345678910111213141516public class FoodFactory { public static Food makeFood(String name) { if (name.equals(&quot;noodle&quot;)) { Food noodle = new LanZhouNoodle(); noodle.addSpicy(&quot;more&quot;); return noodle; } else if (name.equals(&quot;chicken&quot;)) { Food chicken = new HuangMenChicken(); chicken.addCondiment(&quot;potato&quot;); return chicken; } else { return null; } }} 其中，LanZhouNoodle 和 HuangMenChicken 都继承自 Food。 简单地说，简单工厂模式通常就是这样，一个工厂类 XxxFactory，里面有一个静态方法，根据我们不同的参数，返回不同的派生自同一个父类（或实现同一接口）的实例对象。 我们强调职责单一原则，一个类只提供一种功能，FoodFactory 的功能就是只要负责生产各种 Food。 工厂模式 简单工厂模式很简单，如果它能满足我们的需要，我觉得就不要折腾了。之所以需要引入工厂模式，是因为我们往往需要使用两个或两个以上的工厂。 1234567891011121314151617181920212223242526272829public interface FoodFactory { Food makeFood(String name);}public class ChineseFoodFactory implements FoodFactory { @Override public Food makeFood(String name) { if (name.equals(&quot;A&quot;)) { return new ChineseFoodA(); } else if (name.equals(&quot;B&quot;)) { return new ChineseFoodB(); } else { return null; } }}public class AmericanFoodFactory implements FoodFactory { @Override public Food makeFood(String name) { if (name.equals(&quot;A&quot;)) { return new AmericanFoodA(); } else if (name.equals(&quot;B&quot;)) { return new AmericanFoodB(); } else { return null; } }} 其中，ChineseFoodA、ChineseFoodB、AmericanFoodA、AmericanFoodB 都派生自 Food。 客户端调用： 123456789public class APP { public static void main(String[] args) { // 先选择一个具体的工厂 FoodFactory factory = new ChineseFoodFactory(); // 由第一步的工厂产生具体的对象，不同的工厂造出不一样的对象 Food food = factory.makeFood(&quot;A&quot;); }} 虽然都是调用 makeFood(“A”) 制作 A 类食物，但是，不同的工厂生产出来的完全不一样。 第一步，我们需要选取合适的工厂，然后第二步基本上和简单工厂一样。 核心在于，我们需要在第一步选好我们需要的工厂。比如，我们有 LogFactory 接口，实现类有 FileLogFactory 和 KafkaLogFactory，分别对应将日志写入文件和写入 Kafka 中，显然，我们客户端第一步就需要决定到底要实例化 FileLogFactory 还是 KafkaLogFactory，这将决定之后的所有的操作。 虽然简单，不过我也把所有的构件都画到一张图上，这样看着比较清晰： 抽象工厂模式 当涉及到产品族的时候，就需要引入抽象工厂模式了。 一个经典的例子是造一台电脑。我们先不引入抽象工厂模式，看看怎么实现。 因为电脑是由许多的构件组成的，我们将 CPU 和主板进行抽象，然后 CPU 由 CPUFactory 生产，主板由 MainBoardFactory 生产，然后，我们再将 CPU 和主板搭配起来组合在一起，如下图： 这个时候的客户端调用是这样的： 12345678910// 得到 Intel 的 CPUCPUFactory cpuFactory = new IntelCPUFactory();CPU cpu = intelCPUFactory.makeCPU();// 得到 AMD 的主板MainBoardFactory mainBoardFactory = new AmdMainBoardFactory();MainBoard mainBoard = mainBoardFactory.make();// 组装 CPU 和主板Computer computer = new Computer(cpu, mainBoard); 单独看 CPU 工厂和主板工厂，它们分别是前面我们说的工厂模式。这种方式也容易扩展，因为要给电脑加硬盘的话，只需要加一个 HardDiskFactory 和相应的实现即可，不需要修改现有的工厂。 但是，这种方式有一个问题，那就是如果** Intel 家产的 CPU 和 AMD 产的主板不能兼容使用**，那么这代码就容易出错，因为客户端并不知道它们不兼容，也就会错误地出现随意组合。 -下面就是我们要说的产品族的概念，它代表了组成某个产品的一系列附件的集合： 当涉及到这种产品族的问题的时候，就需要抽象工厂模式来支持了。我们不再定义 CPU 工厂、主板工厂、硬盘工厂、显示屏工厂等等，我们直接定义电脑工厂，每个电脑工厂负责生产所有的设备，这样能保证肯定不存在兼容问题。 这个时候，对于客户端来说，不再需要单独挑选 CPU厂商、主板厂商、硬盘厂商等，直接选择一家品牌工厂，品牌工厂会负责生产所有的东西，而且能保证肯定是兼容可用的。 12345678910111213public static void main(String[] args) { // 第一步就要选定一个“大厂” ComputerFactory cf = new AmdFactory(); // 从这个大厂造 CPU CPU cpu = cf.makeCPU(); // 从这个大厂造主板 MainBoard board = cf.makeMainBoard(); // 从这个大厂造硬盘 HardDisk hardDisk = cf.makeHardDisk(); // 将同一个厂子出来的 CPU、主板、硬盘组装在一起 Computer result = new Computer(cpu, board, hardDisk);} 当然，抽象工厂的问题也是显而易见的，比如我们要加个显示器，就需要修改所有的工厂，给所有的工厂都加上制造显示器的方法。这有点违反了对修改关闭，对扩展开放这个设计原则。 单例模式 单例模式用得最多，错得最多。 饿汉模式最简单： 12345678910111213public class Singleton { // 首先，将 new Singleton() 堵死 private Singleton() {}; // 创建私有静态实例，意味着这个类第一次使用的时候就会进行创建 private static Singleton instance = new Singleton(); public static Singleton getInstance() { return instance; } // 瞎写一个静态方法。这里想说的是，如果我们只是要调用 Singleton.getDate(...)， // 本来是不想要生成 Singleton 实例的，不过没办法，已经生成了 public static Date getDate(String mode) {return new Date();}} 很多人都能说出饿汉模式的缺点，可是我觉得生产过程中，很少碰到这种情况：你定义了一个单例的类，不需要其实例，可是你却把一个或几个你会用到的静态方法塞到这个类中。 饱汉模式最容易出错： 12345678910111213141516171819public class Singleton { // 首先，也是先堵死 new Singleton() 这条路 private Singleton() {} // 和饿汉模式相比，这边不需要先实例化出来，注意这里的 volatile，它是必须的 private static volatile Singleton instance = null; public static Singleton getInstance() { if (instance == null) { // 加锁 synchronized (Singleton.class) { // 这一次判断也是必须的，不然会有并发问题 if (instance == null) { instance = new Singleton(); } } } return instance; }} 双重检查，指的是两次检查 instance 是否为 null。volatile 在这里是需要的，希望能引起读者的关注。很多人不知道怎么写，直接就在 getInstance() 方法签名上加上 synchronized，这就不多说了，性能太差。 嵌套类最经典，以后大家就用它吧： 1234567891011public class Singleton3 { private Singleton3() {} // 主要是使用了 嵌套类可以访问外部类的静态属性和静态方法 的特性 private static class Holder { private static Singleton3 instance = new Singleton3(); } public static Singleton3 getInstance() { return Holder.instance; }} 注意，很多人都会把这个嵌套类说成是静态内部类，严格地说，内部类和嵌套类是不一样的，它们能访问的外部类权限也是不一样的。 最后，一定有人跳出来说用枚举实现单例，是的没错，枚举类很特殊，它在类加载的时候会初始化里面的所有的实例，而且 JVM 保证了它们不会再被实例化，所以它天生就是单例的。不说了，读者自己看着办吧，不建议使用。 建造者模式 经常碰见的 XxxBuilder 的类，通常都是建造者模式的产物。建造者模式其实有很多的变种，但是对于客户端来说，我们的使用通常都是一个模式的 12Food food = new FoodBuilder().a().b().c().build();Food food = Food.builder().a().b().c().build(); 套路就是先 new 一个 Builder，然后可以链式地调用一堆方法，最后再调用一次 build() 方法，我们需要的对象就有了。 来一个中规中矩的建造者模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class User { // 下面是“一堆”的属性 private String name; private String password; private String nickName; private int age; // 构造方法私有化，不然客户端就会直接调用构造方法了 private User(String name, String password, String nickName, int age) { this.name = name; this.password = password; this.nickName = nickName; this.age = age; } // 静态方法，用于生成一个 Builder，这个不一定要有，不过写这个方法是一个很好的习惯， // 有些代码要求别人写 new User.UserBuilder().a()...build() 看上去就没那么好 public static UserBuilder builder() { return new UserBuilder(); } public static class UserBuilder { // 下面是和 User 一模一样的一堆属性 private String name; private String password; private String nickName; private int age; private UserBuilder() { } // 链式调用设置各个属性值，返回 this，即 UserBuilder public UserBuilder name(String name) { this.name = name; return this; } public UserBuilder password(String password) { this.password = password; return this; } public UserBuilder nickName(String nickName) { this.nickName = nickName; return this; } public UserBuilder age(int age) { this.age = age; return this; } // build() 方法负责将 UserBuilder 中设置好的属性“复制”到 User 中。 // 当然，可以在 “复制” 之前做点检验 public User build() { if (name == null || password == null) { throw new RuntimeException(&quot;用户名和密码必填&quot;); } if (age &lt;= 0 || age &gt;= 150) { throw new RuntimeException(&quot;年龄不合法&quot;); } // 还可以做赋予”默认值“的功能 if (nickName == null) { nickName = name; } return new User(name, password, nickName, age); } }} 核心是：先把所有的属性都设置给 Builder，然后 build() 方法的时候，将这些属性复制给实际产生的对象。 看看客户端的调用： 12345678910public class APP { public static void main(String[] args) { User d = User.builder() .name(&quot;foo&quot;) .password(&quot;pAss12345&quot;) .age(25) .build(); }} 说实话，建造者模式的链式写法很吸引人，但是，多写了很多“无用”的 builder 的代码，感觉这个模式没什么用。不过，当属性很多，而且有些必填，有些选填的时候，这个模式会使代码清晰很多。我们可以在 Builder 的构造方法中强制让调用者提供必填字段，还有，在 build() 方法中校验各个参数比在 User 的构造方法中校验，代码要优雅一些。 题外话，强烈建议读者使用 lombok，用了 lombok 以后，上面的一大堆代码会变成如下这样: 12345678@Builderclass User { private String name; private String password; private String nickName; private int age;} 怎么样，省下来的时间是不是又可以干点别的了。 当然，如果你只是想要链式写法，不想要建造者模式，有个很简单的办法，User 的 getter 方法不变，所有的 setter 方法都让其 *return this 就可以了，然后就可以像下面这样调用： 12User user = new User().setName(&quot;&quot;).setPassword(&quot;&quot;).setAge(20); 原型模式 这是我要说的创建型模式的最后一个设计模式了。 原型模式很简单：有一个原型实例，基于这个原型实例产生新的实例，也就是“克隆”了。 Object 类中有一个 clone() 方法，它用于生成一个新的对象，当然，如果我们要调用这个方法，java 要求我们的类必须先实现 Cloneable 接口，此接口没有定义任何方法，但是不这么做的话，在 clone() 的时候，会抛出 CloneNotSupportedException 异常。 12protected native Object clone() throws CloneNotSupportedException; java 的克隆是浅克隆，碰到对象引用的时候，克隆出来的对象和原对象中的引用将指向同一个对象。通常实现深克隆的方法是将对象进行序列化，然后再进行反序列化。 原型模式了解到这里我觉得就够了，各种变着法子说这种代码或那种代码是原型模式，没什么意义。 创建型模式总结 创建型模式总体上比较简单，它们的作用就是为了产生实例对象，算是各种工作的第一步了，因为我们写的是面向对象的代码，所以我们第一步当然是需要创建一个对象了。 简单工厂模式最简单；工厂模式在简单工厂模式的基础上增加了选择工厂的维度，需要第一步选择合适的工厂；抽象工厂模式有产品族的概念，如果各个产品是存在兼容性问题的，就要用抽象工厂模式。单例模式就不说了，为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源；建造者模式专门对付属性很多的那种类，为了让代码更优美；原型模式用得最少，了解和 Object 类中的 clone() 方法相关的知识即可。 结构型模式 前面创建型模式介绍了创建对象的一些设计模式，这节介绍的结构型模式旨在通过改变代码结构来达到解耦的目的，使得我们的代码容易维护和扩展。 代理模式 第一个要介绍的代理模式是最常使用的模式之一了，用一个代理来隐藏具体实现类的实现细节，通常还用于在真实的实现的前后添加一部分逻辑。 既然说是代理，那就要对客户端隐藏真实实现，由代理来负责客户端的所有请求。当然，代理只是个代理，它不会完成实际的业务逻辑，而是一层皮而已，但是对于客户端来说，它必须表现得就是客户端需要的真实实现。 理解代理这个词，这个模式其实就简单了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface FoodService { Food makeChicken(); Food makeNoodle();}public class FoodServiceImpl implements FoodService { public Food makeChicken() { Food f = new Chicken() f.setChicken(&quot;1kg&quot;); f.setSpicy(&quot;1g&quot;); f.setSalt(&quot;3g&quot;); return f; } public Food makeNoodle() { Food f = new Noodle(); f.setNoodle(&quot;500g&quot;); f.setSalt(&quot;5g&quot;); return f; }}// 代理要表现得“就像是”真实实现类，所以需要实现 FoodServicepublic class FoodServiceProxy implements FoodService { // 内部一定要有一个真实的实现类，当然也可以通过构造方法注入 private FoodService foodService = new FoodServiceImpl(); public Food makeChicken() { System.out.println(&quot;我们马上要开始制作鸡肉了&quot;); // 如果我们定义这句为核心代码的话，那么，核心代码是真实实现类做的， // 代理只是在核心代码前后做些“无足轻重”的事情 Food food = foodService.makeChicken(); System.out.println(&quot;鸡肉制作完成啦，加点胡椒粉&quot;); // 增强 food.addCondiment(&quot;pepper&quot;); return food; } public Food makeNoodle() { System.out.println(&quot;准备制作拉面~&quot;); Food food = foodService.makeNoodle(); System.out.println(&quot;制作完成啦&quot;) return food; }} 客户端调用，注意，我们要用代理来实例化接口： 1234// 这里用代理类来实例化FoodService foodService = new FoodServiceProxy();foodService.makeChicken(); 我们发现没有，代理模式说白了就是做 “方法包装” 或做 “方法增强”。在面向切面编程中，算了还是不要吹捧这个名词了，在 AOP 中，其实就是动态代理的过程。比如 Spring 中，我们自己不定义代理类，但是 Spring 会帮我们动态来定义代理，然后把我们定义在 @Before、@After、@Around 中的代码逻辑动态添加到代理中。 说到动态代理，又可以展开说 …… Spring 中实现动态代理有两种，一种是如果我们的类定义了接口，如 UserService 接口和 UserServiceImpl 实现，那么采用 JDK 的动态代理，感兴趣的读者可以去看看 java.lang.reflect.Proxy 类的源码；另一种是我们自己没有定义接口的，Spring 会采用 CGLIB 进行动态代理，它是一个 jar 包，性能还不错。 适配器模式 说完代理模式，说适配器模式，是因为它们很相似，这里可以做个比较。 适配器模式做的就是，有一个接口需要实现，但是我们现成的对象都不满足，需要加一层适配器来进行适配 适配器模式总体来说分三种：默认适配器模式、对象适配器模式、类适配器模式。先不急着分清楚这几个，先看看例子再说。 默认适配器模式 首先，我们先看看最简单的适配器模式**默认适配器模式(Default Adapter)**是怎么样的。 我们用 Appache commons-io 包中的 FileAlterationListener 做例子，此接口定义了很多的方法，用于对文件或文件夹进行监控，一旦发生了对应的操作，就会触发相应的方法。 1234567891011public interface FileAlterationListener { void onStart(final FileAlterationObserver observer); void onDirectoryCreate(final File directory); void onDirectoryChange(final File directory); void onDirectoryDelete(final File directory); void onFileCreate(final File file); void onFileChange(final File file); void onFileDelete(final File file); void onStop(final FileAlterationObserver observer);} 此接口的一大问题是抽象方法太多了，如果我们要用这个接口，意味着我们要实现每一个抽象方法，如果我们只是想要监控文件夹中的文件创建和文件删除事件，可是我们还是不得不实现所有的方法，很明显，这不是我们想要的。 所以，我们需要下面的一个适配器，它用于实现上面的接口，但是所有的方法都是空方法，这样，我们就可以转而定义自己的类来继承下面这个类即可。 123456789101112131415161718192021222324252627public class FileAlterationListenerAdaptor implements FileAlterationListener { public void onStart(final FileAlterationObserver observer) { } public void onDirectoryCreate(final File directory) { } public void onDirectoryChange(final File directory) { } public void onDirectoryDelete(final File directory) { } public void onFileCreate(final File file) { } public void onFileChange(final File file) { } public void onFileDelete(final File file) { } public void onStop(final FileAlterationObserver observer) { }} 比如我们可以定义以下类，我们仅仅需要实现我们想实现的方法就可以了： 1234567891011public class FileMonitor extends FileAlterationListenerAdaptor { public void onFileCreate(final File file) { // 文件创建 doSomething(); } public void onFileDelete(final File file) { // 文件删除 doSomething(); }} 当然，上面说的只是适配器模式的其中一种，也是最简单的一种，无需多言。下面，再介绍“正统的”适配器模式。 对象适配器模式 来看一个《Head First 设计模式》中的一个例子，我稍微修改了一下，看看怎么将鸡适配成鸭，这样鸡也能当鸭来用。因为，现在鸭这个接口，我们没有合适的实现类可以用，所以需要适配器。 12345678910111213141516171819public interface Duck { public void quack(); // 鸭的呱呱叫 public void fly(); // 飞}public interface Cock { public void gobble(); // 鸡的咕咕叫 public void fly(); // 飞}public class WildCock implements Cock { public void gobble() { System.out.println(&quot;咕咕叫&quot;); } public void fly() { System.out.println(&quot;鸡也会飞哦&quot;); }} 鸭接口有 fly() 和 quare() 两个方法，鸡 Cock 如果要冒充鸭，fly() 方法是现成的，但是鸡不会鸭的呱呱叫，没有 quack() 方法。这个时候就需要适配了： 12345678910111213141516171819202122// 毫无疑问，首先，这个适配器肯定需要 implements Duck，这样才能当做鸭来用public class CockAdapter implements Duck { Cock cock; // 构造方法中需要一个鸡的实例，此类就是将这只鸡适配成鸭来用 public CockAdapter(Cock cock) { this.cock = cock; } // 实现鸭的呱呱叫方法 @Override public void quack() { // 内部其实是一只鸡的咕咕叫 cock.gobble(); } @Override public void fly() { cock.fly(); }} 客户端调用很简单了： 12345678public static void main(String[] args) { // 有一只野鸡 Cock wildCock = new WildCock(); // 成功将野鸡适配成鸭 Duck duck = new CockAdapter(wildCock); ...} 到这里，大家也就知道了适配器模式是怎么回事了。无非是我们需要一只鸭，但是我们只有一只鸡，这个时候就需要定义一个适配器，由这个适配器来充当鸭，但是适配器里面的方法还是由鸡来实现的。 我们用一个图来简单说明下： 上图应该还是很容易理解的，我就不做更多的解释了。下面，我们看看类适配模式怎么样的。 类适配器模式 废话少说，直接上图： 看到这个图，大家应该很容易理解的吧，通过继承的方法，适配器自动获得了所需要的大部分方法。这个时候，客户端使用更加简单，直接 Target t = new SomeAdapter(); 就可以了。 适配器模式总结 类适配和对象适配的异同 一个采用继承，一个采用组合； 类适配属于静态实现，对象适配属于组合的动态实现，对象适配需要多实例化一个对象。 总体来说，对象适配用得比较多。 适配器模式和代理模式的异同 比较这两种模式，其实是比较对象适配器模式和代理模式，在代码结构上，它们很相似，都需要一个具体的实现类的实例。但是它们的目的不一样，代理模式做的是增强原方法的活；适配器做的是适配的活，为的是提供“把鸡包装成鸭，然后当做鸭来使用”，而鸡和鸭它们之间原本没有继承关系。 桥梁模式 理解桥梁模式，其实就是理解代码抽象和解耦。 我们首先需要一个桥梁，它是一个接口，定义提供的接口方法。 123public interface DrawAPI { public void draw(int radius, int x, int y);} 然后是一系列实现类： 123456789101112131415161718public class RedPen implements DrawAPI { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用红色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }}public class GreenPen implements DrawAPI { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用绿色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }}public class BluePen implements DrawAPI { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用蓝色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }} 定义一个抽象类，此类的实现类都需要使用 DrawAPI： 12345678public abstract class Shape { protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI){ this.drawAPI = drawAPI; } public abstract void draw(); } 定义抽象类的子类：12345678910111213141516171819202122232425262728// 圆形public class Circle extends Shape { private int radius; public Circle(int radius, DrawAPI drawAPI) { super(drawAPI); this.radius = radius; } public void draw() { drawAPI.draw(radius, 0, 0); }}// 长方形public class Rectangle extends Shape { private int x; private int y; public Rectangle(int x, int y, DrawAPI drawAPI) { super(drawAPI); this.x = x; this.y = y; } public void draw() { drawAPI.draw(0, x, y); }} 最后，我们来看客户端演示： 12345678public static void main(String[] args) { Shape greenCircle = new Circle(10, new GreenPen()); Shape redRectangle = new Rectangle(4, 8, new RedPen()); greenCircle.draw(); redRectangle.draw();} 可能大家看上面一步步还不是特别清晰，我把所有的东西整合到一张图上： 这回大家应该就知道抽象在哪里，怎么解耦了吧。桥梁模式的优点也是显而易见的，就是非常容易进行扩展。 装饰模式 要把装饰模式说清楚明白，不是件容易的事情。也许读者知道 Java IO 中的几个类是典型的装饰模式的应用，但是读者不一定清楚其中的关系，也许看完就忘了，希望看完这节后，读者可以对其有更深的感悟。 首先，我们先看一个简单的图，看这个图的时候，了解下层次结构就可以了： 我们来说说装饰模式的出发点，从图中可以看到，接口 Component 其实已经有了 ConcreteComponentA 和 ConcreteComponentB 两个实现类了，但是，如果我们要增强这两个实现类的话，我们就可以采用装饰模式，用具体的装饰器来装饰实现类，以达到增强的目的。 从名字来简单解释下装饰器。既然说是装饰，那么往往就是添加小功能这种，而且，我们要满足可以添加多个小功能。最简单的，代理模式就可以实现功能的增强，但是代理不容易实现多个功能的增强，当然你可以说用代理包装代理的方式，但是那样的话代码就复杂了。 首先明白一些简单的概念，从图中我们看到，所有的具体装饰者们 ConcreteDecorator 都可以作为 Component 来使用，因为它们都实现了 Component 中的所有接口。它们和 Component 实现类 ConcreteComponent 的区别是，它们只是装饰者，起装饰作用，也就是即使它们看上去牛逼轰轰，但是它们都只是在具体的实现中加了层皮来装饰而已。 注意这段话中混杂在各个名词中的 Component 和 Decorator，别搞混了。 下面来看看一个例子，先把装饰模式弄清楚，然后再介绍下 java io 中的装饰模式的应用。 最近大街上流行起来了“快乐柠檬”，我们把快乐柠檬的饮料分为三类：红茶、绿茶、咖啡，在这三大类的基础上，又增加了许多的口味，什么金桔柠檬红茶、金桔柠檬珍珠绿茶、芒果红茶、芒果绿茶、芒果珍珠红茶、烤珍珠红茶、烤珍珠芒果绿茶、椰香胚芽咖啡、焦糖可可咖啡等等，每家店都有很长的菜单，但是仔细看下，其实原料也没几样，但是可以搭配出很多组合，如果顾客需要，很多没出现在菜单中的饮料他们也是可以做的。 在这个例子中，红茶、绿茶、咖啡是最基础的饮料，其他的像金桔柠檬、芒果、珍珠、椰果、焦糖等都属于装饰用的。当然，在开发中，我们确实可以像门店一样，开发这些类：LemonBlackTea、LemonGreenTea、MangoBlackTea、MangoLemonGreenTea……但是，很快我们就发现，这样子干肯定是不行的，这会导致我们需要组合出所有的可能，而且如果客人需要在红茶中加双份柠檬怎么办？三份柠檬怎么办？万一有个变态要四份柠檬，所以这种做法是给自己找加班的。 不说废话了，上代码。 首先，定义饮料抽象基类： 123456public abstract class Beverage { // 返回描述 public abstract String getDescription(); // 返回价格 public abstract double cost();} 然后是三个基础饮料实现类，红茶、绿茶和咖啡： 1234567891011121314151617public class BlackTea extends Beverage { public String getDescription() { return &quot;红茶&quot;; } public double cost() { return 10; }}public class GreenTea extends Beverage { public String getDescription() { return &quot;绿茶&quot;; } public double cost() { return 11; }}...// 咖啡省略 定义调料，也就是装饰者的基类，此类必须继承自 Beverage： 12345// 调料public abstract class Condiment extends Beverage {} 然后我们来定义柠檬、芒果等具体的调料，它们属于装饰者，毫无疑问，这些调料肯定都需要继承 Condiment 类： 1234567891011121314151617181920212223242526272829public class Lemon extends Condiment { private Beverage bevarage; // 这里很关键，需要传入具体的饮料，如需要传入没有被装饰的红茶或绿茶， // 当然也可以传入已经装饰好的芒果绿茶，这样可以做芒果柠檬绿茶 public Lemon(Beverage bevarage) { this.bevarage = bevarage; } public String getDescription() { // 装饰 return bevarage.getDescription() + &quot;, 加柠檬&quot;; } public double cost() { // 装饰 return beverage.cost() + 2; // 加柠檬需要 2 元 }}public class Mango extends Condiment { private Beverage bevarage; public Mango(Beverage bevarage) { this.bevarage = bevarage; } public String getDescription() { return bevarage.getDescription() + &quot;, 加芒果&quot;; } public double cost() { return beverage.cost() + 3; // 加芒果需要 3 元 }}...// 给每一种调料都加一个类 看客户端调用 12345678910public static void main(String[] args) { // 首先，我们需要一个基础饮料，红茶、绿茶或咖啡 Beverage beverage = new GreenTea(); // 开始装饰 beverage = new Lemon(beverage); // 先加一份柠檬 beverage = new Mongo(beverage); // 再加一份芒果 System.out.println(beverage.getDescription() + &quot; 价格：￥&quot; + beverage.cost()); //&quot;绿茶, 加柠檬, 加芒果 价格：￥16&quot;} 如果我们需要芒果珍珠双份柠檬红茶： 1Beverage beverage = new Mongo(new Pearl(new Lemon(new Lemon(new BlackTea())))); 是不是很变态？ 看看下图可能会清晰一些： 到这里，大家应该已经清楚装饰模式了吧。 下面，我们再来说说 java IO 中的装饰模式。看下图 InputStream 派生出来的部分类 我们知道 InputStream 代表了输入流，具体的输入来源可以是文件（FileInputStream）、管道（PipedInputStream）、数组（ByteArrayInputStream）等，这些就像前面奶茶的例子中的红茶、绿茶，属于基础输入流。 FilterInputStream 承接了装饰模式的关键节点，其实现类是一系列装饰器，比如 BufferedInputStream 代表用缓冲来装饰，也就使得输入流具有了缓冲的功能，LineNumberInputStream 代表用行号来装饰，在操作的时候就可以取得行号了，DataInputStream 的装饰，使得我们可以从输入流转换为 java 中的基本类型值。 当然，在 java IO 中，如果我们使用装饰器的话，就不太适合面向接口编程了，如： 1InputStream inputStream = new LineNumberInputStream(new BufferedInputStream(new FileInputStream(&quot;&quot;))); 这样的结果是，InputStream 还是不具有读取行号的功能，因为读取行号的方法定义在 LineNumberInputStream 类中。 我们应该像下面这样使用： 1234DataInputStream is = new DataInputStream( new BufferedInputStream( new FileInputStream(&quot;&quot;))); 所以说嘛，要找到纯的严格符合设计模式的代码还是比较难的 门面模式 门面模式（也叫外观模式，Facade Pattern）在许多源码中有使用，比如 slf4j 就可以理解为是门面模式的应用。这是一个简单的设计模式，我们直接上代码再说吧。 首先，我们定义一个接口： 1234public interface Shape { void draw();} 定义几个实现类：12345678910111213141516public class Circle implements Shape { @Override public void draw() { System.out.println(&quot;Circle::draw()&quot;); }}public class Rectangle implements Shape { @Override public void draw() { System.out.println(&quot;Rectangle::draw()&quot;); }} 客户端调用： 12345678910public static void main(String[] args) { // 画一个圆形 Shape circle = new Circle(); circle.draw(); // 画一个长方形 Shape rectangle = new Rectangle(); rectangle.draw();} 以上是我们常写的代码，我们需要画圆就要先实例化圆，画长方形就需要先实例化一个长方形，然后再调用相应的 draw() 方法。 下面，我们看看怎么用门面模式来让客户端调用更加友好一些。 我们先定义一个门面： 1234567891011121314151617181920212223242526public class ShapeMaker { private Shape circle; private Shape rectangle; private Shape square; public ShapeMaker() { circle = new Circle(); rectangle = new Rectangle(); square = new Square(); } /** * 下面定义一堆方法，具体应该调用什么方法，由这个门面来决定 */ public void drawCircle(){ circle.draw(); } public void drawRectangle(){ rectangle.draw(); } public void drawSquare(){ square.draw(); }} 看看现在客户端怎么调用： 123456789public static void main(String[] args) { ShapeMaker shapeMaker = new ShapeMaker(); // 客户端调用现在更加清晰了 shapeMaker.drawCircle(); shapeMaker.drawRectangle(); shapeMaker.drawSquare(); } 门面模式的优点显而易见，客户端不再需要关注实例化时应该使用哪个实现类，直接调用门面提供的方法就可以了，因为门面类提供的方法的方法名对于客户端来说已经很友好了。 组合模式 组合模式用于表示具有层次结构的数据，使得我们对单个对象和组合对象的访问具有一致性。 直接看一个例子吧，每个员工都有姓名、部门、薪水这些属性，同时还有下属员工集合（虽然可能集合为空），而下属员工和自己的结构是一样的，也有姓名、部门这些属性，同时也有他们的下属员工集合。 1234567891011121314151617181920212223242526272829public class Employee { private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; // 下属 public Employee(String name,String dept, int sal) { this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); } public void add(Employee e) { subordinates.add(e); } public void remove(Employee e) { subordinates.remove(e); } public List&lt;Employee&gt; getSubordinates(){ return subordinates; } public String toString(){ return (&quot;Employee :[ Name : &quot; + name + &quot;, dept : &quot; + dept + &quot;, salary :&quot; + salary+&quot; ]&quot;); } } 通常，这种类需要定义 add(node)、remove(node)、getChildren() 这些方法。 这说的其实就是组合模式，这种简单的模式我就不做过多介绍了，相信各位读者也不喜欢看我写废话。 享元模式 英文是 Flyweight Pattern，不知道是谁最先翻译的这个词，感觉这翻译真的不好理解，我们试着强行关联起来吧。Flyweight 是轻量级的意思，享元分开来说就是 共享 元器件，也就是复用已经生成的对象，这种做法当然也就是轻量级的了。 复用对象最简单的方式是，用一个 HashMap 来存放每次新生成的对象。每次需要一个对象的时候，先到 HashMap 中看看有没有，如果没有，再生成新的对象，然后将这个对象放入 HashMap 中。 这种简单的代码我就不演示了。 结构型模式总结 前面，我们说了代理模式、适配器模式、桥梁模式、装饰模式、门面模式、组合模式和享元模式。读者是否可以分别把这几个模式说清楚了呢？在说到这些模式的时候，心中是否有一个清晰的图或处理流程在脑海里呢？ 代理模式是做方法增强的，适配器模式是把鸡包装成鸭这种用来适配接口的，桥梁模式做到了很好的解耦，装饰模式从名字上就看得出来，适合于装饰类或者说是增强类的场景，门面模式的优点是客户端不需要关心实例化过程，只要调用需要的方法即可，组合模式用于描述具有层次结构的数据，享元模式是为了在特定的场景中缓存已经创建的对象，用于提高性能。 行为型模式 行为型模式关注的是各个类之间的相互作用，将职责划分清楚，使得我们的代码更加地清晰。 策略模式 策略模式太常用了，所以把它放到最前面进行介绍。它比较简单，我就不废话，直接用代码说事吧。 下面设计的场景是，我们需要画一个图形，可选的策略就是用红色笔来画，还是绿色笔来画，或者蓝色笔来画。 首先，先定义一个策略接口： 123public interface Strategy { public void draw(int radius, int x, int y);} 然后我们定义具体的几个策略： 12345678910111213141516171819public class RedPen implements Strategy { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用红色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }}public class GreenPen implements Strategy { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用绿色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }}public class BluePen implements Strategy { @Override public void draw(int radius, int x, int y) { System.out.println(&quot;用蓝色笔画图，radius:&quot; + radius + &quot;, x:&quot; + x + &quot;, y:&quot; + y); }} 使用策略的类：1234567891011public class Context { private Strategy strategy; public Context(Strategy strategy){ this.strategy = strategy; } public int executeDraw(int radius, int x, int y){ return strategy.draw(radius, x, y); }} 客户端演示： 12345public static void main(String[] args) { Context context = new Context(new BluePen()); // 使用绿色笔来画 context.executeDraw(10, 0, 0);} 放到一张图上，让大家看得清晰些： 这个时候，大家有没有联想到结构型模式中的桥梁模式，它们其实非常相似，我把桥梁模式的图拿过来大家对比下： 要我说的话，它们非常相似，桥梁模式在左侧加了一层抽象而已。桥梁模式的耦合更低，结构更复杂一些。 观察者模式 观察者模式对于我们来说，真是再简单不过了。无外乎两个操作，观察者订阅自己关心的主题和主题有数据变化后通知观察者们。 首先，需要定义主题，每个主题需要持有观察者列表的引用，用于在数据变更的时候通知各个观察者： 123456789101112131415161718192021222324252627public class Subject { private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() { return state; } public void setState(int state) { this.state = state; // 数据已变更，通知观察者们 notifyAllObservers(); } public void attach(Observer observer){ observers.add(observer); } // 通知观察者们 public void notifyAllObservers(){ for (Observer observer : observers) { observer.update(); } } } 定义观察者接口： 12345public abstract class Observer { protected Subject subject; public abstract void update();} 其实如果只有一个观察者类的话，接口都不用定义了，不过，通常场景下，既然用到了观察者模式，我们就是希望一个事件出来了，会有多个不同的类需要处理相应的信息。比如，订单修改成功事件，我们希望发短信的类得到通知、发邮件的类得到通知、处理物流信息的类得到通知等。 我们来定义具体的几个观察者类： 12345678910111213141516171819202122232425262728293031public class BinaryObserver extends Observer { // 在构造方法中进行订阅主题 public BinaryObserver(Subject subject) { this.subject = subject; // 通常在构造方法中将 this 发布出去的操作一定要小心 this.subject.attach(this); } // 该方法由主题类在数据变更的时候进行调用 @Override public void update() { String result = Integer.toBinaryString(subject.getState()); System.out.println(&quot;订阅的数据发生变化，新的数据处理为二进制值为：&quot; + result); }}public class HexaObserver extends Observer { public HexaObserver(Subject subject) { this.subject = subject; this.subject.attach(this); } @Override public void update() { String result = Integer.toHexString(subject.getState()).toUpperCase(); System.out.println(&quot;订阅的数据发生变化，新的数据处理为十六进制值为：&quot; + result); }} 客户端使用也非常简单： 1234567891011public static void main(String[] args) { // 先定义一个主题 Subject subject1 = new Subject(); // 定义观察者 new BinaryObserver(subject1); new HexaObserver(subject1); // 模拟数据变更，这个时候，观察者们的 update 方法将会被调用 subject.setState(11);} output: 123订阅的数据发生变化，新的数据处理为二进制值为：1011订阅的数据发生变化，新的数据处理为十六进制值为：B 当然，jdk 也提供了相似的支持，具体的大家可以参考 java.util.Observable 和 java.util.Observer 这两个类。 实际生产过程中，观察者模式往往用消息中间件来实现，如果要实现单机观察者模式，笔者建议读者使用 Guava 中的 EventBus，它有同步实现也有异步实现，本文主要介绍设计模式，就不展开说了。 责任链模式 责任链通常需要先建立一个单向链表，然后调用方只需要调用头部节点就可以了，后面会自动流转下去。比如流程审批就是一个很好的例子，只要终端用户提交申请，根据申请的内容信息，自动建立一条责任链，然后就可以开始流转了 有这么一个场景，用户参加一个活动可以领取奖品，但是活动需要进行很多的规则校验然后才能放行，比如首先需要校验用户是否是新用户、今日参与人数是否有限额、全场参与人数是否有限额等等。设定的规则都通过后，才能让用户领走奖品。 如果产品给你这个需求的话，我想大部分人一开始肯定想的就是，用一个 List 来存放所有的规则，然后 foreach 执行一下每个规则就好了。不过，读者也先别急，看看责任链模式和我们说的这个有什么不一样？ 首先，我们要定义流程上节点的基类： 123456789101112131415public abstract class RuleHandler { // 后继节点 protected RuleHandler successor; public abstract void apply(Context context); public void setSuccessor(RuleHandler successor) { this.successor = successor; } public RuleHandler getSuccessor() { return successor; }} 接下来，我们需要定义具体的每个节点了。 校验用户是否是新用户： 123456789101112131415public class NewUserRuleHandler extends RuleHandler { public void apply(Context context) { if (context.isNewUser()) { // 如果有后继节点的话，传递下去 if (this.getSuccessor() != null) { this.getSuccessor().apply(context); } } else { throw new RuntimeException(&quot;该活动仅限新用户参与&quot;); } }} 校验用户所在地区是否可以参与： 12345678910111213public class LocationRuleHandler extends RuleHandler { public void apply(Context context) { boolean allowed = activityService.isSupportedLocation(context.getLocation); if (allowed) { if (this.getSuccessor() != null) { this.getSuccessor().apply(context); } } else { throw new RuntimeException(&quot;非常抱歉，您所在的地区无法参与本次活动&quot;); } }} 校验奖品是否已领完： 12345678910111213public class LimitRuleHandler extends RuleHandler { public void apply(Context context) { int remainedTimes = activityService.queryRemainedTimes(context); // 查询剩余奖品 if (remainedTimes &gt; 0) { if (this.getSuccessor() != null) { this.getSuccessor().apply(userInfo); } } else { throw new RuntimeException(&quot;您来得太晚了，奖品被领完了&quot;); } }} 客户端： 12345678910public static void main(String[] args) { RuleHandler newUserHandler = new NewUserRuleHandler(); RuleHandler locationHandler = new LocationRuleHandler(); RuleHandler limitHandler = new LimitRuleHandler(); // 假设本次活动仅校验地区和奖品数量，不校验新老用户 locationHandler.setSuccessor(limitHandler); locationHandler.apply(context);} 代码其实很简单，就是先定义好一个链表，然后在通过任意一节点后，如果此节点有后继节点，那么传递下去。 至于它和我们前面说的用一个 List 存放需要执行的规则的做法有什么异同，留给读者自己琢磨吧。 模板方法模式 在含有继承结构的代码中，模板方法模式是非常常用的，这也是在开源代码中大量被使用的。 通常会有一个抽象类： 12345678910111213141516public abstract class AbstractTemplate { // 这就是模板方法 public void templateMethod(){ init(); apply(); // 这个是重点 end(); // 可以作为钩子方法 } protected void init() { System.out.println(&quot;init 抽象层已经实现，子类也可以选择覆写&quot;); } // 留给子类实现 protected abstract void apply(); protected void end() { }} 模板方法中调用了 3 个方法，其中 apply() 是抽象方法，子类必须实现它，其实模板方法中有几个抽象方法完全是自由的，我们也可以将三个方法都设置为抽象方法，让子类来实现。也就是说，模板方法只负责定义第一步应该要做什么，第二步应该做什么，第三步应该做什么，至于怎么做，由子类来实现。 我们写一个实现类：123456789public class ConcreteTemplate extends AbstractTemplate { public void apply() { System.out.println(&quot;子类实现抽象方法 apply&quot;); } public void end() { System.out.println(&quot;我们可以把 method3 当做钩子方法来使用，需要的时候覆写就可以了&quot;); }} 客户端调用演示： 123456public static void main(String[] args) { AbstractTemplate t = new ConcreteTemplate(); // 调用模板方法 t.templateMethod();} 代码其实很简单，基本上看到就懂了，关键是要学会用到自己的代码中。 状态模式 废话我就不说了，我们说一个简单的例子。商品库存中心有个最基本的需求是减库存和补库存，我们看看怎么用状态模式来写。 核心在于，我们的关注点不再是 Context 是该进行哪种操作，而是关注在这个 Context 会有哪些操作。 定义状态接口： 1234public interface State { public void doAction(Context context);} 定义减库存的状态：1234567891011121314public class DeductState implements State { public void doAction(Context context) { System.out.println(&quot;商品卖出，准备减库存&quot;); context.setState(this); //... 执行减库存的具体操作 } public String toString(){ return &quot;Deduct State&quot;; }} 定义补库存状态：123456789101112public class RevertState implements State { public void doAction(Context context) { System.out.println(&quot;给此商品补库存&quot;); context.setState(this); //... 执行加库存的具体操作 } public String toString() { return &quot;Revert State&quot;; }} 前面用到了 context.setState(this)，我们来看看怎么定义 Context 类： 123456789101112131415public class Context { private State state; private String name; public Context(String name) { this.name = name; } public void setState(State state) { this.state = state; } public void getState() { return this.state; }} 我们来看下客户端调用，大家就一清二楚了： 12345678910111213141516public static void main(String[] args) { // 我们需要操作的是 iPhone X Context context = new Context(&quot;iPhone X&quot;); // 看看怎么进行补库存操作 State revertState = new RevertState(); revertState.doAction(context); // 同样的，减库存操作也非常简单 State deductState = new DeductState(); deductState.doAction(context); // 如果需要我们可以获取当前的状态 // context.getState().toString();} 读者可能会发现，在上面这个例子中，如果我们不关心当前 context 处于什么状态，那么 Context 就可以不用维护 state 属性了，那样代码会简单很多。 不过，商品库存这个例子毕竟只是个例，我们还有很多实例是需要知道当前 context 处于什么状态的。 行为型模式总结 行为型模式部分介绍了策略模式、观察者模式、责任链模式、模板方法模式和状态模式，其实，经典的行为型模式还包括备忘录模式、命令模式等，但是它们的使用场景比较有限，而且本文篇幅也挺大了，我就不进行介绍了。 总结 学习设计模式的目的是为了让我们的代码更加的优雅、易维护、易扩展。这次整理这篇文章，让我重新审视了一下各个设计模式，对我自己而言收获还是挺大的。我想，文章的最大收益者一般都是作者本人，为了写一篇文章，需要巩固自己的知识，需要寻找各种资料，而且，自己写过的才最容易记住，也算是我给读者的建议吧。","link":"/2019/05/20/Java-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"Java集合框架","text":"前言 一、概述 集合框架图 Collection Map 工具类 通用实现 二、深入源码分析 ArrayList 1. 概览 2. 序列化 3. 扩容 4. 删除元素 5. Fail-Fast Vector 1. 同步 2. ArrayList 与 Vector 3. Vector 替代方案 synchronizedList CopyOnWriteArrayList LinkedList 1. 概览 2. add() 3. remove() 4. get() 5. 总结 6. ArrayList 与 LinkedList HashMap 1. 存储结构 JDK1.7 的存储结构 JDK1.8 的存储结构 2. 重要参数 3. 确定哈希桶数组索引位置 4. 分析HashMap的put方法 5. 扩容机制 6. 线程安全性 7. JDK1.8与JDK1.7的性能对比 8. Hash较均匀的情况 9. Hash极不均匀的情况 10. HashMap与HashTable 11. 小结 ConcurrentHashMap 1. 概述 2. 存储结构 2. size 操作 3. 同步方式 4. JDK 1.8 的改动 HashSet 1. 成员变量 2. 构造函数 3. add() 4. 总结 LinkedHashSet and LinkedHashMap 1. 概览 2. get() 3. put() 4. remove() 5. LinkedHashSet 6. LinkedHashMap经典用法 三、容器中的设计模式 迭代器模式 适配器模式 四、面试指南 1. ArrayList和LinkedList区别 2. HashMap和HashTable区别，HashMap的key类型 3. HashMap和ConcurrentHashMap 4. Hashtable的原理 5. Hash冲突的解决办法 6. 什么是迭代器 7. 构造相同hash的字符串进行攻击，这种情况应该怎么处理？JDK7如何处理 8. Hashmap为什么大小是2的幂次 更新日志 前言 Java集合框架 (Java Collections Framework, JCF) 也称容器，这里可以类比 C++ 中的 STL，在市面上似乎还没能找到一本详细介绍的书籍。在这里主要对如下部分进行源码分析，及在面试中常见的问题。 例如，在阿里面试常问到的 HashMap 和 ConcurrentHashMap 原理等等。深入源码分析是面试中必备的技能，通过本文的阅读会对集合框架有更深一步的了解。 本文参考： CarpenterLee/JCFInternals: 深入理解Java集合框架 crossoverJie/Java-Interview: 👨‍🎓 Java related : basic, concurrent, algorithm Interview-Notebook/Java 容器.md at master · CyC2018/Interview-Notebook 一、概述 Java集合框架提供了数据持有对象的方式，提供了对数据集合的操作。Java 集合框架位于 java.util 包下，主要有三个大类：Collection(接口)**、Map(接口)、集合工具类**。 集合框架图 Collection ArrayList：线程不同步。默认初始容量为 10，当数组大小不足时容量扩大为 1.5 倍。为追求效率，ArrayList 没有实现同步（synchronized），如果需要多个线程并发访问，用户可以手动同步，也可使用 Vector 替代。 LinkedList：线程不同步。双向链接实现。LinkedList 同时实现了 List 接口和 Deque 接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列（Queue），同时又可以看作一个栈（Stack）。这样看来，LinkedList 简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用 LinkedList，一方面是因为 Java 官方已经声明不建议使用 Stack 类，更遗憾的是，Java 里根本没有一个叫做 Queue 的类（它是个接口名字）。关于栈或队列，现在的首选是 ArrayDeque，它有着比 LinkedList（当作栈或队列使用时）有着更好的性能。 Stack and Queue：Java 里有一个叫做 Stack 的类，却没有叫做 Queue 的类（它是个接口名字）。当需要使用栈时，Java 已不推荐使用 Stack，而是推荐使用更高效的 ArrayDeque；既然 Queue 只是一个接口，当需要使用队列时也就首选 ArrayDeque 了（次选是 LinkedList ）。 Vector：线程同步。默认初始容量为 10，当数组大小不足时容量扩大为 2 倍。它的同步是通过 Iterator 方法加 synchronized 实现的。 Stack：线程同步。继承自 Vector，添加了几个方法来完成栈的功能。现在已经不推荐使用 Stack，在栈和队列中有限使用 ArrayDeque，其次是 LinkedList。 TreeSet：线程不同步，内部使用 NavigableMap 操作。默认元素 “自然顺序” 排列，可以通过 Comparator 改变排序。TreeSet 里面有一个 TreeMap（适配器模式） HashSet：线程不同步，内部使用 HashMap 进行数据存储，提供的方法基本都是调用 HashMap 的方法，所以两者本质是一样的。集合元素可以为 NULL。 Set：Set 是一种不包含重复元素的 Collection，Set 最多只有一个 null 元素。Set 集合通常可以通过 Map 集合通过适配器模式得到。 PriorityQueue：Java 中 PriorityQueue 实现了 Queue 接口，不允许放入 null 元素；其通过堆实现，具体说是通过完全二叉树（complete binary tree）实现的小顶堆（任意一个非叶子节点的权值，都不大于其左右子节点的权值），也就意味着可以通过数组来作为 PriorityQueue 的底层实现。 优先队列的作用是能保证每次取出的元素都是队列中权值最小的（Java 的优先队列每次取最小元素，C++ 的优先队列每次取最大元素）。这里牵涉到了大小关系，元素大小的评判可以通过元素本身的自然顺序（natural ordering），也可以通过构造时传入的比较器（Comparator，类似于 C++ 的仿函数）。 NavigableSet：添加了搜索功能，可以对给定元素进行搜索：小于、小于等于、大于、大于等于，放回一个符合条件的最接近给定元素的 key。 EnumSet：线程不同步。内部使用 Enum 数组实现，速度比 HashSet 快。只能存储在构造函数传入的枚举类的枚举值。 注释：更多设计模式，请转向 Java 设计模式 Map TreeMap：线程不同步，基于 红黑树 （Red-Black tree）的 NavigableMap 实现，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。 TreeMap 底层通过红黑树（Red-Black tree）实现，也就意味着 containsKey(), get(), put(), remove() 都有着 log(n) 的时间复杂度。其具体算法实现参照了《算法导论》。 HashTable：线程安全，HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器。HashTable 不能存储 NULL 的 key 和 value。 HashMap：线程不同步。根据 key 的 hashcode 进行存储，内部使用静态内部类 Node 的数组进行存储，默认初始大小为 16，每次扩大一倍。当发生 Hash 冲突时，采用拉链法（链表）。JDK 1.8中：当单个桶中元素个数大于等于8时，链表实现改为红黑树实现；当元素个数小于6时，变回链表实现。由此来防止hashCode攻击。 Java HashMap 采用的是冲突链表方式。 HashMap 是 Hashtable 的轻量级实现，可以接受为 null 的键值 (key) 和值 (value)，而 Hashtable 不允许。 LinkedHashMap：保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的。也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比 HashMap 慢，不过有种情况例外，当 HashMap 容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap 慢，因为 LinkedHashMap 的遍历速度只和实际数据有关，和容量无关，而 HashMap 的遍历速度和他的容量有关。 WeakHashMap：从名字可以看出它是某种 Map。它的特殊之处在于 WeakHashMap 里的 entry 可能会被 GC 自动删除，即使程序员没有调用 remove() 或者 clear() 方法。 WeakHashMap 的存储结构类似于HashMap 既然有 WeekHashMap，是否有 WeekHashSet 呢？答案是没有！不过 Java Collections 工具类给出了解决方案，Collections.newSetFromMap(Map&lt;E,Boolean&gt; map) 方法可以将任何 Map包装成一个Set。 工具类 Collections、Arrays：集合类的一个工具类帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 Comparable、Comparator：一般是用于对象的比较来实现排序，两者略有区别。 类设计者没有考虑到比较问题而没有实现 Comparable 接口。这是我们就可以通过使用 Comparator，这种情况下，我们是不需要改变对象的。 一个集合中，我们可能需要有多重的排序标准，这时候如果使用 Comparable 就有些捉襟见肘了，可以自己继承 Comparator 提供多种标准的比较器进行排序。 说明：线程不同步的时候可以通过，Collections.synchronizedList() 方法来包装一个线程同步方法 通用实现ImplementationsHash TableResizable ArrayBalanced TreeLinked ListHash Table + Linked ListInterfacesSetHashSetTreeSetLinkedHashSetListArrayListLinkedListDequeArrayDequeLinkedListMapHashMapTreeMapLinkedHashMap 参考资料： CarpenterLee/JCFInternals:深入理解Java集合框架 Java基础-集合框架 - 掘金 二、深入源码分析源码分析基于 JDK 1.8 / JDK 1.7，在 IDEA 中 double shift 调出 Search EveryWhere，查找源码文件，找到之后就可以阅读源码。 ArrayList1. 概览实现了 RandomAccess 接口，因此支持随机访问，这是理所当然的，因为 ArrayList 是基于数组实现的。 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1private static final int DEFAULT_CAPACITY = 10; 2. 序列化基于数组实现，保存元素的数组使用 transient 修饰，该关键字声明数组默认不会被序列化。ArrayList 具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。ArrayList 重写了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 1transient Object[] elementData; // non-private to simplify nested class access 3. 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 1234567891011121314151617181920212223242526272829303132333435363738394041// JDK 1.8 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;}// 判断数组是否越界private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity);}private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);}// 扩容private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 1.5倍 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);}private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;} 4. 删除元素需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上。 12345678910public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;} 5. Fail-Fast开始之前我们想讲讲，什么是 fail-fast 机制? fail-fast 机制在遍历一个集合时，当集合结构被修改，会抛出 Concurrent Modification Exception。 fail-fast 会在以下两种情况下抛出 Concurrent Modification Exception （1）单线程环境 集合被创建后，在遍历它的过程中修改了结构。 注意 remove() 方法会让 expectModcount 和 modcount 相等，所以是不会抛出这个异常。 （2）多线程环境 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。 modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 Concurrent Modification Exception。 1234567891011121314151617private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); }} Vector1. 同步它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。 123456789101112public synchronized boolean add(E e) { modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;}public synchronized E get(int index) { if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);} 2. ArrayList 与 Vector Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。 3. Vector 替代方案synchronizedList为了获得线程安全的 ArrayList，可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); CopyOnWriteArrayList 也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); CopyOnWrite 容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，读和写不同的容器。 123456789101112131415161718192021public boolean add(T e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; // 复制出新数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 把新元素添加到新数组里 newElements[len] = e; // 把原数组引用指向新数组 setArray(newElements); return true; } finally { lock.unlock(); }}final void setArray(Object[] a) { array = a;} 读的时候不需要加锁，如果读的时候有多个线程正在向 ArrayList 添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的 ArrayList。 123public E get(int index) { return get(getArray(), index);} CopyOnWrite的缺点 CopyOnWrite 容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。 内存占用问题。 因为 CopyOnWrite 的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意：在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说 200M 左右，那么再写入 100M 数据进去，内存就会占用 300M，那么这个时候很有可能造成频繁的 Yong GC 和 Full GC。之前我们系统中使用了一个服务由于每晚使用 CopyOnWrite 机制更新大对象，造成了每晚 15 秒的 Full GC，应用响应时间也随之变长。 针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是 10 进制的数字，可以考虑把它压缩成 36 进制或 64 进制。或者不使用 CopyOnWrite 容器，而使用其他的并发容器，如 ConcurrentHashMap 。 数据一致性问题。 CopyOnWrite 容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用 CopyOnWrite 容器。 关于 C++ 的 STL 中，曾经也有过 Copy-On-Write 的玩法，参见陈皓的《C++ STL String类中的Copy-On-Write》，后来，因为有很多线程安全上的事，就被去掉了。 参考资料： 聊聊并发-Java中的Copy-On-Write容器 | 并发编程网 – ifeve.com LinkedList 1. 概览LinkedList 底层是基于双向链表实现的，也是实现了 List 接口，所以也拥有 List 的一些特点 (JDK1.7/8 之后取消了循环，修改为双向链表) 。 LinkedList 同时实现了 List 接口和 Deque 接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列（Queue），同时又可以看作一个栈（Stack）。这样看来， LinkedList 简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用 LinkedList ，一方面是因为 Java 官方已经声明不建议使用 Stack 类，更遗憾的是，Java里根本没有一个叫做 Queue 的类（它是个接口名字）。 关于栈或队列，现在的首选是 ArrayDeque，它有着比 LinkedList （当作栈或队列使用时）有着更好的性能。 基于双向链表实现，内部使用 Node 来存储链表节点信息。 12345private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;} 每个链表存储了 Head 和 Tail 指针： 12transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; LinkedList 的实现方式决定了所有跟下标相关的操作都是线性时间，而在首段或者末尾删除元素只需要常数时间。为追求效率LinkedList没有实现同步（synchronized），如果需要多个线程并发访问，可以先采用 Collections.synchronizedList() 方法对其进行包装。 2. add() add() 方法有两个版本，一个是 add(E e)，该方法在 LinkedList 的末尾插入元素，因为有 last 指向链表末尾，在末尾插入元素的花费是常数时间。只需要简单修改几个相关引用即可；另一个是 add(int index, E element)，该方法是在指定下表处插入元素，需要先通过线性查找找到具体位置，然后修改相关引用完成插入操作。 123456789101112131415161718192021// JDK 1.8public boolean add(E e) { linkLast(e); return true;}/*** Links e as last element.*/void linkLast(E e) { final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;} add(int index, E element) 的逻辑稍显复杂，可以分成两部分 先根据 index 找到要插入的位置； 修改引用，完成插入操作。 123456789101112public void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));}private void checkPositionIndex(int index) { if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));} 上面代码中的 node(int index) 函数有一点小小的 trick，因为链表双向的，可以从开始往后找，也可以从结尾往前找，具体朝那个方向找取决于条件 index &lt; (size &gt;&gt; 1)，也即是 index 是靠近前端还是后端。 3. remove()remove() 方法也有两个版本，一个是删除跟指定元素相等的第一个元素 remove(Object o)，另一个是删除指定下标处的元素 remove(int index)。 两个删除操作都要： 先找到要删除元素的引用； 修改相关引用，完成删除操作。 在寻找被删元素引用的时候 remove(Object o) 调用的是元素的 equals 方法，而 remove(int index) 使用的是下标计数，两种方式都是线性时间复杂度。在步骤 2 中，两个 revome() 方法都是通过 unlink(Node&lt;E&gt; x) 方法完成的。这里需要考虑删除元素是第一个或者最后一个时的边界情况。 4. get()12345678910111213141516171819public E get(int index) { checkElementIndex(index); return node(index).item;} Node&lt;E&gt; node(int index) { // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; }} 由此可以看出是使用二分查找来看 index 离 size 中间距离来判断是从头结点正序查还是从尾节点倒序查。 node() 会以 O(n/2) 的性能去获取一个结点 如果索引值大于链表大小的一半，那么将从尾结点开始遍历 这样的效率是非常低的，特别是当 index 越接近 size 的中间值时。 5. 总结 LinkedList 插入，删除都是移动指针效率很高。 查找需要进行遍历查询，效率较低。 6. ArrayList 与 LinkedList ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 HashMap我们这篇文章就来试着分析下 HashMap 的源码，由于 HashMap 底层涉及到太多方面，一篇文章总是不能面面俱到，所以我们可以带着面试官常问的几个问题去看源码： 了解底层如何存储数据的 HashMap 的几个主要方法 HashMap 是如何确定元素存储位置的以及如何处理哈希冲突的 HashMap 扩容机制是怎样的 JDK 1.8 在扩容和解决哈希冲突上对 HashMap 源码做了哪些改动？有什么好处? HashMap 的内部功能实现很多，本文主要从根据 key 获取哈希桶数组索引位置、put 方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 1. 存储结构JDK1.7 的存储结构在 1.7 之前 JDK 采用「拉链法」来存储数据，即数组和链表结合的方式： 「拉链法」用专业点的名词来说叫做链地址法。简单来说，就是数组加链表的结合。在每个数组元素上存储的都是一个链表。 我们之前说到不同的 key 可能经过 hash 运算可能会得到相同的地址，但是一个数组单位上只能存放一个元素，采用链地址法以后，如果遇到相同的 hash 值的 key 的时候，我们可以将它放到作为数组元素的链表上。待我们去取元素的时候通过 hash 运算的结果找到这个链表，再在链表中找到与 key 相同的节点，就能找到 key 相应的值了。 JDK1.7 中新添加进来的元素总是放在数组相应的角标位置，而原来处于该角标的位置的节点作为 next 节点放到新节点的后边。稍后通过源码分析我们也能看到这一点。 JDK1.8 的存储结构对于 JDK1.8 之后的 HashMap 底层在解决哈希冲突的时候，就不单单是使用数组加上单链表的组合了，因为当处理如果 hash 值冲突较多的情况下，链表的长度就会越来越长，此时通过单链表来寻找对应 Key 对应的 Value 的时候就会使得时间复杂度达到 O(n)，因此在 JDK1.8 之后，在链表新增节点导致链表长度超过 TREEIFY_THRESHOLD = 8 的时候，就会在添加元素的同时将原来的单链表转化为红黑树。 对数据结构很在行的读者应该，知道红黑树是一种易于增删改查的二叉树，他对与数据的查询的时间复杂度是 O(logn) 级别，所以利用红黑树的特点就可以更高效的对 HashMap 中的元素进行操作。 从结构实现来讲，HashMap 是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。 这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么优点呢？ （1）从源码可知，HashMap 类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个 Node 的数组。我们来看 Node（ JDK1.8 中） 是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) { ... } public final K getKey(){ ... } public final V getValue() { ... } public final String toString() { ... } public final int hashCode() { ... } public final V setValue(V newValue) { ... } public final boolean equals(Object o) { ... }} Node 是 HashMap 的一个内部类，实现了 Map.Entry 接口，本质是就是一个映射（键值对）。上图中的每个黑色圆点就是一个Node对象。 （2）HashMap 就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题， Java 中 HashMap 采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被 Hash 后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码： 1map.put(&quot;美团&quot;,&quot;小美&quot;); 系统将调用 “美团” 这个 key 的 hashCode() 方法得到其 hashCode 值（该方法适用于每个 Java 对象），然后再通过 Hash 算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个 key 会定位到相同的位置，表示发生了 Hash 碰撞。当然 Hash 算法计算结果越分散均匀，Hash 碰撞的概率就越小，map 的存取效率就会越高。 如果哈希桶数组很大，即使较差的 Hash 算法也会比较分散，如果哈希桶数组数组很小，即使好的 Hash 算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的 hash 算法减少 Hash 碰撞。 那么通过什么方式来控制 map 使得 Hash 碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？ 答案就是好的 Hash 算法和扩容机制。 在理解 Hash 和扩容流程之前，我们得先了解下 HashMap 的几个字段。从 HashMap 的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下： 1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度 length (默认值是16)**，Load factor 为负载因子(默认值是0.75)，threshold 是 HashMap 所能容纳的最大数据量的 Node (键值对)个数。threshold = length * Load factor**。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold 就是在此 Load factor 和 length (数组长度)对应下允许的最大元素数目，超过这个数目就重新 resize(扩容)，扩容后的 HashMap 容量是之前容量的两倍。默认的负载因子 0.75 是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子 Load factor 的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子 loadFactor 的值，这个值可以大于1。 size 这个字段其实很好理解，就是 HashMap 中实际存在的键值对数量。注意和 table 的长度 length、容纳最大键值对数量 threshold 的区别。而 modCount 字段主要用来记录 HashMap 内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如 put 新键值对，但是某个 key 对应的 value 值被覆盖不属于结构变化。 在 HashMap 中，哈希桶数组 table 的长度 length 大小必须为 2n（一定是合数），这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考 为什么一般hashtable的桶数会取一个素数？ ，Hashtable 初始化桶大小为 11，就是桶大小设计为素数的应用（Hashtable 扩容后不能保证还是素数）。HashMap 采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap 定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和 Hash 算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。于是，在 JDK1.8 版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高 HashMap 的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考：教你初步了解红黑树。 2. 重要参数 参数 说明 buckets 在 HashMap 的注释里使用哈希桶来形象的表示数组中每个地址位置。注意这里并不是数组本身，数组是装哈希桶的，他可以被称为哈希表。 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size table 的实际使用量。 threshold size 的临界值，size 必须小于 threshold，如果大于等于，就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = capacity * loadFactor。 TREEIFY_THRESHOLD 树化阀值，哈希桶中的节点个数大于该值（默认为8）的时候将会被转为红黑树行存储结构。 UNTREEIFY_THRESHOLD 非树化阀值，小于该值（默认为 6）的时候将再次改为单链表的格式存储 3. 确定哈希桶数组索引位置很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); （一）计算 hash 值 1234567891011121314151617final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);}public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value);} （二）取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123y : 10110010x : 00010000y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) { return h &amp; (length-1);} 4. 分析HashMap的put方法 HashMap 的 put 方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。 ①.判断键值对数组 table[i] 是否为空或为 null，否则执行 resize() 进行扩容； ②.根据键值 key 计算 hash 值得到插入的数组索引i，如果 table[i]==null，直接新建节点添加，转向 ⑥，如果table[i] 不为空，转向 ③； ③.判断 table[i] 的首个元素是否和 key 一样，如果相同直接覆盖 value，否则转向 ④，这里的相同指的是 hashCode 以及 equals； ④.判断table[i] 是否为 treeNode，即 table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向 ⑤； ⑤.遍历 table[i]，判断链表长度是否大于 8，大于 8 的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现 key 已经存在直接覆盖 value 即可； ⑥.插入成功后，判断实际存在的键值对数量 size 是否超多了最大容量 threshold，如果超过，进行扩容。 JDK1.8 HashMap 的 put 方法源码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V put(K key, V value) { // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true);}final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;} 5. 扩容机制扩容 (resize) 就是重新计算容量，向 HashMap 对象里不停的添加元素，而 HashMap 对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然 Java 里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下 resize 的源码，鉴于 JDK1.8 融入了红黑树，较复杂，为了便于理解我们仍然使用 JDK1.7 的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213void resize(int newCapacity) { //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; } Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值} 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer() 方法将原有 Entry 数组的元素拷贝到新的 Entry 数组里。 1234567891011121314151617void transfer(Entry[] newTable) { Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) { src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do { Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 } while (e != null); } }} newTable[i] 的引用赋给了 e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到 Entry 链的尾部(如果发生了 hash 冲突的话），这一点和 Jdk1.8 有区别，下文详解。在旧数组中同一条 Entry 链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的 hash 算法就是简单的用 key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组 table 的 size=2， 所以 key = 3、7、5，put 顺序依次为 5、7、3。在 mod 2 以后都冲突在 table[1] 这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小 size 大于 table 的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize 成 4，然后所有的 Node 重新 rehash 的过程。 下面我们讲解下 JDK1.8 做了哪些优化。经过观测可以发现，我们使用的是 2 次幂的扩展 (指长度扩为原来 2 倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动 2 次幂的位置。看下图可以明白这句话的意思，n 为 table 的长度，图（a）表示扩容前的 key1 和 key2 两种 key 确定索引位置的示例，图（b）表示扩容后 key1 和 key2 两种 key 确定索引位置的示例，其中 hash1 是 key1 对应的哈希与高位运算结果。 元素在重新计算 hash 之后，因为 n 变为 2 倍，那么 n-1 的 mask 范围在高位多 1bit (红色)，因此新的 index 就会发生这样的变化： 因此，我们在扩充 HashMap 的时候，不需要像 JDK1.7 的实现那样重新计算 hash，只需要看看原来的 hash 值新增的那个 bit 是 1 还是 0 就好了，是 0 的话索引没变，是 1 的话索引变成“原索引+oldCap”，可以看看下图为 16 扩充为 32 的 resize 示意图： 这个设计确实非常的巧妙，既省去了重新计算 hash 值的时间，而且同时，由于新增的 1bit 是 0 还是 1 可以认为是随机的，因此 resize 的过程，均匀的把之前的冲突的节点分散到新的 bucket 了。这一块就是 JDK1.8 新增的优化点。有一点注意区别，JDK1.7 中 rehash 的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8 不会倒置。有兴趣的同学可以研究下 JDK1.8 的 resize源 码，写的很赞，如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;，&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里 if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 6. 线程安全性在多线程使用场景中，应该尽量避免使用线程不安全的 HashMap，而使用线程安全的 ConcurrentHashMap。那么为什么说 HashMap 是线程不安全的，下面举例子说明在并发的多线程使用场景中使用 HashMap 可能造成死循环。代码例子如下(便于理解，仍然使用 JDK1.7 的环境)： 1234567891011121314151617181920public class HashMapInfiniteLoop { private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); public static void main(String[] args) { map.put(5， &quot;C&quot;); new Thread(&quot;Thread1&quot;) { public void run() { map.put(7, &quot;B&quot;); System.out.println(map); }; }.start(); new Thread(&quot;Thread2&quot;) { public void run() { map.put(3, &quot;A); System.out.println(map); }; }.start(); } } 其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。 注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。 线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。 e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。 于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。 7. JDK1.8与JDK1.7的性能对比HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。 8. Hash较均匀的情况为了便于测试，我们先写一个类Key，如下： 123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; { private final int value; Key(int value) { this.value = value; } @Override public int compareTo(Key o) { return Integer.compare(this.value, o.value); } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; } @Override public int hashCode() { return value; }} 这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下： 123456789101112131415public class Keys { public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static { for (int i = 0; i &lt; MAX_KEY; ++i) { KEYS_CACHE[i] = new Key(i); } } public static Key of(int value) { return KEYS_CACHE[value]; }} 现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下： 1234567891011121314151617181920static void test(int mapSize) { HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) { map.put(Keys.of(i), i); } long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) { map.get(Keys.of(i)); } long endTime = System.nanoTime(); System.out.println(endTime - beginTime);}public static void main(String[] args) { for(int i=10;i&lt;= 1000 0000;i*= 10){ test(i); }} 在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下： 通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。 9. Hash极不均匀的情况假设我们又一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下： 123456789class Key implements Comparable&lt;Key&gt; { //... @Override public int hashCode() { return 1; }} 仍然执行main方法，得出的结果如下表所示： 从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。 测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。 10. HashMap与HashTable HashTable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 11. 小结 扩容是一个特别耗性能的操作，所以当程序员在使用 HashMap 的时候，估算 map 的大小，初始化的时候给一个大致的数值，避免 map 进行频繁的扩容。 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 HashMap 是线程不安全的，不要在并发的环境中同时操作 HashMap，建议使用 ConcurrentHashMap。 JDK1.8 引入红黑树大程度优化了 HashMap 的性能。 参考资料： Java 8系列之重新认识HashMap——美团技术 搞懂 Java HashMap 源码 - 掘金 搞懂 Java equals 和 hashCode 方法 - 掘金 ConcurrentHashMap1. 概述 众所周知，哈希表是中非常高效，复杂度为 O(1) 的数据结构，在 Java 开发中，我们最常见到最频繁使用的就是 HashMap 和 HashTable，但是在线程竞争激烈的并发场景中使用都不够合理。 HashMap ：先说 HashMap，HashMap 是线程不安全的，在并发环境下，可能会形成环状链表（扩容时可能造成），导致 get 操作时，cpu 空转，所以，在并发环境中使 用HashMap 是非常危险的。 HashTable ： HashTable 和 HashMap的实现原理几乎一样，差别无非是：（1）HashTable不允许key和value为null；（2）HashTable是线程安全的。 但是 HashTable 线程安全的策略实现代价却太大了，简单粗暴，get/put 所有相关操作都是 synchronized 的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。 HashTable 性能差主要是由于所有操作需要竞争同一把锁，而如果容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。这就是ConcurrentHashMap 所采用的 “分段锁“ 思想。 2. 存储结构ConcurrentHashMap 采用了非常精妙的”分段锁”策略，ConcurrentHashMap 的主干是个 Segment 数组。 1final Segment&lt;K,V&gt;[] segments; Segment 继承了 ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。（就按默认的 ConcurrentLeve 为16来讲，理论上就允许 16 个线程并发执行，有木有很酷） 所以，对于同一个 Segment 的操作才需考虑线程同步，不同的 Segment 则无需考虑。 Segment 类似于 HashMap，一个 Segment 维护着一个 HashEntry 数组 1transient volatile HashEntry&lt;K,V&gt;[] table; HashEntry 是目前我们提到的最小的逻辑处理单元了。一个 ConcurrentHashMap 维护一个 Segment 数组，一个 Segment 维护一个 HashEntry 数组。 123456static final class HashEntry&lt;K,V&gt; { final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;} ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 Segment 继承自 ReentrantLock。 1234567891011121314151617static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable { private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;} 1final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; 2. size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */static final int RETRIES_BEFORE_LOCK = 2;public int size() { // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try { for (;;) { // 超过尝试次数，则对每个 Segment 加锁 if (retries++ == RETRIES_BEFORE_LOCK) { for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation } sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) { Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) { sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; } } // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; } } finally { if (retries &gt; RETRIES_BEFORE_LOCK) { for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); } } return overflow ? Integer.MAX_VALUE : size;} 3. 同步方式Segment 继承自 ReentrantLock，所以我们可以很方便的对每一个 Segment 上锁。 对于读操作，获取 Key 所在的 Segment 时，需要保证可见性。具体实现上可以使用 volatile 关键字，也可使用锁。但使用锁开销太大，而使用 volatile 时每次写操作都会让所有 CPU 内缓存无效，也有一定开销。ConcurrentHashMap 使用如下方法保证可见性，取得最新的 Segment。 1Segment&lt;K,V&gt; s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u) 获取 Segment 中的 HashEntry 时也使用了类似方法 12HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE) 对于写操作，并不要求同时获取所有 Segment 的锁，因为那样相当于锁住了整个 Map。它会先获取该 Key-Value 对所在的 Segment 的锁，获取成功后就可以像操作一个普通的 HashMap 一样操作该 Segment，并保证该Segment 的安全性。同时由于其它 Segment 的锁并未被获取，因此理论上可支持 concurrencyLevel（等于 Segment 的个数）个线程安全的并发读写。 获取锁时，并不直接使用 lock 来获取，因为该方法获取锁失败时会挂起。事实上，它使用了自旋锁，如果 tryLock 获取锁失败，说明锁被其它线程占用，此时通过循环再次以 tryLock 的方式申请锁。如果在循环过程中该 Key 所对应的链表头被修改，则重置 retry 次数。如果 retry 次数超过一定值，则使用 lock 方法申请锁。 这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗 CPU 资源比较多，因此在自旋次数超过阈值时切换为互斥锁。 4. JDK 1.8 的改动 JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发程度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。 参考资料： ConcurrentHashMap演进从Java7到Java8 ConcurrentHashMap实现原理及源码分析 - dreamcatcher-cx - 博客园 HashSet 前面已经说过 HashSet 是对 HashMap 的简单包装，对 HashSet 的函数调用都会转换成合适的 HashMap 方法，因此 HashSet 的实现非常简单，只有不到 300 行代码（适配器模式）。这里不再赘述。 12345678910111213141516//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;{ ...... private transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() { map = new HashMap&lt;&gt;(); } ...... public boolean add(E e) {//简单的方法转换 return map.put(e, PRESENT)==null; } ......} 1. 成员变量首先了解下 HashSet 的成员变量: 1234private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 发现主要就两个变量: map ：用于存放最终数据的。 PRESENT ：是所有写入 map 的 value 值。 2. 构造函数1234567public HashSet() { map = new HashMap&lt;&gt;();}public HashSet(int initialCapacity, float loadFactor) { map = new HashMap&lt;&gt;(initialCapacity, loadFactor);} 构造函数很简单，利用了 HashMap 初始化了 map 。 3. add()123public boolean add(E e) { return map.put(e, PRESENT)==null;} 比较关键的就是这个 add() 方法。 可以看出它是将存放的对象当做了 HashMap 的健，value 都是相同的 PRESENT 。由于 HashMap 的 key 是不能重复的，所以每当有重复的值写入到 HashSet 时，value 会被覆盖，但 key 不会收到影响，这样就保证了 HashSet 中只能存放不重复的元素。 4. 总结HashSet 的原理比较简单，几乎全部借助于 HashMap 来实现的。 所以 HashMap 会出现的问题 HashSet 依然不能避免。 LinkedHashSet and LinkedHashMap1. 概览 如果你已看过前面关于 HashSet 和 HashMap，的讲解，一定能够想到本文将要讲解的 LinkedHashSet 和 LinkedHashMap 其实也是一回事。 LinkedHashSet 和 LinkedHashMap 在 Java 里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说 LinkedHashSet 里面有一个 LinkedHashMap（适配器模式）。因此本文将重点分析 LinkedHashMap。 LinkedHashMap 实现了 Map 接口，即允许放入 key 为 null 的元素，也允许插入 value 为 null 的元素。从名字上可以看出该容器是 LinkedList 和 HashMap 的混合体，也就是说它同时满足 HashMap 和 LinkedList 的某些特性。可将 LinkedHashMap 看作采用 LinkedList 增强的 HashMap。 事实上 LinkedHashMap 是 HashMap 的直接子类，二者唯一的区别是 LinkedHashMap 在 HashMap 的基础上，采用双向链表（doubly-linked list）的形式将所有 entry 连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。上图给出了 LinkedHashMap 的结构图，主体部分跟 HashMap 完全一样，多了 header 指向双向链表的头部（是一个哑元），该双向链表的迭代顺序就是 entry 的插入顺序。 除了可以保迭代历顺序，这种结构还有一个好处：迭代 LinkedHashMap 时不需要像 HashMap 那样遍历整个table，而只需要直接遍历 header 指向的双向链表即可，也就是说 LinkedHashMap 的迭代时间就只跟entry的个数相关，而跟table的大小无关。 有两个参数可以影响 LinkedHashMap 的性能：初始容量（inital capacity）和负载系数（load factor）。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。 将对象放入到 LinkedHashMap 或 LinkedHashSet 中时，有两个方法需要特别关心：hashCode() 和 equals()。hashCode() 方法决定了对象会被放到哪个 bucket 里，当多个对象的哈希值冲突时，equals() 方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到 LinkedHashMap 或 LinkedHashSet 中，需要 @OverridehashCode() 和 equals() 方法。 通过如下方式可以得到一个跟源 Map 迭代顺序 一样的 LinkedHashMap： 1234void foo(Map m) { Map copy = new LinkedHashMap(m); ...} 出于性能原因，LinkedHashMap 是非同步的（not synchronized），如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将 LinkedHashMap 包装成（wrapped）同步的： Map m = Collections.synchronizedMap(new LinkedHashMap(...)); 2. get()get(Object key) 方法根据指定的 key 值返回对应的 value。该方法跟HashMap.get()方法的流程几乎完全一样，读者可自行参考前文，这里不再赘述。 3. put()put(K key, V value) 方法是将指定的 key, value 对添加到 map 里。该方法首先会对 map 做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过 addEntry(int hash, K key, V value, int bucketIndex) 方法插入新的 entry。 注意，这里的插入有两重含义： 从 table 的角度看，新的 entry 需要插入到对应的 bucket 里，当有哈希冲突时，采用头插法将新的 entry 插入到冲突链表的头部。 从 header 的角度看，新的 entry 需要插入到双向链表的尾部。 addEntry()代码如下： 123456789101112131415// LinkedHashMap.addEntry()void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length);// 自动扩容，并重新哈希 hash = (null != key) ? hash(key) : 0; bucketIndex = hash &amp; (table.length-1);// hash%table.length } // 1.在冲突链表头部插入新的entry HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); table[bucketIndex] = e; // 2.在双向链表的尾部插入新的entry e.addBefore(header); size++;} 上述代码中用到了 addBefore()方 法将新 entry e 插入到双向链表头引用 header 的前面，这样 e 就成为双向链表中的最后一个元素。addBefore() 的代码如下： 1234567// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面private void addBefore(Entry&lt;K,V&gt; existingEntry) { after = existingEntry; before = existingEntry.before; before.after = this; after.before = this;} 上述代码只是简单修改相关 entry 的引用而已。 4. remove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry（修改链表的相应引用）。查找过程跟get()方法类似。 注意，这里的删除也有两重含义： 从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。 从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。 removeEntryForKey() 对应的代码如下： 12345678910111213141516171819202122232425// LinkedHashMap.removeEntryForKey()，删除key值对应的entryfinal Entry&lt;K,V&gt; removeEntryForKey(Object key) { ...... int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length);// hash&amp;(table.length-1) Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表 Entry&lt;K,V&gt; e = prev; while (e != null) {// 遍历冲突链表 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) {// 找到要删除的entry modCount++; size--; // 1. 将e从对应bucket的冲突链表中删除 if (prev == e) table[i] = next; else prev.next = next; // 2. 将e从双向链表中删除 e.before.after = e.after; e.after.before = e.before; return e; } prev = e; e = next; } return e;} 5. LinkedHashSet前面已经说过LinkedHashSet是对LinkedHashMap的简单包装，对LinkedHashSet的函数调用都会转换成合适的LinkedHashMap方法，因此LinkedHashSet的实现非常简单，这里不再赘述。 1234567891011121314public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable { ...... // LinkedHashSet里面有一个LinkedHashMap public LinkedHashSet(int initialCapacity, float loadFactor) { map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); } ...... public boolean add(E e) {//简单的方法转换 return map.put(e, PRESENT)==null; } ......} 6. LinkedHashMap经典用法LinkedHashMap 除了可以保证迭代顺序外，还有一个非常有用的用法：可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap 有一个子类方法 protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉 Map 是否要删除“最老”的 Entry，所谓最老就是当前 Map 中最早插入的 Entry，如果该方法返回 true，最老的那个元素就会被删除。在每次插入新元素的之后 LinkedHashMap 会自动询问 removeEldestEntry() 是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让 removeEldestEntry() 返回 true，就能够实现一个固定大小的 FIFO 策略的缓存。示例代码如下： 12345678910111213/** 一个固定大小的FIFO替换策略的缓存 */class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;{ private final int cacheSize; public FIFOCache(int cacheSize){ this.cacheSize = cacheSize; } // 当Entry个数超过cacheSize时，删除最老的Entry @Override protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return size() &gt; cacheSize; }} 三、容器中的设计模式迭代器模式 Collection 实现了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);for (String item : list) { System.out.println(item);} 适配器模式java.util.Arrays.asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 如果要将数组类型转换为 List 类型，应该注意的是 asList() 的参数为泛型的变长参数，因此不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = {1, 2, 3};List list = Arrays.asList(arr); 也可以使用以下方式生成 List。 1List list = Arrays.asList(1,2,3); 四、面试指南1. ArrayList和LinkedList区别 ArrayList 和 LinkedList 可想从名字分析，它们一个是 Array (动态数组) 的数据结构，一个是 Link (链表) 的数据结构，此外，它们两个都是对 List 接口的实现。前者是数组队列，相当于动态数组；后者为双向链表结构，也可当作堆栈、队列、双端队列； 当随机访问 List 时（get和set操作），ArrayList 比 LinkedList的效率更高，因为 LinkedList 是线性的数据存储方式，所以需要移动指针从前往后依次查找； 当对数据进行增加和删除的操作时（add 和 remove 操作），LinkedList 比 ArrayList 的效率更高，因为 ArrayList 是数组，所以在其中进行增删操作时，会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动； 从利用效率来看，ArrayList 自由性较低，因为它需要手动的设置固定大小的容量，但是它的使用比较方便，只需要创建，然后添加数据，通过调用下标进行使用；而 LinkedList 自由性较高，能够动态的随数据量的变化而变化，但是它不便于使用； ArrayList 主要空间开销在于需要在 List 列表预留一定空间；而 LinkList 主要控件开销在于需要存储结点信息以及结点指针信息。 ArrayList、LinkedList 和 Vector如何选择？ 当对数据的主要操作为索引或只在集合的末端增加、删除元素时，使用 ArrayList 或 Vector 效率比较高； 当对数据的操作主要为制定位置的插入或删除操作时，使用 LinkedList 效率比较高； 当在多线程中使用容器时（即多个线程会同时访问该容器），选用 Vector 较为安全； 2. HashMap和HashTable区别，HashMap的key类型 Hash Map和HashTable的区别 Hashtable 的方法是同步的，HashMap 非同步，所以在多线程场合要手动同步 Hashtable 不允许 null 值 (key 和 value 都不可以)，HashMap 允许 null 值( key 和 value 都可以)。 两者的遍历方式大同小异，Hashtable 仅仅比 HashMap 多一个 elements 方法。 Hashtable 和 HashMap 都能通过 values() 方法返回一个 Collection ，然后进行遍历处理。 两者也都可以通过 entrySet() 方法返回一个 Set ， 然后进行遍历处理。 HashTable 使用 Enumeration，HashMap 使用 Iterator。 哈希值的使用不同，Hashtable 直接使用对象的 hashCode。而 HashMap 重新计算hash值，而且用于代替求模。 Hashtable 中 hash 数组默认大小是11，增加的方式是 old*2+1。HashMap 中 hash 数组的默认大小是16，而且一定是 2 的指数。 HashTable 基于 Dictionary 类，而 HashMap 基于 AbstractMap 类 HashMap中的key可以是任何对象或数据类型吗 可以为null，但不能是可变对象，如果是可变对象的话，对象中的属性改变，则对象 HashCode 也进行相应的改变，导致下次无法查找到已存在Map中的数据。 如果可变对象在 HashMap 中被用作键，那就要小心在改变对象状态的时候，不要改变它的哈希值了。我们只需要保证成员变量的改变能保证该对象的哈希值不变即可。 HashTable是线程安全的么 HashTable 是线程安全的，其实现是在对应的方法上添加了 synchronized 关键字进行修饰，由于在执行此方法的时候需要获得对象锁，则执行起来比较慢。所以现在如果为了保证线程安全的话，使用 CurrentHashMap。 3. HashMap和ConcurrentHashMap HashMap和Concurrent HashMap区别？ HashMa p是非线程安全的，CurrentHashMap 是线程安全的。 ConcurrentHashMap 将整个 Hash 桶进行了分段 segment，也就是将这个大的数组分成了几个小的片段segment，而且每个小的片段 segment 上面都有锁存在，那么在插入元素的时候就需要先找到应该插入到哪一个片段 segment，然后再在这个片段上面进行插入，而且这里还需要获取 segment 锁。 ConcurrentHashMap 让锁的粒度更精细一些，并发性能更好。 ConcurrentHashMap 线程安全吗， ConcurrentHashMap如何保证 线程安全？ HashTable 容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问 HashTable 的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是 ConcurrentHashMap 所使用的分段锁，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 get 操作的高效之处在于整个 get 过程不需要加锁，除非读到的值是空的才会加锁重读。get 方法里将要使用的共享变量都定义成 volatile，如用于统计当前 Segement 大小的 count 字段和用于存储值的 HashEntry 的 value。定义成 volatile 的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在 get 操作里只需要读不需要写共享变量 count 和 value，所以可以不用加锁。 put 方法首先定位到 Segment，然后在 Segment 里进行插入操作。 插入操作需要经历两个步骤：（1）判断是否需要对 Segment 里的 HashEntry 数组进行扩容；（2）定位添加元素的位置然后放在HashEntry数组里。 4. Hashtable的原理Hashtable 使用链地址法进行元素存储，通过一个实际的例子来演示一下插入元素的过程： 假设我们现在 Hashtable 的容量为 5，已经存在了 (5,5)，(13,13)，(16,16)，(17,17)，(21,21) 这 5 个键值对，目前他们在 Hashtable 中的位置如下： 现在，我们插入一个新的键值对，put(16,22)，假设 key=16 的索引为 1.但现在索引 1 的位置有两个 Entry 了，所以程序会对链表进行迭代。迭代的过程中，发现其中有一个 Entry 的 key 和我们要插入的键值对的 key 相同，所以现在会做的工作就是将 newValue=22 替换 oldValue=16，然后返回 oldValue = 16. 然后我们现在再插入一个，put(33,33)，key=33 的索引为 3，并且在链表中也不存在 key=33 的 Entry，所以将该节点插入链表的第一个位置。 Hashtable 与 HashMap 的简单比较 HashTable 基于 Dictionary 类，而 HashMap 是基于 AbstractMap。Dictionary 是任何可将键映射到相应值的类的抽象父类，而 AbstractMap 是基于 Map 接口的实现，它以最大限度地减少实现此接口所需的工作。 HashMap 的 key 和 value 都允许为 null，而 Hashtable 的 key 和 value 都不允许为 null。HashMap 遇到 key 为 null 的时候，调用 putForNullKey 方法进行处理，而对 value 没有处理；Hashtable遇到 null，直接返回 NullPointerException。 Hashtable 方法是同步，而HashMap则不是。我们可以看一下源码，Hashtable 中的几乎所有的 public 的方法都是 synchronized 的，而有些方法也是在内部通过 synchronized 代码块来实现。所以有人一般都建议如果是涉及到多线程同步时采用 HashTable，没有涉及就采用 HashMap，但是在 Collections 类中存在一个静态方法：**synchronizedMap()**，该方法创建了一个线程安全的 Map 对象，并把它作为一个封装的对象来返回。 参考资料： Hashtable 的实现原理 - Java 集合学习指南 - 极客学院Wiki 5. Hash冲突的解决办法 链地址法 开放地址法（向后一位） 线性探测 平方探测 二次哈希 再哈希法 6. 什么是迭代器 Java 集合框架的集合类，我们有时候称之为容器。容器的种类有很多种，比如 ArrayList、LinkedList、HashSet…，每种容器都有自己的特点，ArrayList 底层维护的是一个数组；LinkedList 是链表结构的；HashSet 依赖的是哈希表，每种容器都有自己特有的数据结构。 因为容器的内部结构不同，很多时候可能不知道该怎样去遍历一个容器中的元素。所以为了使对容器内元素的操作更为简单，Java 引入了迭代器模式！ 把访问逻辑从不同类型的集合类中抽取出来，从而避免向外部暴露集合的内部结构。 迭代器模式：就是提供一种方法对一个容器对象中的各个元素进行访问，而又不暴露该对象容器的内部细。 1234567891011121314151617public static void main(String[] args) { // 使用迭代器遍历ArrayList集合 Iterator&lt;String&gt; listIt = list.iterator(); while(listIt.hasNext()){ System.out.println(listIt.hasNext()); } // 使用迭代器遍历Set集合 Iterator&lt;String&gt; setIt = set.iterator(); while(setIt.hasNext()){ System.out.println(listIt.hasNext()); } // 使用迭代器遍历LinkedList集合 Iterator&lt;String&gt; linkIt = linkList.iterator(); while(linkIt.hasNext()){ System.out.println(listIt.hasNext()); }} 参考资料： 深入理解Java中的迭代器 - Mr·Dragon - 博客园 7. 构造相同hash的字符串进行攻击，这种情况应该怎么处理？JDK7如何处理攻击原理： 当客户端发送一个请求到服务器，如果该请求中带有参数，服务器端会将 参数名-参数值 作为 key-value 保存在 HashMap 中。如果有人恶意构造请求，在请求中加入大量相同 hash 值的 String 参数名（key），那么在服务器端用于存储这些 key-value 对的 HashMap 会被强行退化成链表，如图： 如果数据量足够大，那么在查找，插入时会占用大量 CPU，达到拒绝服务攻击的目的。 怎么处理 限制 POST 和 GET 请求的参数个数 限制 POST 请求的请求体大小 Web Application FireWall（WAF） JDK7如何处理 HashMap 会动态的使用一个专门 TreeMap 实现来替换掉它。 8. Hashmap为什么大小是2的幂次首先来看一下 hashmap 的 put 方法的源码 1234567891011121314151617181920212223public V put(K key, V value) { if (key == null) return putForNullKey(value); //将空key的Entry加入到table[0]中 int hash = hash(key.hashCode()); //计算key.hashcode()的hash值，hash函数由hashmap自己实现 int i = indexFor(hash, table.length); //获取将要存放的数组下标 /* * for中的代码用于：当hash值相同且key相同的情况下，使用新值覆盖旧值（其实就是修改功能） */ //注意：for循环在第一次执行时就会先判断条件 for (Entry&lt;K, V&gt; e = table[i]; e != null; e = e.next) { Object k; //hash值相同且key相同的情况下，使用新值覆盖旧值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; //e.recordAccess(this); return oldValue;//返回旧值 } } modCount++; addEntry(hash, key, value, i);//增加一个新的Entry到table[i] return null;//如果没有与传入的key相等的Entry，就返回null} 1234567/** * &quot;按位与&quot;来获取数组下标 */static int indexFor(int h, int length) { return h &amp; (length - 1);} hashmap 始终将自己的桶保持在2n，这是为什么？indexFor这个方法解释了这个问题 大家都知道计算机里面位运算是基本运算，位运算的效率是远远高于取余 % 运算的 举个例子：2n 转换成二进制就是 1+n 个 0，减 1 之后就是 0+n个1，如16 -&gt; 10000，15 -&gt; 01111 那么根据 &amp; 位运算的规则，都为 1 (真)时，才为 1，那 0≤运算后的结果≤15，假设 h &lt;= 15，那么运算后的结果就是 h 本身，h &gt;15，运算后的结果就是最后四位二进制做 &amp; 运算后的值，最终，就是 % 运算后的余数。 当容量一定是 2n 时，h &amp; (length - 1) == h % length 更新日志 2018/8/3 v2.5 基础版 2018/9/1 v3.0 初稿版","link":"/2019/05/16/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"技巧","slug":"技巧","link":"/tags/%E6%8A%80%E5%B7%A7/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"mybatisPlus","slug":"mybatisPlus","link":"/tags/mybatisPlus/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"工具","slug":"工具","link":"/tags/%E5%B7%A5%E5%85%B7/"},{"name":"基本命令","slug":"基本命令","link":"/tags/%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"name":"签名","slug":"签名","link":"/tags/%E7%AD%BE%E5%90%8D/"},{"name":"性能","slug":"性能","link":"/tags/%E6%80%A7%E8%83%BD/"},{"name":"heroku","slug":"heroku","link":"/tags/heroku/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"图片识别","slug":"图片识别","link":"/tags/%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"防盗链","slug":"防盗链","link":"/tags/%E9%98%B2%E7%9B%97%E9%93%BE/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"信号量","slug":"信号量","link":"/tags/%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"name":"java基础","slug":"java基础","link":"/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"servlet","slug":"servlet","link":"/tags/servlet/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"分布式事务","slug":"分布式事务","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"小程序","slug":"小程序","link":"/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"java核心","slug":"java核心","link":"/tags/java%E6%A0%B8%E5%BF%83/"}],"categories":[{"name":"Effective Java","slug":"Effective-Java","link":"/categories/Effective-Java/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"基础","slug":"java/基础","link":"/categories/java/%E5%9F%BA%E7%A1%80/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"dubbo","slug":"dubbo","link":"/categories/dubbo/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"nodejs","slug":"nodejs","link":"/categories/nodejs/"},{"name":"杂谈","slug":"杂谈","link":"/categories/%E6%9D%82%E8%B0%88/"},{"name":"J2EE","slug":"J2EE","link":"/categories/J2EE/"},{"name":"mq","slug":"mq","link":"/categories/mq/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"服务器","slug":"服务器","link":"/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"基础","slug":"Java/基础","link":"/categories/Java/%E5%9F%BA%E7%A1%80/"},{"name":"网站","slug":"网站","link":"/categories/%E7%BD%91%E7%AB%99/"},{"name":"SpringCloud商城","slug":"SpringCloud商城","link":"/categories/SpringCloud%E5%95%86%E5%9F%8E/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"事务","slug":"事务","link":"/categories/%E4%BA%8B%E5%8A%A1/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"题目","slug":"面试/题目","link":"/categories/%E9%9D%A2%E8%AF%95/%E9%A2%98%E7%9B%AE/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"}]}